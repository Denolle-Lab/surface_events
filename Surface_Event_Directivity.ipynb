{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f6cb81",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Surface Event Analysis\n",
    "###### This notebook analyzes surface event waveforms and calculates location, directivity, and velocity\n",
    "###### Francesca Skene\n",
    "###### fskene@uw.edu\n",
    "###### Created: 7/22/22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021dc6f",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf759fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from obspy.core import UTCDateTime\n",
    "import pandas as pd\n",
    "from obspy.clients.fdsn.client import Client\n",
    "client2 = Client(\"IRIS\")\n",
    "from obspy.geodetics import *\n",
    "import requests\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append(\"/data/wsd01/pnwstore/\")\n",
    "from obspy.signal.cross_correlation import *\n",
    "from mpl_toolkits import mplot3d\n",
    "import scipy\n",
    "\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from pnwstore.mseed import WaveformClient\n",
    "from obspy.core.utcdatetime import UTCDateTime\n",
    "client = WaveformClient()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30de3d",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_before = 120 #number of seconds before pick time\n",
    "t_after = 120 #number of seconds after pick time\n",
    "fs = 40 #sampling rate that all waveforms are resampled to\n",
    "window = 30 #window length of the signal\n",
    "pr = 98 #percentile\n",
    "thr = 7 #SNR threshold\n",
    "station_distance_threshold = 25\n",
    "pi = np.pi\n",
    "v_s = 1000 #shear wave velocity at the surface\n",
    "t_beginning = UTCDateTime(2001,1,1,0,0,0)\n",
    "t_end = UTCDateTime(2021,12,31,23,59)\n",
    "low_cut = 2\n",
    "high_cut = 8\n",
    "az_thr = 2 #threshold of distance from center of volcano that a station's azimuth counts towards direction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96853aa",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d4c152",
   "metadata": {},
   "source": [
    "This functions cross correlates envelopes of waveforms to calculate picktimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d04cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_time(ref_env, data_env_dict):\n",
    "    est_picktimes = []\n",
    "    est_picktimes.append(str(tr.stats.starttime + t_before)) \n",
    "    xcor = obspy.signal.cross_correlation.correlate(data_env_dict,ref_env,int(5*fs))\n",
    "    index = np.argmax(xcor)\n",
    "    cc = round(xcor[index],9) #correlation coefficient\n",
    "    shift = 5*fs-index #how much it is shifted from the reference envelope\n",
    "    #print(shift, cc, key)\n",
    "    \n",
    "    p = UTCDateTime(est_picktimes[0]) + shift/fs  # p is the new phase pick for each station\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b14b1",
   "metadata": {},
   "source": [
    "This function resamples the data in the streams to 40 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f20a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(st, fs):\n",
    "    for i in st:\n",
    "        i.detrend(type='demean')\n",
    "        i.taper(0.05)\n",
    "        i.resample(fs)   \n",
    "    return st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a8154",
   "metadata": {},
   "source": [
    "Function to fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5199fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def test_func(theta, a,theta0, c):\n",
    "                    return a * np.cos(theta-theta0)+c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d472ef4",
   "metadata": {},
   "source": [
    "##  Import and organize metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22a659",
   "metadata": {},
   "source": [
    "### 1. Volcano Data (network and station, labeled with volcano name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b099703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data includes all stations within 50km of each volcano and the lat, lon, elev of each station\n",
    "df = pd.read_csv('Volcano_Metadata_50km.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb31546",
   "metadata": {},
   "source": [
    "Input Volcano Names and Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data obtained from www.lat-long.com\n",
    "volc_lat_lon = {}\n",
    "volc_lat_lon['Mt_Rainier'] = [46.8528857, -121.7603744, 4392.5]\n",
    "volc_lat_lon['Mt_Adams'] = [46.202621, -121.4906384, 3743.2]\n",
    "volc_lat_lon['Mt_Baker'] = [48.7773426,  -121.8132008, 3287.6]\n",
    "# change the lat and lon of mt st helens to the middle of the dome instead of the highest point\n",
    "#NOTE: while changing the lat and lon from the peak to the middle of the dome caused the sin curve to look\n",
    "#differet, the flow direction stayed more or less the same!\n",
    "volc_lat_lon['Mt_St_Helens'] =[46.200472222222224,-122.18883611111112,2549] #[46.1912, -122.1944, 2549]\n",
    "volc_lat_lon['Glacier_Peak'] = [48.1112273, -121.1139922, 3213]\n",
    "volc_lat_lon['Crater_Lake']=[42.907745, -122.143494, 1883]\n",
    "volc_lat_lon['Mt_Hood']=[45.373221, -121.696509, 3428.7]\n",
    "volc_lat_lon['Newberry']=[43.7220653, -121.2344654, 2435]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ca268",
   "metadata": {},
   "source": [
    "### 3. Surface Event Data from PNSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3894296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"su\" is the label for surface event\n",
    "\n",
    "df3= pd.read_csv('../surface_events/PNSN_Pick_Label.csv')\n",
    "\n",
    "label = df3['Label'].values.tolist()\n",
    "\n",
    "surface_label = df3[df3['Label']== 'su']['Label'].values.tolist()\n",
    "net = df3[df3['Label']== 'su']['Network'].values.tolist()\n",
    "sta = df3[df3['Label']== 'su']['Station'].values.tolist()\n",
    "evt_id = df3[df3['Label']== 'su']['Event_ID'].values.tolist()\n",
    "start_time = df3[df3['Label']== 'su']['Picktime'].values.tolist()                               \n",
    "\n",
    "print((start_time[7234]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e896",
   "metadata": {},
   "source": [
    "## Calculating seasonal occurence of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in volc_lat_lon:\n",
    "    events = []\n",
    "    starttimes = []\n",
    "    stations = []\n",
    "    networks = []\n",
    "    for i in range(0, len(start_time)):\n",
    "        try:\n",
    "            associated_volcano = df[df['Station']== sta[i]]['Volcano_Name'].values[0]\n",
    "        except: \n",
    "            associated_volcano = 'unknown'\n",
    "    \n",
    "        if associated_volcano == name and evt_id[i]!=evt_id[i-1]:\n",
    "            events.append(evt_id[i])\n",
    "            starttimes.append(start_time[i])\n",
    "            stations.append(sta[i])\n",
    "            networks.append(net[i])\n",
    "\n",
    "    num_events = {}\n",
    "    for year in range (2001, 2021):\n",
    "        for month in range (1, 13):\n",
    "            Nevt = []\n",
    "            period = str(year)+\"_\"+str(month)\n",
    "            t0 = UTCDateTime(year, month, 1)\n",
    "            t1 = t0+3600*24*30\n",
    "            for i in range(0, len(starttimes)):\n",
    "                if t0<starttimes[i]<t1:\n",
    "                    Nevt.append(events[i])\n",
    "                    \n",
    "\n",
    "            if len(Nevt) != 0:\n",
    "                num_events[period]=len(Nevt)\n",
    "            if len(Nevt) == 0:\n",
    "                num_events[period] = 0\n",
    "\n",
    "\n",
    "    periods = list(num_events.keys())\n",
    "    num_of_events = list(num_events.values())\n",
    "    fig = plt.figure(figsize = (60, 10))\n",
    "    for x in range(0,len(periods)):\n",
    "        if '5'<=periods[x][-1]<='9':\n",
    "            plt.bar(periods[x], num_of_events[x], color = 'r', width = 0.4)\n",
    "        else:\n",
    "            plt.bar(periods[x],num_of_events[x], color ='b', width = 0.4)\n",
    "    plt.xlabel(\"year_month\")\n",
    "    plt.xticks(np.arange(0, len(periods)+1, 12)) #make every year\n",
    "    plt.ylabel(\"No. of events\")\n",
    "    plt.title(\"Number of surface events per month at\" + str(name))\n",
    "    plt.rcParams.update({'font.size': 30})\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the average slope of each volcano (very tentative)\n",
    "h1 = []\n",
    "for y in volc_lat_lon:\n",
    "    h1.append(volc_lat_lon[y][2]) #top of each volcano\n",
    "    \n",
    "h2 = [1538.935, 1822.704, 1343.863]\n",
    "\n",
    "radius = [11265.41, 4828.032, 6437.376]\n",
    "\n",
    "slope =[]\n",
    "for i in range(len(h2)):\n",
    "    height = h1[i]-h2[i]\n",
    "    slope.append(height/radius[i])\n",
    "print(slope)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee17f48",
   "metadata": {},
   "source": [
    "### Time Series for the XD temporary network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12fa267",
   "metadata": {},
   "source": [
    "## Calculating directivity and velocity of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c702477",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "for n in range(249,260):\n",
    "    event_ID = str(evt_id[n])\n",
    "    t = UTCDateTime(start_time[n])\n",
    "    if net != 'CN' and evt_id[n]!=evt_id[n-1]:\n",
    "        if t_beginning<=t<=t_end:\n",
    "            reference = str(net[n]+'.'+sta[n])\n",
    "            try:\n",
    "                associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "            except: \n",
    "                associated_volcano = 'unknown'\n",
    "\n",
    "            if associated_volcano == 'unknown':\n",
    "                pass\n",
    "            else:\n",
    "            #get info for stations within 50km of volcano that event ocurred at\n",
    "                stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "                networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "                latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "                longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "                elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "                volc_lat = volc_lat_lon[associated_volcano][0]\n",
    "                volc_lon = volc_lat_lon[associated_volcano][1]\n",
    "                \n",
    "                \n",
    "            # get all waveforms for one event\n",
    "                bulk = [] \n",
    "                for m in range(0, len(networks)):\n",
    "                    bulk.append([networks[m], stations[m], '*', '*', t-t_before, t+t_after])\n",
    "                st = client.get_waveforms_bulk(bulk)\n",
    "                for tr in st:\n",
    "                    if tr.stats.channel[0:2] != 'BH' and tr.stats.channel[0:2] != 'EH' and tr.stats.channel[0:2] != 'HH':\n",
    "                            st.remove(tr)\n",
    "                            continue\n",
    "                    if len(tr.data)/tr.stats.sampling_rate < 239.9:\n",
    "                        st.remove(tr)\n",
    "                \n",
    "            #resampling the data to 40Hz for each trace\n",
    "                st = resample(st,fs) \n",
    "                \n",
    "                \n",
    "            #Plotting all traces for one event with channel z, SNR>7, and bandpasses between 2-12Hz\n",
    "                snr, SNR, stas, data_env_dict = [], [], [],{}\n",
    "                \n",
    "                fig = plt.figure(figsize = (20,50), dpi=80)\n",
    "                plt.subplots_adjust(hspace = .4)\n",
    "                fig.suptitle('evtID:UW'+ event_ID+associated_volcano)\n",
    "\n",
    "                ax1 = plt.subplot(4,1,1)\n",
    "                iplot = 0\n",
    "                for g,x in enumerate(st):\n",
    "                    t = x.times()\n",
    "                    x.detrend(type = 'demean')\n",
    "                    x.filter('bandpass',freqmin=2.0,freqmax=12.0,corners=2,zerophase=True)\n",
    "                    network = x.stats.network\n",
    "                    station = x.stats.station\n",
    "                    cha = x.stats.channel\n",
    "                    starttime = x.stats.starttime\n",
    "                    smooth_length = 2*fs\n",
    "\n",
    "                    signal_window = x.copy()\n",
    "                    noise_window = x.copy()\n",
    "                    #TODO: fix signal window to be around the max amplitude\n",
    "                    signal_window.trim(starttime+t_before-1, starttime+t_before-1+window)\n",
    "                    noise_window.trim(starttime-window+t_before-10, starttime+t_before-10)\n",
    "\n",
    "                    snr.append(20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                                   / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "\n",
    "                    if cha[-1] == 'Z' and snr[g]>thr:\n",
    "                        #enveloping the data to calculate picktimes later on\n",
    "                        data_envelope = obspy.signal.filter.envelope(x.data[110*fs:140*fs])\n",
    "                        data_envelope /= np.max(data_envelope)\n",
    "                        data_envelope += iplot*1.5\n",
    "                        data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "                        data_env_dict[network+'.'+station]= data_envelope\n",
    "\n",
    "                        ax1.plot(t[100*fs:175*fs],x.data[100*fs:175*fs]/np.max(np.abs(x.data))+iplot*1.5)\n",
    "                        ax1.plot(t[110*fs:140*fs], data_envelope, color = 'k')\n",
    "                        ax1.set_xlabel('time (seconds)')\n",
    "                        ax1.set_xlim([100,175])\n",
    "                        plt.text(t[175*fs], iplot*1.5, str(snr[g]))\n",
    "                        plt.text(t[100*fs], iplot*1.5, x.stats.station)\n",
    "                        iplot = iplot+1\n",
    "\n",
    "                        stas.append(x.stats.station)\n",
    "                        SNR.append(snr[g])\n",
    "                    else:\n",
    "                        st.remove(x) #only want to work with z component channels with high SNR\n",
    "                        \n",
    "        \n",
    "                if len(st)>=4: #want events with enough waveforms to work with\n",
    "                    dist, pick_times, lats, lons, elevs, r, theta, Sta = ([] for i in range(8))\n",
    "                    for s in range(0, len(stas)):\n",
    "                        dist.append(df[df['Station'] == stas[s]]['Distance_from_volc'].values[0]) \n",
    "\n",
    "                    for key in data_env_dict:\n",
    "                        p = pick_time(data_env_dict[reference], data_env_dict[key]) #calculate picktimes\n",
    "                        pick_times.append(p)\n",
    "                   \n",
    "                    for i, ii in enumerate(stas):\n",
    "                        a = stations.index(ii)\n",
    "                        lats.append(latitudes[a])\n",
    "                        lons.append(longitudes[a])\n",
    "                        elevs.append(elevations[a])\n",
    "                    #calculating azimuth for each station with respect to the middle of the volcano\n",
    "                        lat2 = lats[i]\n",
    "                        lon2 = lons[i]\n",
    "                        lat1 = volc_lat\n",
    "                        lon1 = volc_lon\n",
    "                        u,b,c = (gps2dist_azimuth(lat1, lon1, lat2, lon2, a=6378137.0, f=0.0033528106647474805))\n",
    "                        r.append(u)\n",
    "                        theta.append(b)\n",
    "                        Sta.append(stas[i])\n",
    "                            \n",
    "                    #Get peak frequency of each event\n",
    "                    ax2 = plt.subplot(4,1,2)\n",
    "                    ax2.set_title('Power Spectral Density')\n",
    "                    spectra_method = \"welch\"\n",
    "                    char_freq_method = \"mean\"\n",
    "                    # read and preprocess data\n",
    "                    st.filter(\"bandpass\",freqmin=low_cut,freqmax=high_cut)\n",
    "                    st.taper(max_percentage=0.01,max_length=20)\n",
    "                    st.trim(starttime=min(pick_times),endtime=min(pick_times)+20) \n",
    "                    \n",
    "                    # make plot of spectra\n",
    "                    colors = list(plt.cm.tab10(np.arange(10))) + [\"crimson\", \"indigo\", \"powderblue\", \"lime\"]\n",
    "                    char_freq, spectra_list, weight= [],[],[]\n",
    "                    for i in range(len(Sta)):\n",
    "                        try:\n",
    "                            data = st.select(station=Sta[i],component=\"Z\")[0].data*100\n",
    "                            a = 'stream is not empty'\n",
    "                        except:\n",
    "                            pass\n",
    "                        if a == 'stream is not empty':\n",
    "                            f,psd=scipy.signal.welch(data,fs=st[0].stats.sampling_rate,nperseg=81,noverlap=1)\n",
    "                            #just get the indices of frequencies within the filter band\n",
    "                            above_low_cut = [f>low_cut]\n",
    "                            below_high_cut = [f<high_cut]\n",
    "                            in_band = np.logical_and(above_low_cut,below_high_cut)[0]\n",
    "                            f = f[in_band]\n",
    "                            psd = psd[in_band]\n",
    "                            #weighting the data by the spikiness of the PSD vs frequency graphs\n",
    "                            ratio = (np.mean(psd)/np.max(psd))\n",
    "                            weight.append(int(1/(ratio**2)*20))\n",
    "                            \n",
    "                            ax2.plot(f,psd,label=Sta[i],linewidth=2)\n",
    "                            ax2.set_xscale('log')\n",
    "                            ax2.set_yscale('log')\n",
    "                            ax2.set_xlabel('Frequency [Hz]')\n",
    "                            ax2.set_ylabel('PSD [$(mm/s)^2$/Hz]')\n",
    "                            spectra_list.append(psd)\n",
    "                            ax2.legend()\n",
    "                            ax2.grid(True)\n",
    "\n",
    "                        # calculate characteristic frequency and report\n",
    "#                             if char_freq_method == \"max\":\n",
    "                            char_freq_max = f[np.argmax(psd)]\n",
    "#                             elif char_freq_method == \"mean\":\n",
    "                            char_freq_mean= np.sum(psd*f)/np.sum(psd)\n",
    "#                             elif char_freq_method == \"median\":\n",
    "#                                 psd_cumsum = np.cumsum(psd)\n",
    "#                                 psd_sum = np.sum(psd)\n",
    "#                                 char_freq_median = f[np.argmin(np.abs(psd_cumsum-psd_sum/2))]\n",
    "                            char_freq.append(char_freq_max)\n",
    "                            ymax=max(psd)\n",
    "                            plt.vlines(char_freq_max, ymin=0, ymax = ymax, color = colors[i])\n",
    "\n",
    "                    if a == 'stream is not empty':\n",
    "                        #manipulating the data\n",
    "                        data = {'azimuth':theta, 'freq':char_freq, 'station':Sta, 'distance':dist, 'weight':weight, 'SNR':SNR}\n",
    "                        DF = pd.DataFrame(data, index = None)\n",
    "                        DF2 = DF.sort_values('azimuth')\n",
    "                        drops =[]\n",
    "                        for i in range (0,len(DF2)):\n",
    "                            value = DF2.loc[i,'distance']\n",
    "                            if value < az_thr:\n",
    "                                drops.append(i)\n",
    "                        DF3 = DF2.drop(drops)\n",
    "                        y_data =  DF3[\"freq\"].values.tolist()\n",
    "                        Sta2 = DF3[\"station\"].values.tolist()\n",
    "                        dist2 = DF3[\"distance\"].values.tolist()\n",
    "                        weight2 = DF3[\"weight\"].values.tolist()\n",
    "                        SNR2 = DF3['SNR'].values.tolist()\n",
    "                        x_data =  np.asarray(DF3[\"azimuth\"].values.tolist())\n",
    "                        x_points = np.linspace(0,360, 100)\n",
    "                        ax3 = plt.subplot(4,1,3)\n",
    "                        ax3.set_title('Fitting Sin curve')\n",
    "                        ax3.set_ylabel('characteristic frequency(Hz)')\n",
    "                        ax3.set_xlabel('azimuth(degrees)')\n",
    "                        for i in range (0,len(Sta2)):\n",
    "                            ax3.scatter(x_data[i], y_data[i], s = (dist2[i]**2*10), label=Sta2[i])\n",
    "                        ax3.plot(x_data,y_data, '--', label='rawdata')\n",
    "                        ax3.legend(loc='best')\n",
    "                        #weighting the data\n",
    "                        print(x_data, 'original')\n",
    "                        tempx, tempy = [],[]\n",
    "                        for i,ii in enumerate(x_data):\n",
    "                            tempx.append([])\n",
    "                            tempx[i].append([ii for l in range(0,weight2[i])])\n",
    "                            tempy.append([])\n",
    "                            tempy[i].append([y_data[i] for l in range(0,weight2[i])])   \n",
    "                        weighted_x = sum(sum(tempx, []),[])\n",
    "                        weighted_y = sum(sum(tempy, []),[])\n",
    "                        \n",
    "                        #optimizing parameters to fit weighted data to test_function\n",
    "                        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "                        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "                        ax3.plot(x_points, d, label='Fitted function')\n",
    "                        \n",
    "                        \n",
    "                        len_r = int(max(r))\n",
    "                        line_length = np.linspace(0,len_r,len_r+1)\n",
    "                        rads = np.arange(0, (2 *pi), 0.01)\n",
    "                        direction=[]\n",
    "                        direction = [(params[1]) for i in range(len_r+1)]\n",
    "                        \n",
    "                        ax4= plt.subplot(4,1,4, polar=True)\n",
    "                        ax4.set_theta_offset(pi/2)\n",
    "                        ax4.set_theta_direction(-1)\n",
    "                        for i in range(0,len(r)):\n",
    "                            ax4.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "                            ax4.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "                        ax4.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "                        for rad in rads:\n",
    "                            ax4.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "                        #calculating velocity from the frequency shift\n",
    "                        fmax = max(d)\n",
    "                        fmin = min(d)\n",
    "                        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "                        print(v,'m/s')\n",
    "\n",
    "                       #plt.savefig('evtID:UW'+ event_ID+associated_volcano+'.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408cef23",
   "metadata": {},
   "source": [
    "## weighting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72901cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 10})\n",
    "for n in range(7234,7235):\n",
    "    event_ID = str(evt_id[n])\n",
    "    t = UTCDateTime(start_time[n])\n",
    "    if net != 'CN' and evt_id[n]!=evt_id[n-1]:\n",
    "        if t_beginning<=t<=t_end:\n",
    "            reference = str(net[n]+'.'+sta[n])\n",
    "            print(reference)\n",
    "            try:\n",
    "                associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "            except: \n",
    "                associated_volcano = 'unknown'\n",
    "\n",
    "            if associated_volcano == 'unknown':\n",
    "                pass\n",
    "            else:\n",
    "            #get info for stations within 50km of volcano that event ocurred at\n",
    "                stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "                networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "                latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "                longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "                elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "                volc_lat = volc_lat_lon[associated_volcano][0]\n",
    "                volc_lon = volc_lat_lon[associated_volcano][1]\n",
    "                \n",
    "                \n",
    "            # get all waveforms for one event\n",
    "                bulk = [] \n",
    "                for m in range(0, len(networks)):\n",
    "                    bulk.append([networks[m], stations[m], '*', '*', t-t_before, t+t_after])\n",
    "                st = client.get_waveforms_bulk(bulk)\n",
    "                for tr in st:\n",
    "                    if tr.stats.channel[0:2] != 'BH' and tr.stats.channel[0:2] != 'EH' and tr.stats.channel[0:2] != 'HH':\n",
    "                            st.remove(tr)\n",
    "                            continue\n",
    "                    if len(tr.data)/tr.stats.sampling_rate < 239.9:\n",
    "                        st.remove(tr)\n",
    "                \n",
    "            #resampling the data to 40Hz for each trace\n",
    "                st = resample(st,fs) \n",
    "                \n",
    "            #Plotting all traces for one event with channel z, SNR>7, and bandpasses between 2-12Hz\n",
    "                snr, SNR, stas, data_env_dict = [], [], [],{}\n",
    "                \n",
    "                fig = plt.figure(figsize = (20,50), dpi=80)\n",
    "                plt.subplots_adjust(hspace = .4)\n",
    "                fig.suptitle('evtID:UW'+ event_ID+associated_volcano)\n",
    "\n",
    "                ax1 = plt.subplot(4,1,1)\n",
    "                iplot = 0\n",
    "                for g,x in enumerate(st):\n",
    "                    t = x.times()\n",
    "                    x.detrend(type = 'demean')\n",
    "                    x.filter('bandpass',freqmin=2.0,freqmax=12.0,corners=2,zerophase=True)\n",
    "                    network = x.stats.network\n",
    "                    station = x.stats.station\n",
    "                    cha = x.stats.channel\n",
    "                    starttime = x.stats.starttime\n",
    "                    smooth_length = 2*fs\n",
    "\n",
    "                    signal_window = x.copy()\n",
    "                    noise_window = x.copy()\n",
    "                    #TODO: fix signal window to be around the max amplitude\n",
    "                    signal_window.trim(starttime+t_before-1, starttime+t_before-1+window)\n",
    "                    noise_window.trim(starttime-window+t_before-10, starttime+t_before-10)\n",
    "\n",
    "                    snr.append(20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                                   / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "\n",
    "                    if cha[-1] == 'Z' and snr[g]>thr:\n",
    "                        #enveloping the data to calculate picktimes later on\n",
    "                        data_envelope = obspy.signal.filter.envelope(x.data[110*fs:140*fs])\n",
    "                        data_envelope /= np.max(data_envelope)\n",
    "                        data_envelope += iplot*1.5\n",
    "                        data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "                        data_env_dict[network+'.'+station]= data_envelope\n",
    "\n",
    "                        ax1.plot(t[100*fs:175*fs],x.data[100*fs:175*fs]/np.max(np.abs(x.data))+iplot*1.5)\n",
    "                        ax1.plot(t[110*fs:140*fs], data_envelope, color = 'k')\n",
    "                        ax1.set_xlabel('time (seconds)')\n",
    "                        ax1.set_xlim([100,175])\n",
    "                        plt.text(t[175*fs], iplot*1.5, str(snr[g]))\n",
    "                        plt.text(t[100*fs], iplot*1.5, x.stats.station)\n",
    "                        iplot = iplot+1\n",
    "\n",
    "                        stas.append(x.stats.station)\n",
    "                        SNR.append(snr[g])\n",
    "                    else:\n",
    "                        st.remove(x) #only want to work with z component channels with high SNR\n",
    "                        \n",
    "        \n",
    "                if len(st)>=4: #want events with enough waveforms to work with\n",
    "                    dist, pick_times, lats, lons, elevs, r, theta, Sta = ([] for i in range(8))\n",
    "                    for s in range(0, len(stas)):\n",
    "                        dist.append(df[df['Station'] == stas[s]]['Distance_from_volc'].values[0]) \n",
    "\n",
    "                    for key in data_env_dict:\n",
    "                        p = pick_time(data_env_dict[reference], data_env_dict[key]) #calculate picktimes\n",
    "                        pick_times.append(p)\n",
    "                   \n",
    "                    for i, ii in enumerate(stas):\n",
    "                        a = stations.index(ii)\n",
    "                        lats.append(latitudes[a])\n",
    "                        lons.append(longitudes[a])\n",
    "                        elevs.append(elevations[a])\n",
    "                    #calculating azimuth for each station with respect to the middle of the volcano\n",
    "                        lat2 = lats[i]\n",
    "                        lon2 = lons[i]\n",
    "                        lat1 = volc_lat\n",
    "                        lon1 = volc_lon\n",
    "                        u,b,c = (gps2dist_azimuth(lat1, lon1, lat2, lon2, a=6378137.0, f=0.0033528106647474805))\n",
    "                        r.append(u)\n",
    "                        theta.append(b)\n",
    "                        Sta.append(stas[i])\n",
    "                            \n",
    "                    #Get peak frequency of each event\n",
    "                    spectra_method = \"welch\"\n",
    "                    char_freq_method = \"mean\"\n",
    "                    # read and preprocess data\n",
    "                    st.filter(\"bandpass\",freqmin=low_cut,freqmax=high_cut)\n",
    "                    st.taper(max_percentage=0.01,max_length=20)\n",
    "                    st.trim(starttime=min(pick_times),endtime=min(pick_times)+20) \n",
    "                    \n",
    "                    # make plot of spectra\n",
    "                    colors = list(plt.cm.tab10(np.arange(10))) + [\"crimson\", \"indigo\", \"powderblue\", \"lime\"]\n",
    "                    char_freq, spectra_list, weight= [],[],[]\n",
    "                    for i in range(len(Sta)):\n",
    "                        try:\n",
    "                            data = st.select(station=Sta[i],component=\"Z\")[0].data*100\n",
    "                            a = 'stream is not empty'\n",
    "                        except:\n",
    "                            pass\n",
    "                        if a == 'stream is not empty':\n",
    "                            f,psd=scipy.signal.welch(data,fs=st[0].stats.sampling_rate,nperseg=81,noverlap=1)\n",
    "                            #just get the indices of frequencies within the filter band\n",
    "                            above_low_cut = [f>low_cut]\n",
    "                            below_high_cut = [f<high_cut]\n",
    "                            in_band = np.logical_and(above_low_cut,below_high_cut)[0]\n",
    "                            f = f[in_band]\n",
    "                            psd = psd[in_band]\n",
    "                            #weighting the data by the spikiness of the PSD vs frequency graphs\n",
    "                            ratio = (np.mean(psd)/np.max(psd))\n",
    "                            weight.append(int(1/(ratio**2)*20))\n",
    "\n",
    "\n",
    "                        # calculate characteristic frequency and report\n",
    "                            char_freq_max = f[np.argmax(psd)]\n",
    "                            char_freq_mean= np.sum(psd*f)/np.sum(psd)\n",
    "                            char_freq.append(char_freq_max)\n",
    "                            ymax=max(psd)\n",
    "                            \n",
    "\n",
    "                    if a == 'stream is not empty':\n",
    "                        #manipulating the data\n",
    "                        data = {'azimuth':theta, 'freq':char_freq, 'station':Sta, 'distance':dist, 'weight':weight, 'SNR':SNR}\n",
    "                        DF = pd.DataFrame(data, index = None)\n",
    "                        DF2 = DF.sort_values('azimuth')\n",
    "                        print(DF2)\n",
    "                        drops = []\n",
    "                        for i in range(len(DF2)):\n",
    "                            value = DF2.loc[i,'distance']\n",
    "                            if value < az_thr:\n",
    "                                drops.append(i)\n",
    "                        DF3 = DF2.drop(drops)\n",
    "                        print(DF3)\n",
    "                        \n",
    "                        y_data =  DF3[\"freq\"].values.tolist()\n",
    "                        #colors2 = DF2[\"color\"].values.tolist()\n",
    "                        Sta2 = DF3[\"station\"].values.tolist()\n",
    "                        dist2 = DF3[\"distance\"].values.tolist()\n",
    "                        weight2 = DF3[\"weight\"].values.tolist()\n",
    "                        SNR2 = DF3['SNR'].values.tolist()\n",
    "                        x_data =  np.asarray(DF3[\"azimuth\"].values.tolist())\n",
    "                        x_points = np.linspace(0,360, 100)\n",
    "                        \n",
    "                    #create figure showing effects of different weights on the data\n",
    "                        fig = plt.figure(figsize = (15,23), dpi=80)\n",
    "                        ax1 = plt.subplot(4,2,1)\n",
    "                        ax1.set_ylabel('characteristic frequency(Hz)')\n",
    "                        ax1.set_xlabel('azimuth(degrees)')\n",
    "                        for i in range (0,len(Sta2)):\n",
    "                            ax1.scatter(x_data[i], y_data[i], label=Sta2[i])\n",
    "                        ax1.plot(x_data,y_data, '--', label='rawdata')\n",
    "                        ax1.legend(loc='best')\n",
    "                        #optimizing parameters to fit data to test_function\n",
    "                        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(x_data), y_data, p0=None)\n",
    "                        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "                        fmax = max(d)\n",
    "                        fmin = min(d)\n",
    "                        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "                        ax1.set_title('Original'+str(v)+'m/s')\n",
    "                        ax1.plot(x_points, d, label='Fitted function')\n",
    "                        \n",
    "                        len_r = int(max(r))\n",
    "                        line_length = np.linspace(0,len_r,len_r+1)\n",
    "                        rads = np.arange(0, (2 *pi), 0.01)\n",
    "                        direction=[]\n",
    "                        direction = [(params[1]) for i in range(len_r+1)]\n",
    "                        \n",
    "                        ax5= plt.subplot(4,2,5, polar=True)\n",
    "                        ax5.set_title('Original'+str(v)+'m/s')\n",
    "                        ax5.set_theta_offset(pi/2)\n",
    "                        ax5.set_theta_direction(-1)\n",
    "                        for i in range(0,len(r)):\n",
    "                            ax5.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "                            ax5.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "                        ax5.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "                        for rad in rads:\n",
    "                            ax5.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "                        \n",
    "                        ax2 = plt.subplot(4,2,2)\n",
    "                        ax2.set_ylabel('characteristic frequency(Hz)')\n",
    "                        ax2.set_xlabel('azimuth(degrees)')\n",
    "                        for i in range (0,len(Sta2)):\n",
    "                            ax2.scatter(x_data[i], y_data[i], s = (weight2[i]**2)/35, label=Sta2[i])\n",
    "                        ax2.plot(x_data,y_data, '--', label='rawdata')\n",
    "                        ax2.legend(loc='best')\n",
    "                        #weighting the data\n",
    "                        tempx, tempy = [],[]\n",
    "                        for i,ii in enumerate(x_data):\n",
    "                            tempx.append([])\n",
    "                            tempx[i].append([ii for l in range(0,weight2[i])])\n",
    "                            tempy.append([])\n",
    "                            tempy[i].append([y_data[i] for l in range(0,weight2[i])])   \n",
    "                        weighted_x = sum(sum(tempx, []),[])\n",
    "                        weighted_y = sum(sum(tempy, []),[])\n",
    "                        #optimizing parameters to fit weighted data to test_function\n",
    "                        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "                        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "                        fmax = max(d)\n",
    "                        fmin = min(d)\n",
    "                        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "                        ax2.set_title('Spikiness'+str(v)+'m/s')\n",
    "                        ax2.plot(x_points, d, label='Fitted function')\n",
    "                        \n",
    "                        direction=[]\n",
    "                        direction = [(params[1]) for i in range(len_r+1)]\n",
    "                        \n",
    "                        ax6= plt.subplot(4,2,6, polar=True)\n",
    "                        ax6.set_title('Spikiness'+str(v)+'m/s')\n",
    "                        ax6.set_theta_offset(pi/2)\n",
    "                        ax6.set_theta_direction(-1)\n",
    "                        for i in range(0,len(r)):\n",
    "                            ax6.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "                            ax6.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "                        ax6.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "                        for rad in rads:\n",
    "                            ax6.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "                        \n",
    "                        ax3 = plt.subplot(4,2,3)\n",
    "                        ax3.set_ylabel('characteristic frequency(Hz)')\n",
    "                        ax3.set_xlabel('azimuth(degrees)')\n",
    "                        ax3.plot(x_data,y_data, '--', label='rawdata')\n",
    "                        ax3.legend(loc='best')\n",
    "                        #weighting the data\n",
    "                        tempx, tempy, weight = [],[],[]\n",
    "                        for i,ii in enumerate(x_data):\n",
    "                            weight.append(int(1/(dist2[i]**2)*1000))\n",
    "                            tempx.append([])\n",
    "                            tempx[i].append([ii for l in range(0,weight[i])])\n",
    "                            tempy.append([])\n",
    "                            tempy[i].append([y_data[i] for l in range(0,weight[i])])   \n",
    "                        weighted_x = sum(sum(tempx, []),[])\n",
    "                        weighted_y = sum(sum(tempy, []),[])\n",
    "                        for i in range (0,len(Sta2)):\n",
    "                            ax3.scatter(x_data[i], y_data[i], s = (weight[i]**2/10),label=Sta2[i])\n",
    "                        #optimizing parameters to fit weighted data to test_function\n",
    "                        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "                        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "                        fmax = max(d)\n",
    "                        fmin = min(d)\n",
    "                        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "                        ax3.set_title('Distance from volcano'+str(v)+'m/s')\n",
    "                        ax3.plot(x_points, d, label='Fitted function')\n",
    "                        \n",
    "                        direction=[]\n",
    "                        direction = [(params[1]) for i in range(len_r+1)]\n",
    "                        \n",
    "                        ax7= plt.subplot(4,2,7, polar=True)\n",
    "                        ax7.set_title('Distance from volcano'+str(v)+'m/s')\n",
    "                        ax7.set_theta_offset(pi/2)\n",
    "                        ax7.set_theta_direction(-1)\n",
    "                        for i in range(0,len(r)):\n",
    "                            ax7.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "                            ax7.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "                        ax7.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "                        for rad in rads:\n",
    "                            ax7.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "                        ax4 = plt.subplot(4,2,4)\n",
    "                        ax4.set_ylabel('characteristic frequency(Hz)')\n",
    "                        ax4.set_xlabel('azimuth(degrees)')\n",
    "                        ax4.plot(x_data,y_data, '--', label='rawdata')\n",
    "                        ax4.legend(loc='best')\n",
    "                        #weighting the data\n",
    "                        tempx, tempy, weight = [],[],[]\n",
    "                        for i,ii in enumerate(x_data):\n",
    "                            weight.append(int(SNR[i]))\n",
    "                            tempx.append([])\n",
    "                            tempx[i].append([ii for l in range(0,weight[i])])\n",
    "                            tempy.append([])\n",
    "                            tempy[i].append([y_data[i] for l in range(0,weight[i])])   \n",
    "                        weighted_x = sum(sum(tempx, []),[])\n",
    "                        weighted_y = sum(sum(tempy, []),[])\n",
    "                        for i in range (0,len(Sta2)):\n",
    "                            ax4.scatter(x_data[i], y_data[i], s = (weight[i]**2),label=Sta2[i])\n",
    "                        #optimizing parameters to fit weighted data to test_function\n",
    "                        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "                        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "                        fmax = max(d)\n",
    "                        fmin = min(d)\n",
    "                        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "                        ax4.set_title('SNR'+str(v)+'m/s')\n",
    "                        ax4.plot(x_points, d, label='Fitted function')\n",
    "                        \n",
    "                        direction=[]\n",
    "                        direction = [(params[1]) for i in range(len_r+1)]\n",
    "                        \n",
    "                        ax8= plt.subplot(4,2,8, polar=True)\n",
    "                        ax8.set_title('SNR'+str(v)+'m/s')\n",
    "                        ax8.set_theta_offset(pi/2)\n",
    "                        ax8.set_theta_direction(-1)\n",
    "                        for i in range(0,len(r)):\n",
    "                            ax8.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "                            ax8.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "                        ax8.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "                        for rad in rads:\n",
    "                            ax8.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "                        \n",
    "                        plt.savefig('evtID:UW'+ event_ID+associated_volcano+'weights.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0788d24",
   "metadata": {},
   "source": [
    "## Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f3f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "#lats used for travel_time_table?\n",
    "#lons\n",
    "#d = pick_times\n",
    "#t = origin time\n",
    "\n",
    "#want:\n",
    "    #X = (lat,lon,0) (location of the event)\n",
    "    \n",
    "# d = t+T(X)+e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84d48b",
   "metadata": {},
   "source": [
    "## 2014 events during temporary XD stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c4c1d",
   "metadata": {},
   "source": [
    "# Mount St Helens Event 5/14/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in Stream Data\n",
    "bulk = []\n",
    "associated_volcano = 'Mt_St_Helens'\n",
    "t = UTCDateTime(2021,2,3,5,43)\n",
    "event_ID = '??'\n",
    "reference = 'CC.SEP'\n",
    "\n",
    "networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "volc_lat = 46.200472222222224 #volc_lat_lon[associated_volcano][0]\n",
    "volc_lon =-122.18883611111112 #volc_lat_lon[associated_volcano][1]\n",
    "\n",
    "for m in range(0, len(networks)):\n",
    "    bulk.append([networks[m], stations[m], '*', '*', t-t_before, t+t_after])\n",
    "st = client2.get_waveforms_bulk(bulk)\n",
    "print(st.__str__(extended=True))\n",
    "for tr in st:\n",
    "    if tr.stats.channel[0:2] != 'BH' and tr.stats.channel[0:2] != 'EH' and tr.stats.channel[0:2] != 'HH':\n",
    "            st.remove(tr)\n",
    "            continue\n",
    "    if len(tr.data)/tr.stats.sampling_rate < 239.9:\n",
    "        st.remove(tr)\n",
    "st = resample(st,fs) \n",
    "\n",
    "for i in st:\n",
    "    if i.stats.station == 'ASR':\n",
    "        st.remove(i)\n",
    "        \n",
    "#Plotting all traces for one event with channel z, SNR>7, and bandpasses between 2-12Hz\n",
    "snr, SNR, stas, data_env_dict = [], [], [],{}\n",
    "\n",
    "fig = plt.figure(figsize = (20,50), dpi=80)\n",
    "plt.subplots_adjust(hspace = .4)\n",
    "fig.suptitle('evtID:UW'+ event_ID+associated_volcano)\n",
    "\n",
    "ax1 = plt.subplot(4,1,1)\n",
    "iplot = 0\n",
    "for g,x in enumerate(st):\n",
    "    t = x.times()\n",
    "    x.detrend(type = 'demean')\n",
    "    x.filter('bandpass',freqmin=2.0,freqmax=12.0,corners=2,zerophase=True)\n",
    "    network = x.stats.network\n",
    "    station = x.stats.station\n",
    "    cha = x.stats.channel\n",
    "    starttime = x.stats.starttime\n",
    "    smooth_length = 2*fs\n",
    "\n",
    "    signal_window = x.copy()\n",
    "    noise_window = x.copy()\n",
    "    #TODO: fix signal window to be around the max amplitude\n",
    "    signal_window.trim(starttime+t_before-1, starttime+t_before-1+window)\n",
    "    noise_window.trim(starttime-window+t_before-10, starttime+t_before-10)\n",
    "\n",
    "    snr.append(20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                   / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "\n",
    "    if cha[-1] == 'Z' and snr[g]>thr:\n",
    "        #enveloping the data to calculate picktimes later on\n",
    "        data_envelope = obspy.signal.filter.envelope(x.data[110*fs:140*fs])\n",
    "        data_envelope /= np.max(data_envelope)\n",
    "        data_envelope += iplot*1.5\n",
    "        data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "        data_env_dict[network+'.'+station]= data_envelope\n",
    "\n",
    "        ax1.plot(t[100*fs:175*fs],x.data[100*fs:175*fs]/np.max(np.abs(x.data))+iplot*1.5)\n",
    "        ax1.plot(t[110*fs:140*fs], data_envelope, color = 'k')\n",
    "        ax1.set_xlabel('time (seconds)')\n",
    "        ax1.set_xlim([100,175])\n",
    "        plt.text(t[175*fs], iplot*1.5, str(snr[g]))\n",
    "        plt.text(t[100*fs], iplot*1.5, x.stats.station)\n",
    "        iplot = iplot+1\n",
    "\n",
    "        stas.append(x.stats.station)\n",
    "        SNR.append(snr[g])\n",
    "    else:\n",
    "        st.remove(x) #only want to work with z component channels with high SNR\n",
    "\n",
    "\n",
    "if len(st)>=4: #want events with enough waveforms to work with\n",
    "    dist, pick_times, lats, lons, elevs, r, theta, Sta = ([] for i in range(8))\n",
    "    for s in range(0, len(stas)):\n",
    "        dist.append(df[df['Station'] == stas[s]]['Distance_from_volc'].values[0]) \n",
    "\n",
    "    for key in data_env_dict:\n",
    "        p = pick_time(data_env_dict[reference], data_env_dict[key]) #calculate picktimes\n",
    "        pick_times.append(p)\n",
    "\n",
    "    for i, ii in enumerate(stas):\n",
    "        a = stations.index(ii)\n",
    "        lats.append(latitudes[a])\n",
    "        lons.append(longitudes[a])\n",
    "        elevs.append(elevations[a])\n",
    "    #calculating azimuth for each station with respect to the middle of the volcano\n",
    "        lat2 = lats[i]\n",
    "        lon2 = lons[i]\n",
    "        lat1 = volc_lat\n",
    "        lon1 = volc_lon\n",
    "        u,b,c = (gps2dist_azimuth(lat1, lon1, lat2, lon2, a=6378137.0, f=0.0033528106647474805))\n",
    "        r.append(u)\n",
    "        theta.append(b)\n",
    "        Sta.append(stas[i])\n",
    "\n",
    "    #Get peak frequency of each event\n",
    "    spectra_method = \"welch\"\n",
    "    char_freq_method = \"mean\"\n",
    "    # read and preprocess data\n",
    "    st.filter(\"bandpass\",freqmin=low_cut,freqmax=high_cut)\n",
    "    st.taper(max_percentage=0.01,max_length=20)\n",
    "    st.trim(starttime=min(pick_times),endtime=min(pick_times)+20) \n",
    "\n",
    "    # make plot of spectra\n",
    "    colors = list(plt.cm.tab10(np.arange(10))) + [\"crimson\", \"indigo\", \"powderblue\", \"lime\"]\n",
    "    char_freq, spectra_list, weight= [],[],[]\n",
    "    for i in range(len(Sta)):\n",
    "        try:\n",
    "            data = st.select(station=Sta[i],component=\"Z\")[0].data*100\n",
    "            a = 'stream is not empty'\n",
    "        except:\n",
    "            pass\n",
    "        if a == 'stream is not empty':\n",
    "            f,psd=scipy.signal.welch(data,fs=st[0].stats.sampling_rate,nperseg=81,noverlap=1)\n",
    "            #just get the indices of frequencies within the filter band\n",
    "            above_low_cut = [f>low_cut]\n",
    "            below_high_cut = [f<high_cut]\n",
    "            in_band = np.logical_and(above_low_cut,below_high_cut)[0]\n",
    "            f = f[in_band]\n",
    "            psd = psd[in_band]\n",
    "            #weighting the data by the spikiness of the PSD vs frequency graphs\n",
    "            ratio = (np.mean(psd)/np.max(psd))\n",
    "            weight.append(int(1/(ratio**2)*20))\n",
    "\n",
    "\n",
    "        # calculate characteristic frequency and report\n",
    "            char_freq_max = f[np.argmax(psd)]\n",
    "            char_freq_mean= np.sum(psd*f)/np.sum(psd)\n",
    "            char_freq.append(char_freq_max)\n",
    "            ymax=max(psd)\n",
    "\n",
    "\n",
    "    if a == 'stream is not empty':\n",
    "        #manipulating the data\n",
    "        data = {'azimuth':theta, 'freq':char_freq, 'station':Sta, 'distance':dist, 'weight':weight, 'SNR':SNR}\n",
    "        DF = pd.DataFrame(data, index = None)\n",
    "        DF2 = DF.sort_values('azimuth')\n",
    "        print(DF2)\n",
    "        drops = []\n",
    "        for i in range(len(DF2)):\n",
    "            value = DF2.loc[i,'distance']\n",
    "            if value < az_thr:\n",
    "                drops.append(i)\n",
    "        DF3 = DF2.drop(drops)\n",
    "        print(DF3)\n",
    "\n",
    "        y_data =  DF3[\"freq\"].values.tolist()\n",
    "        #colors2 = DF2[\"color\"].values.tolist()\n",
    "        Sta2 = DF3[\"station\"].values.tolist()\n",
    "        dist2 = DF3[\"distance\"].values.tolist()\n",
    "        weight2 = DF3[\"weight\"].values.tolist()\n",
    "        SNR2 = DF3['SNR'].values.tolist()\n",
    "        x_data =  np.asarray(DF3[\"azimuth\"].values.tolist())\n",
    "        x_points = np.linspace(0,360, 100)\n",
    "\n",
    "    #create figure showing effects of different weights on the data\n",
    "        fig = plt.figure(figsize = (15,30), dpi=80)\n",
    "        ax1 = plt.subplot(4,2,1)\n",
    "        ax1.set_ylabel('characteristic frequency(Hz)')\n",
    "        ax1.set_xlabel('azimuth(degrees)')\n",
    "        for i in range (0,len(Sta2)):\n",
    "            ax1.scatter(x_data[i], y_data[i], label=Sta2[i])\n",
    "        ax1.plot(x_data,y_data, '--', label='rawdata')\n",
    "        ax1.legend(loc='best')\n",
    "        #optimizing parameters to fit data to test_function\n",
    "        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(x_data), y_data, p0=None)\n",
    "        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "        fmax = max(d)\n",
    "        fmin = min(d)\n",
    "        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "        ax1.set_title('Original')#+str(v)+'m/s')\n",
    "        ax1.plot(x_points, d, label='Fitted function')\n",
    "\n",
    "        len_r = int(max(r))\n",
    "        line_length = np.linspace(0,len_r,len_r+1)\n",
    "        rads = np.arange(0, (2 *pi), 0.01)\n",
    "        direction=[]\n",
    "        direction = [(params[1]) for i in range(len_r+1)]\n",
    "\n",
    "        ax5= plt.subplot(4,2,5, polar=True)\n",
    "        ax5.set_title('Original')#+str(v)+'m/s')\n",
    "        ax5.set_theta_offset(pi/2)\n",
    "        ax5.set_theta_direction(-1)\n",
    "        for i in range(0,len(r)):\n",
    "            ax5.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "            ax5.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "        ax5.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "        for rad in rads:\n",
    "            ax5.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "\n",
    "        ax2 = plt.subplot(4,2,2)\n",
    "        ax2.set_ylabel('characteristic frequency(Hz)')\n",
    "        ax2.set_xlabel('azimuth(degrees)')\n",
    "        for i in range (0,len(Sta2)):\n",
    "            ax2.scatter(x_data[i], y_data[i], s = (weight2[i]**2)/35, label=Sta2[i])\n",
    "        ax2.plot(x_data,y_data, '--', label='rawdata')\n",
    "        ax2.legend(loc='best')\n",
    "        #weighting the data\n",
    "        tempx, tempy = [],[]\n",
    "        for i,ii in enumerate(x_data):\n",
    "            tempx.append([])\n",
    "            tempx[i].append([ii for l in range(0,weight2[i])])\n",
    "            tempy.append([])\n",
    "            tempy[i].append([y_data[i] for l in range(0,weight2[i])])   \n",
    "        weighted_x = sum(sum(tempx, []),[])\n",
    "        weighted_y = sum(sum(tempy, []),[])\n",
    "        #optimizing parameters to fit weighted data to test_function\n",
    "        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "        fmax = max(d)\n",
    "        fmin = min(d)\n",
    "        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "        ax2.set_title('Spikiness')#+str(v)+'m/s')\n",
    "        ax2.plot(x_points, d, label='Fitted function')\n",
    "\n",
    "        direction=[]\n",
    "        direction = [(params[1]) for i in range(len_r+1)]\n",
    "\n",
    "        ax6= plt.subplot(4,2,6, polar=True)\n",
    "        ax6.set_title('Spikiness')#+str(v)+'m/s')\n",
    "        ax6.set_theta_offset(pi/2)\n",
    "        ax6.set_theta_direction(-1)\n",
    "        for i in range(0,len(r)):\n",
    "            ax6.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "            ax6.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "        ax6.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "        for rad in rads:\n",
    "            ax6.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "        ax3 = plt.subplot(4,2,3)\n",
    "        ax3.set_ylabel('characteristic frequency(Hz)')\n",
    "        ax3.set_xlabel('azimuth(degrees)')\n",
    "        ax3.plot(x_data,y_data, '--', label='rawdata')\n",
    "        ax3.legend(loc='best')\n",
    "        #weighting the data\n",
    "        tempx, tempy, weight = [],[],[]\n",
    "        for i,ii in enumerate(x_data):\n",
    "            weight.append(int(1/(dist2[i]**2)*1000))\n",
    "            tempx.append([])\n",
    "            tempx[i].append([ii for l in range(0,weight[i])])\n",
    "            tempy.append([])\n",
    "            tempy[i].append([y_data[i] for l in range(0,weight[i])])   \n",
    "        weighted_x = sum(sum(tempx, []),[])\n",
    "        weighted_y = sum(sum(tempy, []),[])\n",
    "        for i in range (0,len(Sta2)):\n",
    "            ax3.scatter(x_data[i], y_data[i], s = (weight[i]**2/10),label=Sta2[i])\n",
    "        #optimizing parameters to fit weighted data to test_function\n",
    "        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "        fmax = max(d)\n",
    "        fmin = min(d)\n",
    "        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "        ax3.set_title('Distance from volcano')#+str(v)+'m/s')\n",
    "        ax3.plot(x_points, d, label='Fitted function')\n",
    "\n",
    "        direction=[]\n",
    "        direction = [(params[1]) for i in range(len_r+1)]\n",
    "\n",
    "        ax7= plt.subplot(4,2,7, polar=True)\n",
    "        ax7.set_title('Distance from volcano')#+str(v)+'m/s')\n",
    "        ax7.set_theta_offset(pi/2)\n",
    "        ax7.set_theta_direction(-1)\n",
    "        for i in range(0,len(r)):\n",
    "            ax7.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "            ax7.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "        ax7.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "        for rad in rads:\n",
    "            ax7.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "        ax4 = plt.subplot(4,2,4)\n",
    "        ax4.set_ylabel('characteristic frequency(Hz)')\n",
    "        ax4.set_xlabel('azimuth(degrees)')\n",
    "        ax4.plot(x_data,y_data, '--', label='rawdata')\n",
    "        ax4.legend(loc='best')\n",
    "        #weighting the data\n",
    "        tempx, tempy, weight = [],[],[]\n",
    "        for i,ii in enumerate(x_data):\n",
    "            weight.append(int(SNR[i]))\n",
    "            tempx.append([])\n",
    "            tempx[i].append([ii for l in range(0,weight[i])])\n",
    "            tempy.append([])\n",
    "            tempy[i].append([y_data[i] for l in range(0,weight[i])])   \n",
    "        weighted_x = sum(sum(tempx, []),[])\n",
    "        weighted_y = sum(sum(tempy, []),[])\n",
    "        for i in range (0,len(Sta2)):\n",
    "            ax4.scatter(x_data[i], y_data[i], s = (weight[i]**2),label=Sta2[i])\n",
    "        #optimizing parameters to fit weighted data to test_function\n",
    "        params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(weighted_x), weighted_y, p0=None)\n",
    "        d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "        fmax = max(d)\n",
    "        fmin = min(d)\n",
    "        v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "        ax4.set_title('SNR')#+str(v)+'m/s')\n",
    "        ax4.plot(x_points, d, label='Fitted function')\n",
    "\n",
    "        direction=[]\n",
    "        direction = [(params[1]) for i in range(len_r+1)]\n",
    "\n",
    "        ax8= plt.subplot(4,2,8, polar=True)\n",
    "        ax8.set_title('SNR')#+str(v)+'m/s')\n",
    "        ax8.set_theta_offset(pi/2)\n",
    "        ax8.set_theta_direction(-1)\n",
    "        for i in range(0,len(r)):\n",
    "            ax8.plot(np.deg2rad(theta[i]),r[i], 'g.')\n",
    "            ax8.text(np.deg2rad(theta[i]),r[i],stas[i]) \n",
    "        ax8.plot(direction,line_length, 'k-')  #plot the estimated direction of the event\n",
    "        for rad in rads:\n",
    "            ax8.plot(rad,az_thr, 'b.', markersize = 2)\n",
    "\n",
    "\n",
    "        #plt.savefig('evtID:UW'+ event_ID+associated_volcano+'weights.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
