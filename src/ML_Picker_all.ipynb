{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0f6cb81",
   "metadata": {},
   "source": [
    "# Surface Event Pick Time\n",
    "\n",
    "This is a modified version of the surface-event location+directivity analysis that Francesca Skene ( fskene@uw.edu), originally created by her in 7/22/22, who started as an undergraduate student at UW. This is marine denolle's version. It includes:\n",
    "* Waveform download for each event on each volcano given the PNSN pick times of \"su\" events.\n",
    "* Data pre-processing to trim the data within 2-12 Hz and remove outliers.\n",
    "* phase picking using transfer-learned model (Ni et al, 2023)\n",
    "* event location using 1D grid search\n",
    "* directivity measurements (velocity and direction) using Doppler effects.\n",
    "* gathering of the data into a CSV data frame.\n",
    "\n",
    "Updated 01/24/2024\n",
    "Marine Denolle\n",
    "(mdenolle@uw.edu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7021dc6f",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf759fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/data/wsd01/pnwstore/')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import obspy\n",
    "from obspy.core import UTCDateTime\n",
    "from obspy.clients.fdsn.client import Client\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from geopy import distance\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "from mbf_elep_func import *\n",
    "import torch\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "\n",
    "import seisbench.models as sbm\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "# from ELEP.elep.ensemble_learners import ensemble_regressor_cnn\n",
    "from ELEP.elep import mbf, mbf_utils\n",
    "from ELEP.elep import trigger_func\n",
    "\n",
    "from ELEP.elep.mbf_utils import make_LogFq, make_LinFq, rec_filter_coeff, create_obspy_trace\n",
    "from ELEP.elep.mbf import MB_filter as MBF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd30de3d",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c32de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define clients to download the station data\n",
    "# client = WaveformClient() # we ignore PNWdatastore for now\n",
    "client2 = Client('IRIS')\n",
    "\n",
    "t_before = 15 #number of seconds before pick time\n",
    "# t_after = 15 #number of seconds after pick time\n",
    "t_before_raw = 1200 #number of seconds before pick time before removing instrumental response\n",
    "# t_after_raw = 1200 #number of seconds after pick time before removing instrumental response\n",
    "fs = 40 #sampling rate that all waveforms are resampled to\n",
    "window = 150 #window length of the signal (this will help with phase picking with EqT next). \n",
    "# Use 150 seconds @ 40 Hz gives 6001 points. \n",
    "pr = 98 #percentile\n",
    "thr = 5 #SNR threshold\n",
    "station_distance_threshold = 25\n",
    "pi = np.pi\n",
    "v_s = 1000 #shear wave velocity at the surface\n",
    "\n",
    "# range of dates that we are looking at\n",
    "t_beginning = UTCDateTime(2001,1,1,0,0,0) \n",
    "t_end = UTCDateTime(2023,8,2,23,59)\n",
    "\n",
    "smooth_length = 5 # constant for smoothing the waveform envelopes\n",
    "low_cut = 1 #low frequency threshold\n",
    "high_cut = 12 #high frequency threshold\n",
    "# az_thr = 1000 #threshold of distance in meters from source location\n",
    "# step = 100 #step every 100 m\n",
    "# t_step = 1 #step every second\n",
    "# ratio = 5.6915196 #used to define the grid \n",
    "# colors = list(plt.cm.tab10(np.arange(10)))*3\n",
    "# radius = 6371e3 # radius of the earth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4db39e",
   "metadata": {},
   "source": [
    "## Volcano - Station Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5ede0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data includes all stations within 50km of each volcano and the lat, lon, elev of each station\n",
    "df = pd.read_csv('../data/station/Volcano_Metadata_50km.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b021322",
   "metadata": {},
   "source": [
    "## PNSN SU Pick information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb1d9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'net', 'sta', 'location', 'seedchan', 'iphase', 'quality',\n",
      "       'orid', 'etype', 'evid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "f1 = pd.read_csv(\"../data/events/su_picks.txt\",sep=\"|\")\n",
    "f1.head()\n",
    "print(f1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7c63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the spaces in the file\n",
    "format='%Y/%m/%d %H:%M:%S'\n",
    "test=f1[\"date\"].values.tolist()\n",
    "start_time_temp = [  datetime.strptime(x.strip(),'%Y/%m/%d %H:%M:%S') for x in f1[\"date\"].values.tolist()]\n",
    "# # Ignore events prior to t_beginning\n",
    "ik=np.where(np.array(start_time_temp)>datetime(2001,1,1))[0][0]\n",
    "\n",
    "# select only net, sta, evid, startime for event past the start date.\n",
    "\n",
    "start_time = start_time_temp[ik:]\n",
    "net=[ x.strip() for x in f1[\"net\"].values.tolist()][ik:]\n",
    "sta=[ x.strip() for x in f1[\"sta\"].values.tolist()][ik:]\n",
    "evt_id=[ x for x in f1[\"orid\"].values.tolist()][ik:]\n",
    "all_stas=set(sta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20c89405",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fb0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"/Users/marinedenolle/.seisbench/models/v3/eqtransformer\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba4eaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-26 11:33:55--  https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/pnw.pt.v1\n",
      "Resolving github.com (github.com)... 20.29.134.23\n",
      "Connecting to github.com (github.com)|20.29.134.23|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/congcy/ELEP/main/docs/tutorials/data/pnw.pt.v1 [following]\n",
      "--2024-01-26 11:33:55--  https://raw.githubusercontent.com/congcy/ELEP/main/docs/tutorials/data/pnw.pt.v1\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1592020 (1.5M) [application/octet-stream]\n",
      "Saving to: ‘/Users/marinedenolle/.seisbench/models/v3/eqtransformer/pnw.pt.v1’\n",
      "\n",
      "/Users/marinedenoll 100%[===================>]   1.52M  9.53MB/s    in 0.2s    \n",
      "\n",
      "2024-01-26 11:33:55 (9.53 MB/s) - ‘/Users/marinedenolle/.seisbench/models/v3/eqtransformer/pnw.pt.v1’ saved [1592020/1592020]\n",
      "\n",
      "--2024-01-26 11:33:56--  https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/pnw.json.v1\n",
      "Resolving github.com (github.com)... 20.29.134.23\n",
      "Connecting to github.com (github.com)|20.29.134.23|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/congcy/ELEP/main/docs/tutorials/data/pnw.json.v1 [following]\n",
      "--2024-01-26 11:33:56--  https://raw.githubusercontent.com/congcy/ELEP/main/docs/tutorials/data/pnw.json.v1\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 599 [text/plain]\n",
      "Saving to: ‘/Users/marinedenolle/.seisbench/models/v3/eqtransformer/pnw.json.v1’\n",
      "\n",
      "/Users/marinedenoll 100%[===================>]     599  --.-KB/s    in 0s      \n",
      "\n",
      "2024-01-26 11:33:56 (43.9 MB/s) - ‘/Users/marinedenolle/.seisbench/models/v3/eqtransformer/pnw.json.v1’ saved [599/599]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/pnw.pt.v1 -O ~/.seisbench/models/v3/eqtransformer/pnw.pt.v1\n",
    "!wget https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/pnw.json.v1 -O ~/.seisbench/models/v3/eqtransformer/pnw.json.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad86f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download models\n",
    "list_models_name = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "# pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")\n",
    "\n",
    "list_models = [pn_pnw_model, pn_ethz_model, pn_instance_model, pn_scedc_model, pn_stead_model, pn_geofon_model]\n",
    "\n",
    "pn_pnw_model.to(device);\n",
    "pn_ethz_model.to(device);\n",
    "pn_scedc_model.to(device);\n",
    "# pn_neic_model.to(device);\n",
    "pn_geofon_model.to(device);\n",
    "pn_stead_model.to(device);\n",
    "pn_instance_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4947da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_semblance = {'dt':0.025, 'semblance_order':4, 'window_flag':True, \n",
    "                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "p_thrd, s_thrd = 0.01, 0.05\n",
    "\n",
    "fqmin = low_cut\n",
    "fqmax = high_cut\n",
    "dt = 0.025; fs = 40\n",
    "nfqs = 10\n",
    "nt = 6000; nc = 3\n",
    "fq_list = make_LogFq(fqmin, fqmax, dt, nfqs)\n",
    "coeff_HP, coeff_LP = rec_filter_coeff(fq_list, dt)\n",
    "MBF_paras = {'f_min':fqmin, 'f_max':fqmax, 'nfqs':nfqs, 'frequencies':fq_list, 'CN_HP':coeff_HP, 'CN_LP':coeff_LP, \\\n",
    "    'dt':dt, 'fs':fs, 'nt':nt, 'nc':nc, 'npoles': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605be24",
   "metadata": {},
   "source": [
    "# Pick waveforms\n",
    "\n",
    "In step, we repick all the waveforms, including those already picked by the network analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "075da112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  58 stations at Mt_Rainier\n",
      "3247953 2023-11-05T07:05:01.000000Z\n",
      "(1654,)\n",
      "there are  58 stations at Mt_Rainier\n",
      "3248053 2023-11-07T10:09:49.000000Z\n",
      "(6001,)\n",
      "there are  58 stations at Mt_Rainier\n",
      "3248248 2023-11-08T23:16:43.000000Z\n",
      "(6001,)\n",
      "there are  58 stations at Mt_Rainier\n",
      "3248253 2023-11-08T23:21:31.000000Z\n",
      "(6001,)\n",
      "there are  58 stations at Mt_Rainier\n",
      "3248258 2023-11-08T23:24:03.000000Z\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "# pdf = PdfPages('../plots/MLPicks_test.pdf')\n",
    "associated_volcano = \"Mt_Rainier\"\n",
    "for n in range(len(evt_id)): \n",
    "    if start_time[n]<datetime(2023,11,1):continue   \n",
    "    event_ID = str(evt_id[n])\n",
    "    otime = UTCDateTime(start_time[n])\n",
    "    networks=net[n]\n",
    "    stations=sta[n]\n",
    "    if sta[n]==\"LON\" or sta[n]==\"LO2\":continue\n",
    "    # print(net[n],sta[n])\n",
    "    try:\n",
    "        associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "    except: \n",
    "        pass\n",
    "    if associated_volcano!=\"Mt_Rainier\":continue\n",
    "\n",
    "\n",
    "    #get info for stations within 50km of volcano that event ocurred at\n",
    "    stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "    networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "    latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "    longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "    elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "\n",
    "    print(\"there are \",len(stations),\"stations at\",associated_volcano)           \n",
    "    print(event_ID,otime)\n",
    "\n",
    "#################### WAVEFORM DOWNLOAD #######################\n",
    "    #Download all waveforms for that event based on stations and times\n",
    "    bulk = [] \n",
    "    for m in range(0, len(networks)):\n",
    "        bulk.append([networks[m], stations[m], '*', '*Z', otime-t_before_raw, otime+t_before_raw])\n",
    "    try:\n",
    "        st = client2.get_waveforms_bulk(bulk)\n",
    "        if (len(st))<3:continue # if there are fewer than 3 stations, skip the event\n",
    "        st = resample(st,fs)  #resampling the data to 40Hz for each trace\n",
    "\n",
    "        evt_data = obspy.Stream()\n",
    "        snr=[]\n",
    "        stas=[]\n",
    "        nets=[]\n",
    "        centroid_time = []\n",
    "\n",
    "        # #Keeping all traces for one event with channel z, SNR>10, and bandpassed between 2-12Hz\n",
    "        # ,nets,max_amp_times,durations,data_env_dict,t_diff = [],[],[],[],[],[],[],{},{}\n",
    "        for i,ii in enumerate(st):\n",
    "            ii.detrend(type = 'demean')\n",
    "            ii.filter('bandpass',freqmin=low_cut,freqmax=high_cut,corners=2,zerophase=True)\n",
    "            # trim the data and noise window to exactly 6000 points\n",
    "            signal_window = ii.copy()\n",
    "            noise_window = ii.copy()\n",
    "            signal_window.trim(otime - t_before, otime - t_before + window) # trim the signal at the first pick time of the PNSN data, with loose 40s before\n",
    "            noise_window.trim(otime - window -t_before, otime - t_before) # noise window of the same length\n",
    "            if not len(signal_window.data) or not len(signal_window.data): continue # skip if no data\n",
    "            \n",
    "            # if not np.percentile(np.abs(signal_window.data),pr):continue # skip if max amplitude is zero\n",
    "            snr1 = (20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                            / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "            # print(snr1)\n",
    "            # print(snr,max_amp_time)\n",
    "            # signal_window.plot()x\n",
    "            if snr1<thr: # and 100<max_amp_time<200:\n",
    "                st.remove(ii)\n",
    "                continue\n",
    "            \n",
    "            ############# Calculate envelope of the signal and pick centroid ############\n",
    "\n",
    "################# ENVELOPE AND CENTROID #######################\n",
    "            # enveloping the data \n",
    "            data_envelope = obspy.signal.filter.envelope(signal_window.data)\n",
    "            data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "            data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "            print(data_envelope.shape)\n",
    "            # finding the time of max amplitude of each event\n",
    "            # signal_window is windowed at otime-t_v before the PNSN pick time\n",
    "            print(np.abs(data_envelope))\n",
    "            # crap = np.maxarg(np.abs(data_envelope))[0]+t_before # time of max amplitude relative to otime\n",
    "            # centroid_time.append(crap)\n",
    "            # max_amp = np.max(ii.data)                 \n",
    "            # centroid_time.append(0)\n",
    "\n",
    "\n",
    "            stas.append(ii.stats.station)\n",
    "            nets.append(ii.stats.network)\n",
    "            snr.append(snr1)\n",
    "            evt_data.append(signal_window)\n",
    "        print(stas)\n",
    "        if len(stas)<3:continue\n",
    "        break\n",
    "\n",
    "    ################### ELEP #######################\n",
    "        sta_available,ind = np.unique(np.array(stas),return_index=True)\n",
    "        sta_available=sta_available[np.argsort(ind)]\n",
    "        bigS = np.zeros(shape=(len(sta_available),3,6000))\n",
    "        newstas=[]\n",
    "        for i in range(len(sta_available)):\n",
    "            stream = evt_data.select(station=sta_available[i])\n",
    "            if len(stream[0].data)<6000:continue\n",
    "            if len(stream)<3:\n",
    "                # copy stream to 2 components, zero the missing data.\n",
    "                tr3 = stream[0].copy() # assumed to be the vertical\n",
    "                tr2 = stream[0].copy();tr2.stats.channel=stream[0].stats.channel[0:2]+\"N\"\n",
    "                tr1 = stream[0].copy();tr1.stats.channel=stream[0].stats.channel[0:2]+\"E\"\n",
    "                tr1.data=np.zeros(len(stream[0].data))\n",
    "                tr2.data=np.zeros(len(stream[0].data))\n",
    "                stream=obspy.Stream(traces=[tr1,tr2,tr3])\n",
    "            # convert Stream into seisbench-friendly array    \n",
    "            # fill in big array and order data ZNE\n",
    "            bigS[i,0,:]=stream[2].data[:-1]\n",
    "            bigS[i,1,:]=stream[1].data[:-1]\n",
    "            bigS[i,2,:]=stream[0].data[:-1]\n",
    "            newstas.append(sta_available[i])\n",
    "        # pre process the data\n",
    "        crap2  = bigS.copy()\n",
    "        crap2 -= np.mean(crap2,axis=-1,keepdims=True) # demean data\n",
    "        # original use std norm\n",
    "        data_std = crap2 / np.std(crap2) + 1e-10\n",
    "        # could use max data\n",
    "        mmax= np.max(np.abs(crap2), axis=-1, keepdims=True)\n",
    "        data_max = np.divide(crap2 ,mmax,out=np.zeros_like(crap2),where=mmax!=0)\n",
    "\n",
    "            # test the new function\n",
    "        smb_peak= apply_elep(evt_data, newstas, \\\n",
    "                list_models, MBF_paras, paras_semblance, t_before)\n",
    "        if not max(smb_peak.shape):continue\n",
    "\n",
    "\n",
    "################ SAVE PICKS ##############################\n",
    "        # print(otime)\n",
    "        # print(\"net,stas,snr,picks from ELEP,centroid pick time\")\n",
    "        for i in len(stas):\n",
    "                print(nets[i],stas[i],snr[i],smb_peak[i]-t_before,centroid_time[i])\n",
    "\n",
    "        # print(smb_peak-t_before) # this is the difference between the pick time and the PNSN pick time\n",
    "        break\n",
    "\n",
    "        # pick_mse[n] = np.sqrt(np.sum(smb_peak[:]-t_before)**2/len(stas))\n",
    "        # pick_mae[n] = np.sum(np.abs(smb_peak[:]-t_before))/len(stas)\n",
    "\n",
    "            ## plot figure\n",
    "\n",
    "            # fig = plt.figure()#figsize = (11,8), dpi=200)\n",
    "            # fig.suptitle(str(otime)+\" \"+associated_volcano)\n",
    "            # ax = plt.subplot(1,1,1)\n",
    "            # iplot = 0\n",
    "            # for i in range(len(stas)):\n",
    "            #     ax.plot(t-15,data_max[i,0,:]+iplot*1.5,linewidth=0.5)\n",
    "            #     ax.plot(t-15,smb_pred[ i, :]/np.max(np.abs(smb_pred[ i, :]))+iplot*1.5,'k',linewidth=0.5)\n",
    "            #     ax.set_yticks([])\n",
    "            #     plt.text(-15, iplot*1.5+0.5, stas[i])\n",
    "            #     # if i==ista:\n",
    "            #     err_title=(\"%s %2.2f (s) error in picks\"%(stas[i],smb_peak[i]-t_before))\n",
    "            #     plt.text(60, iplot*1.5+0.5,err_title,color='r')\n",
    "            #     plt.vlines(smb_peak[i]-t_before,iplot*1.5-1.,iplot*1.5+1.,'r')\n",
    "            #     print(stas[i],smb_peak[i]-t_before)\n",
    "            #     iplot+=1\n",
    "            # # plt.grid(True)\n",
    "            # ax.set_xlim([-t_before,80])\n",
    "            # ax.set_xlabel('time (seconds) relative to PNSN picks')\n",
    "            # plt.show()\n",
    "            # pdf.savefig(fig)\n",
    "            # plt.clf()\n",
    "            # del fig\n",
    "\n",
    "        # pick_mse[n] = np.sqrt(np.sum(smb_peak[:]-t_before)**2/len(stas))\n",
    "        # pick_mae[n] = np.sum(np.abs(smb_peak[:]-t_before))/len(stas)\n",
    "        # print(pick_mse[n],pick_mae[n] )\n",
    "        # if n > 10000: break\n",
    "    except:\n",
    "        pass\n",
    "# pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780b0863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Volcano_Name</th>\n",
       "      <th>Network</th>\n",
       "      <th>Station</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Distance_from_volc</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>ARAT</td>\n",
       "      <td>46.788755</td>\n",
       "      <td>-121.852537</td>\n",
       "      <td>1823.137</td>\n",
       "      <td>10.000900</td>\n",
       "      <td>2020-08-06T00:00:00.0000</td>\n",
       "      <td>2021-09-09T18:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>CARB</td>\n",
       "      <td>46.988320</td>\n",
       "      <td>-122.005410</td>\n",
       "      <td>872.470</td>\n",
       "      <td>23.938777</td>\n",
       "      <td>2018-10-16T00:00:00.0000</td>\n",
       "      <td>2022-05-26T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>CRBN</td>\n",
       "      <td>46.988131</td>\n",
       "      <td>-121.961063</td>\n",
       "      <td>499.080</td>\n",
       "      <td>21.410989</td>\n",
       "      <td>2020-10-22T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>GTWY</td>\n",
       "      <td>46.740163</td>\n",
       "      <td>-121.916765</td>\n",
       "      <td>617.235</td>\n",
       "      <td>17.286027</td>\n",
       "      <td>2020-10-28T20:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>KAUT</td>\n",
       "      <td>46.730263</td>\n",
       "      <td>-121.857390</td>\n",
       "      <td>689.000</td>\n",
       "      <td>15.506210</td>\n",
       "      <td>2020-09-02T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>MIRR</td>\n",
       "      <td>46.800468</td>\n",
       "      <td>-121.837353</td>\n",
       "      <td>1655.590</td>\n",
       "      <td>8.262303</td>\n",
       "      <td>2020-07-14T00:00:00.0000</td>\n",
       "      <td>2021-09-09T19:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>OBSR</td>\n",
       "      <td>46.899719</td>\n",
       "      <td>-121.815331</td>\n",
       "      <td>2382.000</td>\n",
       "      <td>6.675695</td>\n",
       "      <td>2008-11-19T00:00:00.0000</td>\n",
       "      <td>2016-09-13T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>OPCH</td>\n",
       "      <td>46.731319</td>\n",
       "      <td>-121.571171</td>\n",
       "      <td>592.430</td>\n",
       "      <td>19.752561</td>\n",
       "      <td>2020-10-26T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PANH</td>\n",
       "      <td>46.859032</td>\n",
       "      <td>-121.642592</td>\n",
       "      <td>2086.000</td>\n",
       "      <td>8.981691</td>\n",
       "      <td>2007-09-15T00:00:00.0000</td>\n",
       "      <td>2021-09-23T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PARA</td>\n",
       "      <td>46.786442</td>\n",
       "      <td>-121.742149</td>\n",
       "      <td>1651.180</td>\n",
       "      <td>7.516893</td>\n",
       "      <td>2020-10-07T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PR01</td>\n",
       "      <td>46.910390</td>\n",
       "      <td>-122.037770</td>\n",
       "      <td>648.000</td>\n",
       "      <td>22.030111</td>\n",
       "      <td>2016-11-03T00:00:00.0000</td>\n",
       "      <td>2020-06-17T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PR02</td>\n",
       "      <td>46.918305</td>\n",
       "      <td>-122.048639</td>\n",
       "      <td>461.000</td>\n",
       "      <td>23.082343</td>\n",
       "      <td>2016-11-17T00:00:00.0000</td>\n",
       "      <td>2020-06-08T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PR03</td>\n",
       "      <td>46.903438</td>\n",
       "      <td>-122.032271</td>\n",
       "      <td>532.000</td>\n",
       "      <td>21.416056</td>\n",
       "      <td>2017-10-12T00:00:00.0000</td>\n",
       "      <td>2021-10-12T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PR04</td>\n",
       "      <td>46.929694</td>\n",
       "      <td>-121.988976</td>\n",
       "      <td>912.700</td>\n",
       "      <td>19.356343</td>\n",
       "      <td>2017-10-12T00:00:00.0000</td>\n",
       "      <td>2020-08-13T00:50:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>PR05</td>\n",
       "      <td>46.841649</td>\n",
       "      <td>-121.948912</td>\n",
       "      <td>1553.000</td>\n",
       "      <td>14.392219</td>\n",
       "      <td>2017-09-28T00:00:00.0000</td>\n",
       "      <td>2022-07-11T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>RUSH</td>\n",
       "      <td>46.903060</td>\n",
       "      <td>-121.944390</td>\n",
       "      <td>1235.000</td>\n",
       "      <td>15.057620</td>\n",
       "      <td>2019-06-20T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>SIFT</td>\n",
       "      <td>46.867092</td>\n",
       "      <td>-121.953246</td>\n",
       "      <td>720.900</td>\n",
       "      <td>14.748834</td>\n",
       "      <td>2019-06-20T00:00:00.0000</td>\n",
       "      <td>2022-06-21T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>SR41</td>\n",
       "      <td>46.886680</td>\n",
       "      <td>-121.536642</td>\n",
       "      <td>1454.000</td>\n",
       "      <td>17.417395</td>\n",
       "      <td>2015-07-09T00:00:00.0000</td>\n",
       "      <td>2018-04-28T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>STYX</td>\n",
       "      <td>46.963747</td>\n",
       "      <td>-122.080535</td>\n",
       "      <td>568.310</td>\n",
       "      <td>27.265372</td>\n",
       "      <td>2022-05-25T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>TRON</td>\n",
       "      <td>46.997660</td>\n",
       "      <td>-122.174511</td>\n",
       "      <td>251.740</td>\n",
       "      <td>35.328864</td>\n",
       "      <td>2022-05-25T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>CC</td>\n",
       "      <td>VOIT</td>\n",
       "      <td>46.966330</td>\n",
       "      <td>-121.983400</td>\n",
       "      <td>977.100</td>\n",
       "      <td>21.121184</td>\n",
       "      <td>2019-09-25T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>ASF</td>\n",
       "      <td>46.759880</td>\n",
       "      <td>-122.027771</td>\n",
       "      <td>528.000</td>\n",
       "      <td>22.827208</td>\n",
       "      <td>1995-03-20T00:00:00.0000</td>\n",
       "      <td>1995-06-12T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>CMK</td>\n",
       "      <td>46.934479</td>\n",
       "      <td>-121.229782</td>\n",
       "      <td>1380.000</td>\n",
       "      <td>41.323655</td>\n",
       "      <td>1995-10-06T00:00:00.0000</td>\n",
       "      <td>1996-07-16T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>CMM</td>\n",
       "      <td>46.490829</td>\n",
       "      <td>-122.013321</td>\n",
       "      <td>305.000</td>\n",
       "      <td>44.643814</td>\n",
       "      <td>1980-04-04T00:00:00.0000</td>\n",
       "      <td>2004-10-04T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>COW</td>\n",
       "      <td>46.490829</td>\n",
       "      <td>-122.013321</td>\n",
       "      <td>305.000</td>\n",
       "      <td>44.643814</td>\n",
       "      <td>1980-03-27T00:00:00.0000</td>\n",
       "      <td>1989-10-04T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>DLR</td>\n",
       "      <td>47.102650</td>\n",
       "      <td>-121.568619</td>\n",
       "      <td>1190.000</td>\n",
       "      <td>31.350631</td>\n",
       "      <td>1995-04-07T00:00:00.0000</td>\n",
       "      <td>1995-09-19T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>FGM</td>\n",
       "      <td>47.075630</td>\n",
       "      <td>-121.763870</td>\n",
       "      <td>1158.000</td>\n",
       "      <td>24.768359</td>\n",
       "      <td>1995-05-20T00:00:00.0000</td>\n",
       "      <td>1995-09-19T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>FMW</td>\n",
       "      <td>46.941399</td>\n",
       "      <td>-121.670998</td>\n",
       "      <td>1859.000</td>\n",
       "      <td>11.957122</td>\n",
       "      <td>1972-09-01T00:00:00.0000</td>\n",
       "      <td>2018-10-11T16:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>GHW</td>\n",
       "      <td>47.041489</td>\n",
       "      <td>-122.273727</td>\n",
       "      <td>268.000</td>\n",
       "      <td>44.251184</td>\n",
       "      <td>1975-08-13T00:00:00.0000</td>\n",
       "      <td>2020-03-14T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>GLK</td>\n",
       "      <td>46.557499</td>\n",
       "      <td>-121.610733</td>\n",
       "      <td>1305.000</td>\n",
       "      <td>34.769494</td>\n",
       "      <td>1973-01-01T00:00:00.0000</td>\n",
       "      <td>2017-12-07T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>GRL</td>\n",
       "      <td>46.814030</td>\n",
       "      <td>-121.328072</td>\n",
       "      <td>1287.000</td>\n",
       "      <td>33.166690</td>\n",
       "      <td>1995-10-01T00:00:00.0000</td>\n",
       "      <td>1996-07-18T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>GSM</td>\n",
       "      <td>47.203880</td>\n",
       "      <td>-121.796043</td>\n",
       "      <td>1313.000</td>\n",
       "      <td>39.120572</td>\n",
       "      <td>1970-06-01T00:00:00.0000</td>\n",
       "      <td>2018-10-18T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>LMW</td>\n",
       "      <td>46.667831</td>\n",
       "      <td>-122.292549</td>\n",
       "      <td>1195.000</td>\n",
       "      <td>45.459342</td>\n",
       "      <td>1975-06-01T00:00:00.0000</td>\n",
       "      <td>2012-10-20T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>LO2</td>\n",
       "      <td>46.750599</td>\n",
       "      <td>-121.809601</td>\n",
       "      <td>853.000</td>\n",
       "      <td>11.974520</td>\n",
       "      <td>1988-03-17T00:00:00.0000</td>\n",
       "      <td>2009-01-28T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>LON</td>\n",
       "      <td>46.750599</td>\n",
       "      <td>-121.809601</td>\n",
       "      <td>853.000</td>\n",
       "      <td>11.974520</td>\n",
       "      <td>1964-03-30T00:00:00.0000</td>\n",
       "      <td>2019-06-19T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>MHL</td>\n",
       "      <td>46.882210</td>\n",
       "      <td>-122.065231</td>\n",
       "      <td>1215.000</td>\n",
       "      <td>23.403181</td>\n",
       "      <td>1995-08-02T00:00:00.0000</td>\n",
       "      <td>1995-10-31T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>MUP</td>\n",
       "      <td>46.839119</td>\n",
       "      <td>-121.126472</td>\n",
       "      <td>1456.000</td>\n",
       "      <td>48.232246</td>\n",
       "      <td>1995-09-30T00:00:00.0000</td>\n",
       "      <td>1996-07-16T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>PAK</td>\n",
       "      <td>46.841320</td>\n",
       "      <td>-122.304268</td>\n",
       "      <td>436.000</td>\n",
       "      <td>41.381996</td>\n",
       "      <td>1992-08-16T00:00:00.0000</td>\n",
       "      <td>1995-08-02T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>PCEP</td>\n",
       "      <td>47.111400</td>\n",
       "      <td>-122.291220</td>\n",
       "      <td>158.000</td>\n",
       "      <td>49.474641</td>\n",
       "      <td>2000-08-02T00:00:00.0000</td>\n",
       "      <td>2020-09-30T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>PCMD</td>\n",
       "      <td>46.888962</td>\n",
       "      <td>-122.301483</td>\n",
       "      <td>239.000</td>\n",
       "      <td>41.327098</td>\n",
       "      <td>2000-09-28T00:00:00.0000</td>\n",
       "      <td>2013-08-22T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>PUPY</td>\n",
       "      <td>46.495420</td>\n",
       "      <td>-122.146130</td>\n",
       "      <td>816.300</td>\n",
       "      <td>49.456268</td>\n",
       "      <td>2019-10-31T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RCM</td>\n",
       "      <td>46.835640</td>\n",
       "      <td>-121.732979</td>\n",
       "      <td>3085.000</td>\n",
       "      <td>2.831586</td>\n",
       "      <td>1993-09-09T00:00:00.0000</td>\n",
       "      <td>2018-09-19T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RCS</td>\n",
       "      <td>46.870831</td>\n",
       "      <td>-121.732307</td>\n",
       "      <td>2877.000</td>\n",
       "      <td>2.921446</td>\n",
       "      <td>1989-06-27T00:00:00.0000</td>\n",
       "      <td>2008-04-01T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RER</td>\n",
       "      <td>46.819050</td>\n",
       "      <td>-121.842133</td>\n",
       "      <td>1756.000</td>\n",
       "      <td>7.268323</td>\n",
       "      <td>1989-07-13T00:00:00.0000</td>\n",
       "      <td>2012-12-10T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RSH</td>\n",
       "      <td>46.812092</td>\n",
       "      <td>-121.529671</td>\n",
       "      <td>1770.000</td>\n",
       "      <td>18.126027</td>\n",
       "      <td>1995-06-13T00:00:00.0000</td>\n",
       "      <td>1995-09-20T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RSU</td>\n",
       "      <td>46.853161</td>\n",
       "      <td>-121.764259</td>\n",
       "      <td>4440.000</td>\n",
       "      <td>0.296966</td>\n",
       "      <td>1999-08-20T00:00:00.0000</td>\n",
       "      <td>2001-09-21T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RVC</td>\n",
       "      <td>46.944080</td>\n",
       "      <td>-121.974190</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>19.149618</td>\n",
       "      <td>1983-01-01T00:00:00.0000</td>\n",
       "      <td>2021-01-10T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>RVN</td>\n",
       "      <td>47.027222</td>\n",
       "      <td>-121.337837</td>\n",
       "      <td>1885.000</td>\n",
       "      <td>37.479584</td>\n",
       "      <td>1995-09-26T00:00:00.0000</td>\n",
       "      <td>2002-08-15T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>SPFR</td>\n",
       "      <td>46.947870</td>\n",
       "      <td>-122.356750</td>\n",
       "      <td>172.300</td>\n",
       "      <td>46.522755</td>\n",
       "      <td>2020-06-11T00:00:00.0000</td>\n",
       "      <td>2020-06-12T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>STAR</td>\n",
       "      <td>46.850849</td>\n",
       "      <td>-121.792953</td>\n",
       "      <td>3365.000</td>\n",
       "      <td>2.487651</td>\n",
       "      <td>2008-09-15T00:00:00.0000</td>\n",
       "      <td>2019-12-18T22:50:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>STOR</td>\n",
       "      <td>47.188099</td>\n",
       "      <td>-121.988800</td>\n",
       "      <td>266.400</td>\n",
       "      <td>41.097944</td>\n",
       "      <td>2008-12-03T00:00:00.0000</td>\n",
       "      <td>2014-06-19T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>TEHA</td>\n",
       "      <td>47.127950</td>\n",
       "      <td>-122.196300</td>\n",
       "      <td>211.700</td>\n",
       "      <td>45.039321</td>\n",
       "      <td>2022-05-04T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>WCR</td>\n",
       "      <td>46.613960</td>\n",
       "      <td>-121.767754</td>\n",
       "      <td>1200.000</td>\n",
       "      <td>26.572101</td>\n",
       "      <td>1995-06-12T00:00:00.0000</td>\n",
       "      <td>1995-09-22T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>WI2</td>\n",
       "      <td>47.136108</td>\n",
       "      <td>-121.382309</td>\n",
       "      <td>1528.000</td>\n",
       "      <td>42.588715</td>\n",
       "      <td>1995-09-24T00:00:00.0000</td>\n",
       "      <td>1996-07-17T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>WPEQ</td>\n",
       "      <td>46.613279</td>\n",
       "      <td>-121.404485</td>\n",
       "      <td>1807.000</td>\n",
       "      <td>38.018319</td>\n",
       "      <td>2021-08-02T00:00:00.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>WPS</td>\n",
       "      <td>46.625000</td>\n",
       "      <td>-121.388031</td>\n",
       "      <td>1789.000</td>\n",
       "      <td>38.040312</td>\n",
       "      <td>1995-06-29T00:00:00.0000</td>\n",
       "      <td>1995-09-29T23:59:59.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>WPW</td>\n",
       "      <td>46.698639</td>\n",
       "      <td>-121.537338</td>\n",
       "      <td>1280.000</td>\n",
       "      <td>24.137150</td>\n",
       "      <td>1980-03-27T00:00:00.0000</td>\n",
       "      <td>2017-04-19T00:00:00.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>Mt_Rainier</td>\n",
       "      <td>UW</td>\n",
       "      <td>XTL</td>\n",
       "      <td>46.929779</td>\n",
       "      <td>-121.494476</td>\n",
       "      <td>1665.000</td>\n",
       "      <td>21.938926</td>\n",
       "      <td>1995-10-11T00:00:00.0000</td>\n",
       "      <td>1997-07-16T23:59:59.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Volcano_Name Network Station   Latitude   Longitude  Elevation  \\\n",
       "0            0   Mt_Rainier      CC    ARAT  46.788755 -121.852537   1823.137   \n",
       "1            1   Mt_Rainier      CC    CARB  46.988320 -122.005410    872.470   \n",
       "2            2   Mt_Rainier      CC    CRBN  46.988131 -121.961063    499.080   \n",
       "3            3   Mt_Rainier      CC    GTWY  46.740163 -121.916765    617.235   \n",
       "4            4   Mt_Rainier      CC    KAUT  46.730263 -121.857390    689.000   \n",
       "5            5   Mt_Rainier      CC    MIRR  46.800468 -121.837353   1655.590   \n",
       "6            6   Mt_Rainier      CC    OBSR  46.899719 -121.815331   2382.000   \n",
       "7            7   Mt_Rainier      CC    OPCH  46.731319 -121.571171    592.430   \n",
       "8            8   Mt_Rainier      CC    PANH  46.859032 -121.642592   2086.000   \n",
       "9            9   Mt_Rainier      CC    PARA  46.786442 -121.742149   1651.180   \n",
       "10          10   Mt_Rainier      CC    PR01  46.910390 -122.037770    648.000   \n",
       "11          11   Mt_Rainier      CC    PR02  46.918305 -122.048639    461.000   \n",
       "12          12   Mt_Rainier      CC    PR03  46.903438 -122.032271    532.000   \n",
       "13          13   Mt_Rainier      CC    PR04  46.929694 -121.988976    912.700   \n",
       "14          14   Mt_Rainier      CC    PR05  46.841649 -121.948912   1553.000   \n",
       "15          15   Mt_Rainier      CC    RUSH  46.903060 -121.944390   1235.000   \n",
       "16          16   Mt_Rainier      CC    SIFT  46.867092 -121.953246    720.900   \n",
       "17          17   Mt_Rainier      CC    SR41  46.886680 -121.536642   1454.000   \n",
       "18          18   Mt_Rainier      CC    STYX  46.963747 -122.080535    568.310   \n",
       "19          19   Mt_Rainier      CC    TRON  46.997660 -122.174511    251.740   \n",
       "20          20   Mt_Rainier      CC    VOIT  46.966330 -121.983400    977.100   \n",
       "21          21   Mt_Rainier      UW     ASF  46.759880 -122.027771    528.000   \n",
       "22          22   Mt_Rainier      UW     CMK  46.934479 -121.229782   1380.000   \n",
       "23          23   Mt_Rainier      UW     CMM  46.490829 -122.013321    305.000   \n",
       "24          24   Mt_Rainier      UW     COW  46.490829 -122.013321    305.000   \n",
       "25          25   Mt_Rainier      UW     DLR  47.102650 -121.568619   1190.000   \n",
       "26          26   Mt_Rainier      UW     FGM  47.075630 -121.763870   1158.000   \n",
       "27          27   Mt_Rainier      UW     FMW  46.941399 -121.670998   1859.000   \n",
       "28          28   Mt_Rainier      UW     GHW  47.041489 -122.273727    268.000   \n",
       "29          29   Mt_Rainier      UW     GLK  46.557499 -121.610733   1305.000   \n",
       "30          30   Mt_Rainier      UW     GRL  46.814030 -121.328072   1287.000   \n",
       "31          31   Mt_Rainier      UW     GSM  47.203880 -121.796043   1313.000   \n",
       "32          32   Mt_Rainier      UW     LMW  46.667831 -122.292549   1195.000   \n",
       "33          33   Mt_Rainier      UW     LO2  46.750599 -121.809601    853.000   \n",
       "34          34   Mt_Rainier      UW     LON  46.750599 -121.809601    853.000   \n",
       "35          35   Mt_Rainier      UW     MHL  46.882210 -122.065231   1215.000   \n",
       "36          36   Mt_Rainier      UW     MUP  46.839119 -121.126472   1456.000   \n",
       "37          37   Mt_Rainier      UW     PAK  46.841320 -122.304268    436.000   \n",
       "38          38   Mt_Rainier      UW    PCEP  47.111400 -122.291220    158.000   \n",
       "39          39   Mt_Rainier      UW    PCMD  46.888962 -122.301483    239.000   \n",
       "40          40   Mt_Rainier      UW    PUPY  46.495420 -122.146130    816.300   \n",
       "41          41   Mt_Rainier      UW     RCM  46.835640 -121.732979   3085.000   \n",
       "42          42   Mt_Rainier      UW     RCS  46.870831 -121.732307   2877.000   \n",
       "43          43   Mt_Rainier      UW     RER  46.819050 -121.842133   1756.000   \n",
       "44          44   Mt_Rainier      UW     RSH  46.812092 -121.529671   1770.000   \n",
       "45          45   Mt_Rainier      UW     RSU  46.853161 -121.764259   4440.000   \n",
       "46          46   Mt_Rainier      UW     RVC  46.944080 -121.974190   1000.000   \n",
       "47          47   Mt_Rainier      UW     RVN  47.027222 -121.337837   1885.000   \n",
       "48          48   Mt_Rainier      UW    SPFR  46.947870 -122.356750    172.300   \n",
       "49          49   Mt_Rainier      UW    STAR  46.850849 -121.792953   3365.000   \n",
       "50          50   Mt_Rainier      UW    STOR  47.188099 -121.988800    266.400   \n",
       "51          51   Mt_Rainier      UW    TEHA  47.127950 -122.196300    211.700   \n",
       "52          52   Mt_Rainier      UW     WCR  46.613960 -121.767754   1200.000   \n",
       "53          53   Mt_Rainier      UW     WI2  47.136108 -121.382309   1528.000   \n",
       "54          54   Mt_Rainier      UW    WPEQ  46.613279 -121.404485   1807.000   \n",
       "55          55   Mt_Rainier      UW     WPS  46.625000 -121.388031   1789.000   \n",
       "56          56   Mt_Rainier      UW     WPW  46.698639 -121.537338   1280.000   \n",
       "57          57   Mt_Rainier      UW     XTL  46.929779 -121.494476   1665.000   \n",
       "\n",
       "    Distance_from_volc                     Start                       End  \n",
       "0            10.000900  2020-08-06T00:00:00.0000  2021-09-09T18:00:00.0000  \n",
       "1            23.938777  2018-10-16T00:00:00.0000  2022-05-26T00:00:00.0000  \n",
       "2            21.410989  2020-10-22T00:00:00.0000                       NaN  \n",
       "3            17.286027  2020-10-28T20:00:00.0000                       NaN  \n",
       "4            15.506210  2020-09-02T00:00:00.0000                       NaN  \n",
       "5             8.262303  2020-07-14T00:00:00.0000  2021-09-09T19:00:00.0000  \n",
       "6             6.675695  2008-11-19T00:00:00.0000  2016-09-13T00:00:00.0000  \n",
       "7            19.752561  2020-10-26T00:00:00.0000                       NaN  \n",
       "8             8.981691  2007-09-15T00:00:00.0000  2021-09-23T00:00:00.0000  \n",
       "9             7.516893  2020-10-07T00:00:00.0000                       NaN  \n",
       "10           22.030111  2016-11-03T00:00:00.0000  2020-06-17T00:00:00.0000  \n",
       "11           23.082343  2016-11-17T00:00:00.0000  2020-06-08T00:00:00.0000  \n",
       "12           21.416056  2017-10-12T00:00:00.0000  2021-10-12T00:00:00.0000  \n",
       "13           19.356343  2017-10-12T00:00:00.0000  2020-08-13T00:50:00.0000  \n",
       "14           14.392219  2017-09-28T00:00:00.0000  2022-07-11T00:00:00.0000  \n",
       "15           15.057620  2019-06-20T00:00:00.0000                       NaN  \n",
       "16           14.748834  2019-06-20T00:00:00.0000  2022-06-21T00:00:00.0000  \n",
       "17           17.417395  2015-07-09T00:00:00.0000  2018-04-28T00:00:00.0000  \n",
       "18           27.265372  2022-05-25T00:00:00.0000                       NaN  \n",
       "19           35.328864  2022-05-25T00:00:00.0000                       NaN  \n",
       "20           21.121184  2019-09-25T00:00:00.0000                       NaN  \n",
       "21           22.827208  1995-03-20T00:00:00.0000  1995-06-12T23:59:59.0000  \n",
       "22           41.323655  1995-10-06T00:00:00.0000  1996-07-16T23:59:59.0000  \n",
       "23           44.643814  1980-04-04T00:00:00.0000  2004-10-04T00:00:00.0000  \n",
       "24           44.643814  1980-03-27T00:00:00.0000  1989-10-04T23:59:59.0000  \n",
       "25           31.350631  1995-04-07T00:00:00.0000  1995-09-19T23:59:59.0000  \n",
       "26           24.768359  1995-05-20T00:00:00.0000  1995-09-19T23:59:59.0000  \n",
       "27           11.957122  1972-09-01T00:00:00.0000  2018-10-11T16:00:00.0000  \n",
       "28           44.251184  1975-08-13T00:00:00.0000  2020-03-14T00:00:00.0000  \n",
       "29           34.769494  1973-01-01T00:00:00.0000  2017-12-07T00:00:00.0000  \n",
       "30           33.166690  1995-10-01T00:00:00.0000  1996-07-18T23:59:59.0000  \n",
       "31           39.120572  1970-06-01T00:00:00.0000  2018-10-18T00:00:00.0000  \n",
       "32           45.459342  1975-06-01T00:00:00.0000  2012-10-20T00:00:00.0000  \n",
       "33           11.974520  1988-03-17T00:00:00.0000  2009-01-28T00:00:00.0000  \n",
       "34           11.974520  1964-03-30T00:00:00.0000  2019-06-19T00:00:00.0000  \n",
       "35           23.403181  1995-08-02T00:00:00.0000  1995-10-31T23:59:59.0000  \n",
       "36           48.232246  1995-09-30T00:00:00.0000  1996-07-16T23:59:59.0000  \n",
       "37           41.381996  1992-08-16T00:00:00.0000  1995-08-02T23:59:59.0000  \n",
       "38           49.474641  2000-08-02T00:00:00.0000  2020-09-30T00:00:00.0000  \n",
       "39           41.327098  2000-09-28T00:00:00.0000  2013-08-22T00:00:00.0000  \n",
       "40           49.456268  2019-10-31T00:00:00.0000                       NaN  \n",
       "41            2.831586  1993-09-09T00:00:00.0000  2018-09-19T00:00:00.0000  \n",
       "42            2.921446  1989-06-27T00:00:00.0000  2008-04-01T00:00:00.0000  \n",
       "43            7.268323  1989-07-13T00:00:00.0000  2012-12-10T00:00:00.0000  \n",
       "44           18.126027  1995-06-13T00:00:00.0000  1995-09-20T23:59:59.0000  \n",
       "45            0.296966  1999-08-20T00:00:00.0000  2001-09-21T00:00:00.0000  \n",
       "46           19.149618  1983-01-01T00:00:00.0000  2021-01-10T00:00:00.0000  \n",
       "47           37.479584  1995-09-26T00:00:00.0000  2002-08-15T00:00:00.0000  \n",
       "48           46.522755  2020-06-11T00:00:00.0000  2020-06-12T00:00:00.0000  \n",
       "49            2.487651  2008-09-15T00:00:00.0000  2019-12-18T22:50:00.0000  \n",
       "50           41.097944  2008-12-03T00:00:00.0000  2014-06-19T00:00:00.0000  \n",
       "51           45.039321  2022-05-04T00:00:00.0000                       NaN  \n",
       "52           26.572101  1995-06-12T00:00:00.0000  1995-09-22T23:59:59.0000  \n",
       "53           42.588715  1995-09-24T00:00:00.0000  1996-07-17T23:59:59.0000  \n",
       "54           38.018319  2021-08-02T00:00:00.0000                       NaN  \n",
       "55           38.040312  1995-06-29T00:00:00.0000  1995-09-29T23:59:59.0000  \n",
       "56           24.137150  1980-03-27T00:00:00.0000  2017-04-19T00:00:00.0000  \n",
       "57           21.938926  1995-10-11T00:00:00.0000  1997-07-16T23:59:59.0000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Volcano_Name\"]==\"Mt_Rainier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec1eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for n in range(11649,11660):    \n",
    "#     event_ID = str(evt_id[n])\n",
    "#     otime = UTCDateTime(start_time[n])\n",
    "#     print(event_ID,otime)\n",
    "#     if net != 'CN' and evt_id[n]!=evt_id[n-1]:\n",
    "#         reference = str(net[n]+'.'+sta[n])\n",
    "#         try:\n",
    "#             associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "#         except: \n",
    "#             pass\n",
    "#         print(associated_volcano)\n",
    "            \n",
    "#         #get info for stations within 50km of volcano that event ocurred at\n",
    "#         stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "#         networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "#         latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "#         longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "#         elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "\n",
    "#         if stations.count(\"LON\")>0 and stations.count(\"LO2\")>0:\n",
    "#             index = stations.index(\"LO2\")\n",
    "#             del stations[index]\n",
    "#             del networks[index]\n",
    "#             del latitudes[index]\n",
    "#             del longitudes[index]\n",
    "#             del elevations[index]\n",
    "\n",
    "\n",
    "# #################### WAVEFORM DOWNLOAD #######################\n",
    "#         #Download all waveforms for that event based on stations and times\n",
    "#         bulk = [] \n",
    "#         for m in range(0, len(networks)):\n",
    "#             bulk.append([networks[m], stations[m], '*', '*H*', otime-t_before_raw, otime+t_after_raw])\n",
    "#         st = client2.get_waveforms_bulk(bulk)\n",
    "\n",
    "#         #remove unwanted data\n",
    "#         for tr in st:\n",
    "#             cha = tr.stats.channel\n",
    "#             try:\n",
    "#                 if len(tr.data)/tr.stats.sampling_rate < 239.9:\n",
    "#                     st.remove(tr)\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#         #resampling the data to 40Hz for each trace\n",
    "#         st = resample(st,fs) \n",
    "#         # #Plotting all traces for one event with channel z, SNR>10, and bandpasses between 2-12Hz\n",
    "#         SNR,SNR_weight, no_weight,stas,nets,max_amp_times,durations,data_env_dict,t_diff = [],[],[],[],[],[],[],{},{}\n",
    "#         fig = plt.figure()#figsize = (11,8), dpi=200)\n",
    "#         fig.suptitle('evtID:UW'+ event_ID+associated_volcano)\n",
    "#         evt_data = obspy.Stream()\n",
    "#         # plt.rcParams.update({'font.size': 20})\n",
    "#         ax = plt.subplot(1,1,1)\n",
    "#         iplot = 0\n",
    "#         # zz = evt_data.select(component=\"Z\")\n",
    "#         for i,ii in enumerate(st):\n",
    "#             network = ii.stats.network\n",
    "#             station = ii.stats.station\n",
    "#             ii.detrend(type = 'demean')\n",
    "#             ii.filter('bandpass',freqmin=low_cut,freqmax=high_cut,corners=2,zerophase=True)\n",
    "#             cha = ii.stats.channel\n",
    "#             # ii.trim(otime,otime+window)\n",
    "#             starttime = ii.stats.starttime\n",
    "#             signal_window = ii.copy()\n",
    "#             noise_window = ii.copy()\n",
    "#             signal_window.trim(otime - 10, otime - 10 + window) # trim the signal at the first pick time of the PNSN data, with loose 40s before\n",
    "#             noise_window.trim(otime - window -10, otime - 10) # noise window of the same length\n",
    "#             snr = (20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "#                             / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "#             max_amp_time = np.argmax(noise_window.data)/fs\n",
    "#             # print(snr,max_amp_time)\n",
    "#             # signal_window.plot()x\n",
    "#             if snr<thr: # and 100<max_amp_time<200:\n",
    "#                 st.remove(ii)\n",
    "#                 continue\n",
    "#             t = signal_window.times()\n",
    "#             t_diff[network+'.'+station] = starttime-otime \n",
    "#             # enveloping the data \n",
    "#             data_envelope = obspy.signal.filter.envelope(signal_window.data)\n",
    "#             data_envelope /= np.max(data_envelope)\n",
    "#             # data_envelope += iplot*1.5\n",
    "#             # finding the time of max amplitude of each event\n",
    "#             max_amp_times.append(max_amp_time)\n",
    "#             max_amp = np.max(ii.data)      \n",
    "#             # creating envelope data dictionary to calculate picktimes\n",
    "#             data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "#             # kurt = rt.signal.kurtosis(signal_window.taper(max_percentage=0.05))\n",
    "#             # kurt /= np.max(kurt)\n",
    "#             data_env_dict[network+'.'+station]= data_envelope\n",
    "#             # b,e = 115,150\n",
    "#             if cha[-1]==\"Z\":\n",
    "#                 ax.plot(t,signal_window.data/np.max(np.abs(signal_window.data))+iplot*1.5)\n",
    "#                 ax.plot(t,data_envelope+iplot*1.5, color = 'k')\n",
    "#                 # ax1.plot(t,kurt+iplot*1.5, color = 'r')\n",
    "#                 # ax1.plot(t[(t_before_raw+b)*fs:(t_before_raw+e)*fs], data_envelope, color = 'k')\n",
    "#                 # ax1.plot(t[b*fs:e*fs],ii.data[b*fs:e*fs]/np.max(np.abs(ii.data))+iplot*1.5)\n",
    "#                 # ax1.plot(t[115*fs:150*fs], data_envelope, color = 'k')\n",
    "#                 ax.set_xlabel('time (seconds)')\n",
    "#                 # ax1.set_xlim([b+t_before_raw,e+t_before_raw])\n",
    "#                 ax.set_yticks([])\n",
    "#                 # plt.text(t[e*fs], iplot*1.5, 'SNR:'+str(int(snr)))\n",
    "#                 # plt.text(t[b*fs], iplot*1.5, station)\n",
    "\n",
    "#                 iplot = iplot+1\n",
    "#             stas.append(ii.stats.station)\n",
    "#             nets.append(ii.stats.network)\n",
    "#             SNR.append(snr)\n",
    "#             SNR_weight.append(int(snr))\n",
    "#             no_weight.append(1)\n",
    "#             evt_data.append(signal_window)\n",
    "#     # impose at least 4 stations\n",
    "#     if len(evt_data)<4:  \n",
    "#         continue\n",
    "\n",
    "#     sta_available = np.unique(np.array(stas))\n",
    "#     print(sta_available)\n",
    "    \n",
    "\n",
    "# ## Get an approximative measurement of duration taking the highest SNR data\n",
    "#     ik=np.argmax(SNR)\n",
    "#     crap =np.cumsum(np.abs(evt_data[ik].data))\n",
    "#     maxcrap = crap[-1]\n",
    "#     Td=len(np.where((crap>=0.02*crap[-1])&(crap<=0.95*crap[-1]))[0])/fs\n",
    "#     print(\"The approximate duration of this event is %f s \"%Td)\n",
    "\n",
    "\n",
    "\n",
    "# ############## PEAK FREQUENCY MEASUREMENTS ############\n",
    "# # Given the approximate measurement of duration, window the signal windows around that\n",
    "# # then measure peak frequency so that there is less noise in it.\n",
    "# # perform this on the Z component only.\n",
    "#     data2measure_peak_frequency=evt_data.copy()\n",
    "#     print(data2measure_peak_frequency[3:6])\n",
    "#     data2measure_peak_frequency=data2measure_peak_frequency.select(component=\"Z\")\n",
    "#     print(data2measure_peak_frequency[3:6])\n",
    "#     data2measure_peak_frequency.taper(max_percentage=0.01,max_length=20)\n",
    "#     # evt_data.trim(starttime=otime-20,endtime=otime+Td+20) \n",
    "#     #         # make plot of spectra\n",
    "#     char_freq, sharp_weight= [],[]\n",
    "#     fig1,ax1 = plt.subplots(1,1,figsize=(11,7), dpi = 200)\n",
    "#     for i in range(len(data2measure_peak_frequency)):\n",
    "#         data = data2measure_peak_frequency[i].data #*100\n",
    "#         f,psd=scipy.signal.welch(data,fs=fs,nperseg=81,noverlap=4)\n",
    "#         #just get the frequencies within the filter band\n",
    "#         above_low_cut = [f>low_cut]\n",
    "#         below_high_cut = [f<high_cut]\n",
    "#         in_band = np.logical_and(above_low_cut,below_high_cut)[0]\n",
    "#         f = f[in_band]\n",
    "#         psd = psd[in_band]\n",
    "\n",
    "#         # calculate characteristic frequency and report\n",
    "#         char_freq_max = f[np.argmax(psd)]\n",
    "#         char_freq_mean= np.sum(psd*f)/np.sum(psd)\n",
    "#         psd_cumsum = np.cumsum(psd)\n",
    "#         psd_sum = np.sum(psd)\n",
    "#         char_freq_median = f[np.argmin(np.abs(psd_cumsum-psd_sum/2))]\n",
    "#         char_freq.append(char_freq_mean)\n",
    "\n",
    "# #             plt.rcParams.update({'font.size': 20})\n",
    "#         ax1.plot(f,psd,label=stas[i],linewidth=2)\n",
    "#         ax1.set_xscale('log')\n",
    "#         ax1.set_yscale('log')\n",
    "#         ax1.grid('True')\n",
    "#         ax1.set_xlabel('Frequency [Hz]')\n",
    "#         ax1.set_ylabel('PSD [$(mm/s)^2$/Hz]')\n",
    "#         ax1.vlines(char_freq_mean,ymin=np.min(psd)/10,ymax=np.max(psd)*10,linestyle=\"--\",colors=colors[i])\n",
    "\n",
    "# #             # weighting the data by the spikiness of the PSD vs frequency graphs\n",
    "#         ratio = (np.mean(psd)/np.max(psd))\n",
    "#         sharp_weight.append(int(1/(ratio**2)*20))\n",
    "\n",
    "# #         ax.legend() \n",
    "# #         plt.savefig('psd'+event_ID+associated_volcano+'.png')\n",
    "\n",
    "#         # lats, lons, elevs, r, theta = ([] for i in range(5)) \n",
    "#         # ref = str(nets[0]+'.'+stas[0])\n",
    "#         # try:\n",
    "#         #     ref_env = data_env_dict[reference]\n",
    "#         # except:\n",
    "#         #     ref_env = data_env_dict[ref]\n",
    "\n",
    "\n",
    "#     ################### PHASE PICKING using retrained eqT ####################\n",
    "#     for i in range(len(sta_available)):\n",
    "#         stream = evt_data.select(station=sta_available[i])\n",
    "#         if len(stream)==3:\n",
    "#             annotations = eqt.annotate(stream)\n",
    "#             print(annotations)\n",
    "#         elif len(stream)==1:\n",
    "#             # copy stream to 2 components, zero the missing data.\n",
    "#             tr3 = stream[0].copy()\n",
    "#             tr2 = stream[0].copy();tr2.stats.channel=stream[0].stats.channel[0:2]+\"N\"\n",
    "#             tr1 = stream[0].copy();tr1.stats.channel=stream[0].stats.channel[0:2]+\"E\"\n",
    "#             tr1.data=np.zeros(len(stream[0].data))\n",
    "#             tr2.data=np.zeros(len(stream[0].data))\n",
    "#             crap=obspy.Stream(traces=[tr1,tr2,tr3])\n",
    "#             print(crap)\n",
    "\n",
    "#         pcount = {\"P\":0, \"S\":0}\n",
    "#         for ii in eqt.classify(stream)[0]:\n",
    "#             pcount[ii.phase] += 1\n",
    "#         print('--------------'*3)\n",
    "#         print(f\"{pcount['P']} P picks\\n{pcount['S']} S picks\")\n",
    "\n",
    "#         # print(__annotations__)\n",
    "#         print(annotations[0])\n",
    "#         annotations[0].stats.sampling_rate=40\n",
    "#         t2=annotations[0].times()\n",
    "#         ax.plot(t2,annotations[1].data+i*1.5, color = 'r')\n",
    "#         ax.plot(t2,annotations[2].data+i*1.5, color = 'b')\n",
    "\n",
    "\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc3a72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Trace(s) in Stream:\n",
      "CC.ARAT..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:05:27.325000Z | 40.0 Hz, 1654 samples\n",
      "CC.CARB..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.CRBN..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.OBSR..BHZ | 2023-11-05T07:04:46.005000Z - 2023-11-05T07:07:16.005000Z | 40.0 Hz, 6001 samples\n",
      "CC.PANH..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.PARA..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.PR04..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.PR05..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.RUSH..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.SIFT..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.STYX..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "CC.VOIT..BHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "UW.FMW..HHZ  | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "UW.LO2..EHZ  | 2023-11-05T07:04:46.001014Z - 2023-11-05T07:07:16.001014Z | 40.0 Hz, 6001 samples\n",
      "UW.LON..HHZ  | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "UW.PUPY..EHZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "UW.PUPY..ENZ | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "UW.RCM..HHZ  | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "UW.RCS..EHZ  | 2023-11-05T07:04:46.001026Z - 2023-11-05T07:07:16.001026Z | 40.0 Hz, 6001 samples\n",
      "UW.RER..HHZ  | 2023-11-05T07:04:46.000000Z - 2023-11-05T07:07:16.000000Z | 40.0 Hz, 6001 samples\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(evt_data)\n",
    "tr3 = evt_data[-1].copy()\n",
    "tr2 = evt_data[-1].copy();tr2.stats.channel=evt_data[-1].stats.channel[0:2]+\"N\"\n",
    "tr1 = evt_data[-1].copy();tr1.stats.channel=evt_data[-1].stats.channel[0:2]+\"E\"\n",
    "tr1.data=np.zeros(len(evt_data[-1].data))\n",
    "tr2.data=np.zeros(len(evt_data[-1].data))\n",
    "crap=obspy.Stream(traces=[tr1,tr2,tr3])\n",
    "# crap[0].stats.channel=crap[0].stats.channel[0:2]+\"I\"\n",
    "# crap[1].stats.channel=crap[0].stats.channel[0:2]+\"H\"\n",
    "# crap[2].stats.channel=crap[0].stats.channel[0:2]+\"Z\"\n",
    "\n",
    "# crap[0].data=np.zeros(len(crap[1].data))\n",
    "\n",
    "\n",
    "print(crap[0].data)\n",
    "\n",
    "# print(crap[2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44639804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61c4d6e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c702477",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mt_St_Helens\n"
     ]
    }
   ],
   "source": [
    "for n in range(6290,6291):    \n",
    "    event_ID = str(evt_id[n])\n",
    "    time = UTCDateTime(start_time[n])\n",
    "    if net != 'CN' and evt_id[n]!=evt_id[n-1]:\n",
    "        reference = str(net[n]+'.'+sta[n])\n",
    "        try:\n",
    "            associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "        except: \n",
    "            pass\n",
    "        print(associated_volcano)\n",
    "        # if associated_volcano == 'Mt_Rainier':\n",
    "            \n",
    "        #get info for stations within 50km of volcano that event ocurred at\n",
    "        stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "        networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "        latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "        longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "        elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "\n",
    "        if stations.count(\"LON\")>0 and stations.count(\"LO2\")>0:\n",
    "            index = stations.index(\"LO2\")\n",
    "            del stations[index]\n",
    "            del networks[index]\n",
    "            del latitudes[index]\n",
    "            del longitudes[index]\n",
    "            del elevations[index]\n",
    "\n",
    "            #Download all waveforms for that event based on stations and times\n",
    "            bulk = [] \n",
    "            for m in range(0, len(networks)):\n",
    "                bulk.append([networks[m], stations[m], '*', '*', time-t_before, time+t_after])\n",
    "            st = client2.get_waveforms_bulk(bulk)\n",
    "\n",
    "            #remove unwanted data\n",
    "            for tr in st:\n",
    "                cha = tr.stats.channel\n",
    "                if cha[0:2] != 'BH' and cha[0:2] != 'EH' and cha[0:2] != 'HH':\n",
    "                    st.remove(tr)\n",
    "                try:\n",
    "                    if len(tr.data)/tr.stats.sampling_rate < 239.9:\n",
    "                        st.remove(tr)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            #resampling the data to 40Hz for each trace\n",
    "            st = resample(st,fs) \n",
    "\n",
    "            #Plotting all traces for one event with channel z, SNR>10, and bandpasses between 2-12Hz\n",
    "            SNR,SNR_weight, no_weight,stas,nets,max_amp_times,durations,data_env_dict,t_diff = [],[],[],[],[],[],[],{},{}\n",
    "            fig = plt.figure(figsize = (11,8), dpi=200)\n",
    "            fig.suptitle('evtID:UW'+ event_ID+associated_volcano)\n",
    "            plt.rcParams.update({'font.size': 20})\n",
    "            ax1 = plt.subplot(1,1,1)\n",
    "            iplot = 0\n",
    "            for i,ii in enumerate(st):\n",
    "                network = ii.stats.network\n",
    "                station = ii.stats.station\n",
    "                ii.detrend(type = 'demean')\n",
    "                ii.filter('bandpass',freqmin=2.0,freqmax=12.0,corners=2,zerophase=True)\n",
    "                cha = ii.stats.channel\n",
    "                starttime = ii.stats.starttime\n",
    "                max_amp_time = np.argmax(ii.data)/fs\n",
    "                signal_window = ii.copy()\n",
    "                noise_window = ii.copy()\n",
    "                signal_window.trim(starttime + t_before - 20, starttime + t_before - 20 + window)\n",
    "                noise_window.trim(starttime + t_before - window -10, starttime + t_before - 10)\n",
    "                snr = (20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                               / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "\n",
    "                if cha[-1] == 'Z' and snr>thr and 100<max_amp_time<200:\n",
    "                    t = ii.times()\n",
    "                    t_diff[network+'.'+station] = starttime-time \n",
    "                    # enveloping the data \n",
    "                    data_envelope = obspy.signal.filter.envelope(ii.data[115*fs:150*fs])\n",
    "                    data_envelope /= np.max(data_envelope)\n",
    "                    data_envelope += iplot*1.5\n",
    "                    # finding the time of max amplitude of each event\n",
    "                    max_amp_times.append(max_amp_time)\n",
    "                    max_amp = np.max(ii.data)      \n",
    "                    # creating envelope data dictionary to calculate picktimes\n",
    "                    data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length)\n",
    "                    data_env_dict[network+'.'+station]= data_envelope\n",
    "                    b,e = 115,150\n",
    "                    ax1.plot(t[b*fs:e*fs],ii.data[b*fs:e*fs]/np.max(np.abs(ii.data))+iplot*1.5)\n",
    "                    ax1.plot(t[115*fs:150*fs], data_envelope, color = 'k')\n",
    "                    ax1.set_xlabel('time (seconds)')\n",
    "                    ax1.set_xlim([b,e])\n",
    "                    ax1.set_yticks([])\n",
    "                    plt.text(t[e*fs], iplot*1.5, 'SNR:'+str(int(snr)))\n",
    "                    plt.text(t[b*fs], iplot*1.5, station)\n",
    "                    iplot = iplot+1\n",
    "                    stas.append(ii.stats.station)\n",
    "                    nets.append(ii.stats.network)\n",
    "                    SNR.append(snr)\n",
    "                    SNR_weight.append(int(snr))\n",
    "                    no_weight.append(1)\n",
    "                else:\n",
    "                    st.remove(ii)\n",
    "\n",
    "            if len(st)<4:  \n",
    "                continue\n",
    "\n",
    "            # get peak frequency of each event\n",
    "            # read and preprocess data\n",
    "            st.taper(max_percentage=0.01,max_length=20)\n",
    "            st.trim(starttime=time-20,endtime=time+30) \n",
    "\n",
    "            # make plot of spectra\n",
    "            char_freq, sharp_weight= [],[]\n",
    "    #         fig,ax = plt.subplots(1,1,figsize=(11,7), dpi = 200)\n",
    "            for i in range(len(stas)):\n",
    "                data = st.select(station=stas[i],component=\"Z\")[0].data*100\n",
    "                f,psd=scipy.signal.welch(data,fs=st[0].stats.sampling_rate,nperseg=81,noverlap=1)\n",
    "                #just get the frequencies within the filter band\n",
    "                above_low_cut = [f>low_cut]\n",
    "                below_high_cut = [f<high_cut]\n",
    "                in_band = np.logical_and(above_low_cut,below_high_cut)[0]\n",
    "                f = f[in_band]\n",
    "                psd = psd[in_band]\n",
    "\n",
    "                # calculate characteristic frequency and report\n",
    "                char_freq_max = f[np.argmax(psd)]\n",
    "                char_freq_mean= np.sum(psd*f)/np.sum(psd)\n",
    "                psd_cumsum = np.cumsum(psd)\n",
    "                psd_sum = np.sum(psd)\n",
    "                char_freq_median = f[np.argmin(np.abs(psd_cumsum-psd_sum/2))]\n",
    "                char_freq.append(char_freq_mean)\n",
    "\n",
    "                plt.rcParams.update({'font.size': 20})\n",
    "    #             ax.plot(f,psd,label=stas[i],linewidth=2)\n",
    "    #             ax.set_xscale('log')\n",
    "    #             ax.set_yscale('log')\n",
    "    #             ax.grid('True')\n",
    "    #             ax.set_xlabel('Frequency [Hz]')\n",
    "    #             ax.set_ylabel('PSD [$(mm/s)^2$/Hz]')\n",
    "    #             ax.vlines(char_freq_mean,ymin=np.min(psd)/10,ymax=np.max(psd)*10,linestyle=\"--\",colors=colors[i])\n",
    "\n",
    "                # weighting the data by the spikiness of the PSD vs frequency graphs\n",
    "                ratio = (np.mean(psd)/np.max(psd))\n",
    "                sharp_weight.append(int(1/(ratio**2)*20))\n",
    "\n",
    "    #         ax.legend() \n",
    "    #         plt.savefig('psd'+event_ID+associated_volcano+'.png')\n",
    "\n",
    "            lats, lons, elevs, r, theta = ([] for i in range(5)) \n",
    "            ref = str(nets[0]+'.'+stas[0])\n",
    "            try:\n",
    "                ref_env = data_env_dict[reference]\n",
    "            except:\n",
    "                ref_env = data_env_dict[ref]\n",
    "\n",
    "            ############ PHASE PICKING ############################\n",
    "            # calculating the picktimes and shift in arrival times using envelope cross_correlation\n",
    "            pick_times, offsets, starttimes = pick_time(time, ref_env, data_env_dict,st,t_diff, t_before, fs) #calculate picktimes\n",
    "            shifts, vals = shift(pick_times, offsets, starttimes, t_diff)\n",
    "\n",
    "            iplot = 0 \n",
    "            durations = []\n",
    "            for i in range(len(stas)):\n",
    "                max_amp_time = max_amp_times[i]\n",
    "                duration = (max_amp_time-vals[i])*2\n",
    "                durations.append(duration)\n",
    "                ax1.vlines(vals[i], ymin = iplot*1.5-.5, ymax = iplot*1.5+.5, color = colors[i])\n",
    "                #plt.text(t[110*fs], iplot*1.5, 'duration:'+str(int(duration))+'s')\n",
    "                a = stations.index(stas[i])\n",
    "                lats.append(latitudes[a])\n",
    "                lons.append(longitudes[a])\n",
    "                elevs.append(elevations[a])\n",
    "                iplot = iplot+1\n",
    "            avg_duration = np.mean(durations)\n",
    "            plt.savefig('wiggles'+event_ID+associated_volcano+'.png')\n",
    "\n",
    "\n",
    "\n",
    "            ############ LOCATION ############################\n",
    "            # input necessary data for grid search\n",
    "            arrivals = shifts\n",
    "            sta_lats = lats\n",
    "            sta_lons= lons\n",
    "\n",
    "            # define grid origin in lat,lon and grid dimensions in m\n",
    "            lat_start = volc_grid[associated_volcano][0]\n",
    "            lon_start = volc_grid[associated_volcano][1]\n",
    "            side_length = volc_grid[associated_volcano][2]\n",
    "\n",
    "            # create the grid of locations\n",
    "            sta_x = []\n",
    "            sta_y = []\n",
    "            for i in range(len(sta_lats)):\n",
    "                x_dist = distance.distance([lat_start,lon_start],[lat_start,sta_lons[i]]).m\n",
    "                y_dist = distance.distance([lat_start,lon_start],[sta_lats[i],lon_start]).m\n",
    "                sta_x.append(x_dist)\n",
    "                sta_y.append(y_dist)\n",
    "            x_vect = np.arange(0, side_length, step)\n",
    "            y_vect = np.arange(0, side_length, step)\n",
    "            t0 = np.arange(0,np.max(arrivals),t_step)\n",
    "\n",
    "            # carry out the gridsearch weighted by SNR\n",
    "            weight = np.array(SNR_weight)/np.max(SNR_weight)\n",
    "            rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "            loc_idx_snr = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "\n",
    "            # gridsearch with no weight\n",
    "            weight = [1 for i in range(len(SNR_weight))]\n",
    "            rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "            loc_idx = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "\n",
    "            # gridsearch weighted with SNR and Slope\n",
    "            # plot DEM\n",
    "            # gives the lower left grid point in the grid search\n",
    "            # gives the left right, bottom, top of the grid\n",
    "            left, right = r_dem_data_dict[associated_volcano]['left'],r_dem_data_dict[associated_volcano]['right']\n",
    "            bottom, top = r_dem_data_dict[associated_volcano]['bottom'],r_dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "            crs = dem_data_dict[associated_volcano]['crs']\n",
    "            data = dem_data_dict[associated_volcano]['data']\n",
    "            volc = rd.rdarray(data, no_data=-9999)\n",
    "            slope = rd.TerrainAttribute(volc,attrib = 'slope_riserun')\n",
    "            info = volc_lat_lon[associated_volcano]\n",
    "            p2 = Proj(crs,preserve_units=False)\n",
    "            p1 = Proj(proj='latlong',preserve_units=False)\n",
    "            # gives the lower left grid point in the grid search\n",
    "            left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "            # gives the left right, bottom, top of the grid\n",
    "            grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "            left, right = r_dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "            bottom, top = r_dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "            a = int((left_x-left)/10)\n",
    "            b = a+2500\n",
    "            c = (slope.shape[0] - int((bottom_y-bottom)/10))-2500\n",
    "            d = slope.shape[0] - int((bottom_y-bottom)/10)\n",
    "\n",
    "            x = np.arange(a,b,1)\n",
    "            y = np.arange(c,d,1)\n",
    "\n",
    "            x2 = np.arange(a,b,10) # every 100m\n",
    "            y2 = np.arange(c,d,10) # every 100m\n",
    "\n",
    "            slope_data = np.array(slope[c:d,a:b])\n",
    "\n",
    "\n",
    "            slope_norm1 = slope_data/np.max(slope_data)\n",
    "\n",
    "            slope_interp_mat = RectBivariateSpline(y,x,slope_norm1, s = 0)\n",
    "            interp = slope_interp_mat(x2,y2)/np.max(slope_interp_mat(x2,y2))*0.9+.1\n",
    "\n",
    "            rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "            loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "            loc_lat_slope, loc_lon_slope, test_d = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n",
    "\n",
    "            # plot heatmap\n",
    "    #         fig,ax = plt.subplots(1,1,figsize=(8,8), dpi = 200)\n",
    "    #         ax.scatter(x_vect[loc_idx[1]],y_vect[loc_idx[2]],s=100,marker='*',c='r')\n",
    "    #         im = ax.imshow(np.log10(rss_mat[loc_idx[0],:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "    #         ax.set_ylabel('(m)')\n",
    "    #         ax.set_ylabel('(m)')\n",
    "    #         cbar = plt.colorbar(im)\n",
    "    #         cbar.ax.tick_params()\n",
    "    #         cbar.set_label('RMS error on location', rotation=270)\n",
    "    #         plt.savefig('heatmap'+ event_ID+associated_volcano+'.png')\n",
    "\n",
    "\n",
    "            # find the latitude and longitude of the location index\n",
    "            loc_lat, loc_lon, d = location(x_vect[loc_idx[1]], y_vect[loc_idx[2]], lat_start, lon_start)\n",
    "            err_thr = np.min(np.log10(rss_mat))+.05\n",
    "            thr_array = np.argwhere(np.log10(rss_mat)<err_thr)\n",
    "            diameter = error_diameter(thr_array)\n",
    "\n",
    "            break\n",
    "            # calculating azimuth for each station with respect to the middle of the volcano\n",
    "            for i in range(len(stas)):\n",
    "                u,b,c = (gps2dist_azimuth(loc_lat, loc_lon, lats[i], lons[i], a=6378137.0, f=0.0033528106647474805))\n",
    "                r.append(u)\n",
    "                theta.append(b)\n",
    "\n",
    "            bin1,bin2,bin3 = [],[],[]\n",
    "            for i in theta:\n",
    "                if 0<=i<=120:\n",
    "                    bin1.append(i)\n",
    "                if 121<=i<=240:\n",
    "                    bin2.append(i)\n",
    "                if 241<=i<=360:\n",
    "                    bin3.append(i)\n",
    "\n",
    "            if bin1 == [] or bin2 == [] or bin3 == []:\n",
    "                continue\n",
    "\n",
    "            #manipulating the data\n",
    "            data = {'azimuth_deg':theta, 'freq':char_freq, 'station':stas, 'distance_m':r, \n",
    "                    'weight':sharp_weight, 'SNR':SNR, 'colors':colors[0:len(stas)]}\n",
    "            DF = pd.DataFrame(data, index = None)\n",
    "            DF2 = DF.sort_values('azimuth_deg')\n",
    "\n",
    "            #Taking out stations that are too close to the location when looking at azimuth \n",
    "            drops = []\n",
    "            for i in range(len(DF2)):\n",
    "                value = DF2.loc[i,'distance_m']\n",
    "                if value < az_thr:\n",
    "                    drops.append(i)\n",
    "            DF3 = DF2.drop(drops)\n",
    "            y_data =  DF3[\"freq\"].values.tolist()\n",
    "            Sta2 = DF3[\"station\"].values.tolist()\n",
    "            dist2 = DF3[\"distance_m\"].values.tolist()\n",
    "            spike_weight = DF3[\"weight\"].values.tolist()\n",
    "            SNR2 = DF3['SNR'].values.tolist()\n",
    "            colors2 = DF3['colors'].values.tolist()\n",
    "            x_data =  np.asarray(DF3[\"azimuth_deg\"].values.tolist())\n",
    "            x_points = np.linspace(0,360, 100)\n",
    "\n",
    "\n",
    "            ################ DIRECTIVITY FIT ##################################\n",
    "            #optimizing parameters to fit data to test_function\n",
    "            params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(x_data), y_data, p0=None)\n",
    "            perr = np.sqrt(np.diag(params_covariance))\n",
    "            std_deviation = str(round(perr[0],9))+','+str(round(perr[1],9))+','+str(round(perr[2],9))\n",
    "            d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "            len_r = int(max(r))\n",
    "\n",
    "            if params[0]<0:\n",
    "                direction = params[1]+pi \n",
    "            else:\n",
    "                direction = params[1]\n",
    "\n",
    "            fmax = max(d)\n",
    "            fmin = min(d)\n",
    "            v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "\n",
    "\n",
    "\n",
    "            # weight the data\n",
    "            # title = 'Sharpness'\n",
    "            v_sharp,direction_sharp,d_sharp = weight_data(x_data,y_data,sharp_weight,test_func,v_s,stas)\n",
    "\n",
    "            # title = 'SNR'\n",
    "            v_snr,direction_snr,d_snr = weight_data(x_data,y_data,SNR_weight,test_func,v_s,stas)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ############### PLOTS ###################\n",
    "            #convert the direction from polar to cartesian coordinates\n",
    "            dy = len_r*np.sin(direction)\n",
    "            dx = len_r*np.cos(direction)     \n",
    "\n",
    "            dy_sharp = len_r*np.sin(direction_sharp)\n",
    "            dx_sharp = len_r*np.cos(direction_sharp)    \n",
    "\n",
    "\n",
    "            dy_snr = len_r*np.sin(direction_snr)\n",
    "            dx_snr = len_r*np.cos(direction_snr) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            fig,ax = plt.subplots(1,1,figsize=(11,8), dpi = 200)\n",
    "            fig.suptitle('Fitted Cosine Curves')       \n",
    "            ax.set_ylabel('characteristic frequency(Hz)')\n",
    "            ax.set_xlabel(('azimuth(degrees)'))\n",
    "            for i in range (0,len(Sta2)):\n",
    "                ax.scatter(x_data[i], y_data[i], s = (SNR_weight[i]**2),label=Sta2[i], color = colors2[i])\n",
    "            ax.plot(x_data,y_data, '--', label='rawdata')\n",
    "            ax.plot(x_points, d, label = 'original')\n",
    "            ax.plot(x_points, d_sharp, label = 'sharpness')\n",
    "            ax.plot(x_points, d_snr, label = 'snr')\n",
    "            ax.legend(loc='upper right', fontsize = 10)\n",
    "            plt.grid(True)\n",
    "            plt.savefig('curves_freq_data'+ event_ID+associated_volcano+'.png')\n",
    "\n",
    "            #making plots of directivity and location\n",
    "            crs = dem_data_dict[associated_volcano]['crs']\n",
    "            data = dem_data_dict[associated_volcano]['data']\n",
    "            info = volc_lat_lon[associated_volcano]\n",
    "            p2 = Proj(crs,preserve_units=False)\n",
    "            p1 = Proj(proj='latlong',preserve_units=False)\n",
    "            # gives the lower left grid point in the grid search\n",
    "            left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "            # gives the left right, bottom, top of the grid\n",
    "            grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "            left, right = dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "            bottom, top = dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "            # convert loc data onto the DEM data\n",
    "            contour_x,contour_y = np.meshgrid(left_x+x_vect,bottom_y+y_vect)\n",
    "            center_x, center_y = transform(p1,p2,info[1],info[0])\n",
    "            loc_x,loc_y=transform(p1,p2,loc_lon,loc_lat)\n",
    "            duration=avg_duration\n",
    "            length_factor = duration/100\n",
    "\n",
    "            fig,ax = plt.subplots(1,1,figsize=(8,11), dpi = 200)\n",
    "            a = ax.imshow(data,extent=[left, right, bottom, top],cmap='gist_earth')\n",
    "            contours = ax.contour(contour_x,contour_y,np.log10(rss_mat[int(loc_idx[0]),:,:].T),cmap='plasma')\n",
    "            ax.scatter(center_x, center_y, s=100,marker='*',c='r')\n",
    "            plt.arrow(loc_x,loc_y,dy*length_factor,dx*length_factor, color='w', width=170, label='no weight')\n",
    "            plt.arrow(loc_x,loc_y,dy_sharp*length_factor,dx_sharp*length_factor, color='k', width=170, label='sharpness')\n",
    "            plt.arrow(loc_x,loc_y,dy_snr*length_factor,dx_snr*length_factor, color='m', width=170, label='snr')\n",
    "            #plotting the stations on top of this as triangles\n",
    "            for i, ii in enumerate(stas):\n",
    "                sta_x,sta_y = transform(p1,p2,lons[i],lats[i])\n",
    "                if left+info[3]<sta_x<right-info[4] and bottom+info[5]<sta_y<top-info[6]:\n",
    "                    ax.plot(sta_x,sta_y, c='k', marker=\"^\")\n",
    "                    ax.text(sta_x,sta_y,ii, c='k', fontsize = 15)\n",
    "\n",
    "            #getting lat and lon tick marks on the axis\n",
    "            tick_lons = lat_lon_dict[associated_volcano]['tick_lons']\n",
    "            tick_lats = lat_lon_dict[associated_volcano]['tick_lats']\n",
    "            ticks_x = []\n",
    "            ticks_y = []\n",
    "            for i in range(len(tick_lons)):\n",
    "                tick_x,tick_y=transform(p1,p2,tick_lons[i],tick_lats[i])\n",
    "                ticks_x.append(tick_x)\n",
    "                ticks_y.append(tick_y)\n",
    "                tick_lons[i]=str(tick_lons[i])\n",
    "                tick_lats[i]=str(tick_lats[i])\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax1 = divider.append_axes('right', size='4%', pad=0.1)\n",
    "            cax2 = divider.append_axes('right', size='4%', pad=1.3)\n",
    "            ax.set_title('Location and Directivity', fontsize = 20)\n",
    "            ax.set_xlabel('longitudes(DD)', fontsize = 15)\n",
    "            ax.set_ylabel('latitudes(DD)', fontsize = 15)\n",
    "            ax.set_xticks(ticks_x)\n",
    "            ax.set_xticklabels(tick_lons, fontsize = 15)\n",
    "            ax.set_yticks(ticks_y)\n",
    "            ax.set_yticklabels(tick_lats, fontsize = 15)\n",
    "            ax.clabel(contours)\n",
    "            cbar = plt.colorbar(a, cax=cax1)\n",
    "            cbar.ax.tick_params(labelsize=10)\n",
    "            cbar.set_label('elevation(m)\\n', rotation=270, labelpad = 13, fontsize = 15)\n",
    "            cbar2 = plt.colorbar(contours, cax=cax2)\n",
    "            cbar2.ax.tick_params(labelsize=10)\n",
    "            cbar2.set_label('RMS error on location\\n', rotation=270, labelpad = 13,fontsize = 15)\n",
    "            ax.set_xlim(left+info[3],right-info[4])\n",
    "            ax.set_ylim(bottom+info[5],top-info[6])\n",
    "            ax.legend(fontsize = 12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('loc_direction'+ event_ID+associated_volcano+'.png',bbox_inches=\"tight\")\n",
    "\n",
    "            # make a dataframe of the data\n",
    "            evt_data = evt_data.append({'event_ID':event_ID, \n",
    "                        'location_latitude': loc_lat,\n",
    "                        'location_longitude': loc_lon,\n",
    "                        'location_uncertainty(m)':diameter/10,\n",
    "                        'origin_time': min(offsets)-int(loc_idx[0]),\n",
    "                        'direction(degrees)':np.rad2deg(direction),\n",
    "                        'direction_sharpness(degrees)':np.rad2deg(direction_sharp),\n",
    "                        'direction_snr(degrees)':np.rad2deg(direction_snr),\n",
    "                        'duration(sec)':avg_duration,\n",
    "                        'params_std_deviation':std_deviation, \n",
    "                        'velocity(m/s)':v, \n",
    "                        'number_of_stations':len(stas)}, ignore_index = True)\n",
    "\n",
    "            dict_temp = {}\n",
    "            for i in range(len(stas)):\n",
    "                dict_temp[stas[i]] = char_freq[i]\n",
    "            print(dict_temp)    \n",
    "            sta_freq = sta_freq.append(dict_temp,ignore_index = True)\n",
    "\n",
    "            evt_data.to_csv('~/surface_events/Event_Data.csv', index=False)\n",
    "            sta_freq.to_csv('~/surface_events/Station_frequency_data.csv', index=False)\n",
    "    #     except:\n",
    "    #         reject_evts = reject_evts.append({'event_ID':[event_ID]}, ignore_index = True)\n",
    "    #         reject_evts.to_csv('~/surface_events/Rejects5.csv', index=False)\n",
    "    #         continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d569229",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'volc_lat_lon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m r_dem_data_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMt_Rainier\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvolc_lat_lon\u001b[49m[name][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m46\u001b[39m:\n\u001b[1;32m      5\u001b[0m     dem \u001b[38;5;241m=\u001b[39m rio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/DEM_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(name)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(name)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.tif\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#washington volcanoes\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     dem_array \u001b[38;5;241m=\u001b[39m dem\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'volc_lat_lon' is not defined"
     ]
    }
   ],
   "source": [
    "#DEM data \n",
    "r_dem_data_dict = {}\n",
    "name = 'Mt_Rainier'\n",
    "if volc_lat_lon[name][0]>46:\n",
    "    dem = rio.open('Data/DEM_data/'+str(name)+'/'+str(name)+'1.tif') #washington volcanoes\n",
    "    dem_array = dem.read(1).astype('float64')\n",
    "    dem_array[dem_array == -32767] = np.nan #gets rid of edge effects\n",
    "    crs = dem.crs\n",
    "\n",
    "r_dem_data_dict[name]={'data':dem_array, 'crs':crs, 'left':dem.bounds[0], 'right':dem.bounds[2], 'bottom':dem.bounds[1], 'top':dem.bounds[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45649539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the avg slope value within one step of the grid search model\n",
    "associated_volcano = 'Mt_Rainier'\n",
    "step_gs = 100 # grid search model step size is 100m\n",
    "\n",
    "# plot DEM\n",
    "crs = r_dem_data_dict[associated_volcano]['crs']\n",
    "data = r_dem_data_dict[associated_volcano]['data']\n",
    "volc = rd.rdarray(data, no_data=-9999)\n",
    "slope = rd.TerrainAttribute(volc,attrib = 'slope_riserun')\n",
    "info = volc_lat_lon[associated_volcano]\n",
    "p2 = Proj(crs,preserve_units=False)\n",
    "p1 = Proj(proj='latlong',preserve_units=False)\n",
    "# gives the lower left grid point in the grid search\n",
    "left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "# gives the left right, bottom, top of the grid\n",
    "grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "left, right = r_dem_data_dict[associated_volcano]['left'],r_dem_data_dict[associated_volcano]['right']\n",
    "bottom, top = r_dem_data_dict[associated_volcano]['bottom'],r_dem_data_dict[associated_volcano]['top']\n",
    "contour_x,contour_y = np.meshgrid(left_x+x_vect,bottom_y+y_vect)\n",
    "center_x, center_y = transform(p1,p2,info[1],info[0])\n",
    "loc_x,loc_y=transform(p1,p2,loc_lon,loc_lat)\n",
    "\n",
    "# looking at where the grid is:\n",
    "x = np.linspace(left_x, left_x+25000, 10)\n",
    "y = np.linspace(bottom_y, bottom_y+25000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d415dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int((left_x-left)/10)\n",
    "b = a+2500\n",
    "c = (slope.shape[0] - int((bottom_y-bottom)/10))-2500\n",
    "d = slope.shape[0] - int((bottom_y-bottom)/10)\n",
    "\n",
    "x = np.arange(a,b,1)\n",
    "y = np.arange(c,d,1)\n",
    "\n",
    "x2 = np.arange(a,b,10) # every 100m\n",
    "y2 = np.arange(c,d,10) # every 100m\n",
    "\n",
    "slope_data = np.array(slope[c:d,a:b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50610daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_norm1 = slope_data/np.max(slope_data)\n",
    "\n",
    "slope_interp_mat = RectBivariateSpline(y,x,slope_norm1, s = 0)\n",
    "interp = slope_interp_mat(x2,y2)/np.max(slope_interp_mat(x2,y2))*0.9+.1\n",
    "\n",
    "rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "loc_lat_slope, loc_lon_slope, j = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc8eca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 5})\n",
    "\n",
    "# weighted by SNR\n",
    "weight = np.array(SNR_weight)/np.max(SNR_weight)\n",
    "rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "loc_idx = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "loc_lat, loc_lon, j = location(x_vect[loc_idx[1]], y_vect[loc_idx[2]], lat_start, lon_start)\n",
    "\n",
    "x2 = np.linspace(a,b,250)\n",
    "y2 = np.linspace(c,d,250)\n",
    "\n",
    "# weighted by SNR and Slope\n",
    "rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "loc_lat_slope, loc_lon_slope, j = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n",
    "\n",
    "# unweighted\n",
    "no_weight = [1,1,1,1,1,1,1,1]\n",
    "rss_mat_nw = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,no_weight)\n",
    "loc_idx_nw = np.unravel_index([np.argmin(rss_mat_nw)], rss_mat_nw.shape)\n",
    "loc_lat_nw, loc_lon_nw, j = location(x_vect[loc_idx_nw[1]], y_vect[loc_idx_nw[2]], lat_start, lon_start)\n",
    "\n",
    "\n",
    "# plotting the results\n",
    "fig,ax = plt.subplots(3,1,figsize=(6,9), dpi = 180)\n",
    "\n",
    "ax[0].set_title('weighted by SNR: '+str(round(loc_lat,3))+','+str(round(loc_lon,3)))\n",
    "ax[0].scatter(x_vect[loc_idx[1]],y_vect[loc_idx[2]],s=100,marker='*',c='r')\n",
    "im0 = ax[0].imshow(np.log10(rss_mat[loc_idx[0],:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "#im0 = ax[0].imshow(rss_mat[loc_idx[0],:,:].T,origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "ax[0].set_ylabel('(m)')\n",
    "ax[0].set_ylabel('(m)')\n",
    "cbar0 = plt.colorbar(im0, ax = ax[0])\n",
    "cbar0.ax.tick_params()\n",
    "cbar0.set_label('RMS error on location', rotation=270)\n",
    "\n",
    "ax[1].set_title('weighted by SNR and Slope: '+str(round(loc_lat_slope,3))+','+str(round(loc_lon_slope,3)))\n",
    "ax[1].scatter(x_vect[loc_idx_slope[1]],y_vect[loc_idx_slope[2]],s=100,marker='*',c='r')\n",
    "im1 = ax[1].imshow(np.log10(rss_mat_slope[0,:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "#im1 = ax[1].imshow(rss_mat_slope[0,:,:].T,origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "ax[1].set_ylabel('(m)')\n",
    "ax[1].set_ylabel('(m)')\n",
    "cbar1 = plt.colorbar(im1, ax = ax[1])\n",
    "cbar1.ax.tick_params()\n",
    "cbar1.set_label('RMS error on location', rotation=270)\n",
    "\n",
    "ax[2].set_title('unweighted: '+str(round(loc_lat_nw,3))+','+ str(round(loc_lon_nw,3)))\n",
    "ax[2].scatter(x_vect[loc_idx_nw[1]],y_vect[loc_idx_nw[2]],s=100,marker='*',c='r')\n",
    "im2 = ax[2].imshow(np.log10(rss_mat_nw[0,:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "#im2 = ax[2].imshow(rss_mat_nw[0,:,:].T,origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "ax[2].set_ylabel('(m)')\n",
    "ax[2].set_ylabel('(m)')\n",
    "cbar2 = plt.colorbar(im2, ax = ax[2])\n",
    "cbar2.ax.tick_params()\n",
    "cbar2.set_label('RMS error on location', rotation=270)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo_exo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
