{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event location MORA SUs\n",
    "\n",
    "This notebook takes the phase pickin from phasePicking_MORA notebook and does a simple grid search location if the event epicenter and centroid and save it into a second data frame.\n",
    "\n",
    "Done by Marine Denolle (mdenolle@uw.edu) on 3/21/2024, with the help of undergraduate student Francesca Skene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/data/wsd01/pnwstore/')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "import torch\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volcano Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data includes all stations within 50km of each volcano and the lat, lon, elev of each station\n",
    "df = pd.read_csv('../data/station/Volcano_Metadata_50km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "associated_volcano = 'Mt_Rainier'\n",
    "        \n",
    "#get info for stations within 50km of volcano that event ocurred at\n",
    "stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center latitude, center longitude, elevation(m), left_trim, right_trim, bottom_trim, top_trim \n",
    "volc_lat_lon = {}\n",
    "volc_lat_lon['Mt_Rainier'] = [46.8528857, -121.7603744, 4392.5]\n",
    "#Find the lower left corner and grid size based on volcano elevation\n",
    "# define grid origin in lat,lon and grid dimensions in m\n",
    "lon_start = -122 #volc_lat_lon[associated_volcano][0]\n",
    "lon_end = -121.5 #volc_lat_lon[associated_volcano][0]\n",
    "lat_start = 46.6 #volc_lat_lon[associated_volcano][1]\n",
    "lat_end = 47 #volc_lat_lon[associated_volcano][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read pick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.read_csv(\"../data/events/MLPicks_MtRainier.csv\")\n",
    "\n",
    "############ LOCATION ############################\n",
    "# input necessary data for grid search\n",
    "arrivals = dff['smb_peak'].values\n",
    "# arrivals = dff[dff['event_ID']==event_ID]['smb_peak'].values\n",
    "sta_lats = dff['lats'].values\n",
    "sta_lons = dff['lons'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "\n",
    "\n",
    "# # Define the projection: UTM zone 11 for Washington state\n",
    "# proj = pyproj.Proj(proj='utm', zone=11, ellps='WGS84')\n",
    "\n",
    "# # Convert lat/long to Cartesian in meters\n",
    "# xsta, ysta = proj(sta_lons, sta_lats)\n",
    "\n",
    "# cmap = plt.get_cmap('hot_r')\n",
    "# ik=np.where(arrivals>0)[0]\n",
    "# for i in ik:\n",
    "#     tt = arrivals[i]-np.min(arrivals[ik])\n",
    "#     nmax=np.max(arrivals[ik])-np.min(arrivals[ik])\n",
    "#     plt.plot(xsta[i],ysta[i],'o',color=cmap(tt/nmax),markersize=10,markeredgecolor='k')\n",
    "#     plt.text(xsta[i],ysta[i],stas[i]+\":\"+str(np.ceil(tt))+\" s\")\n",
    "#     plt.axis('equal')\n",
    "# plt.title(\"Travel time Relative to RCM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ista =np.where(arrivals>-t_before+0.1)[0]\n",
    "t_best,lon_best,lat_best = gridsearch_parallel(lat_start,lon_start,\\\n",
    "                                              lat_end,lon_end,\\\n",
    "                                                sta_lats[ista],sta_lons[ista],arrivals[ista],vs=1000,\n",
    "                                                weight=dff['snr'].values[ista]**2)\n",
    "\n",
    "print(t_best,lon_best,lat_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## location of centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_before' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ista \u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(arrivals\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[43mt_before\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m t_best,mlon_best,mlat_best \u001b[38;5;241m=\u001b[39m gridsearch_parallel(lat_start,lon_start,\\\n\u001b[1;32m      3\u001b[0m                                               lat_end,lon_end,\\\n\u001b[1;32m      4\u001b[0m                                                 sta_lats[ista],sta_lons[ista],dff[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[ista],vs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(mlon_best,mlat_best)\n",
      "\u001b[0;31mNameError\u001b[0m: name 't_before' is not defined"
     ]
    }
   ],
   "source": [
    "ista =np.where(arrivals>-t_before+0.1)[0]\n",
    "t_best,mlon_best,mlat_best = gridsearch_parallel(lat_start,lon_start,\\\n",
    "                                              lat_end,lon_end,\\\n",
    "                                                sta_lats[ista],sta_lons[ista],dff['max_time'].values[ista],vs=1000)\n",
    "print(mlon_best,mlat_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing imshow plot\n",
    "fig, ax = plt.subplots(figsize=(16, 10), dpi=400)\n",
    "im = plt.imshow(np.squeeze(rss_mat[0,:,:].T),extent=[lon_start,lon_end,lat_start,lat_end], cmap='hsv', interpolation='nearest',origin='lower')\n",
    "\n",
    "# Add contour lines\n",
    "num_contour_lines = 20  # Change this to the number of contour lines you want\n",
    "contours = plt.contour(np.squeeze(rss_mat[0,:,:].T), num_contour_lines, extent=[lon_start,lon_end,lat_start,lat_end], colors='black')\n",
    "plt.clabel(contours, inline=True, fontsize=8)\n",
    "plt.plot(lon_best,lat_best,'o',color='k',markersize=10)\n",
    "plt.plot(mlon_best,mlat_best,'s',color='k',markersize=10)\n",
    "plt.plot(clon_best,clat_best,'p',color='k',markersize=10)\n",
    "cmap1 = plt.get_cmap('hot_r')\n",
    "ik=np.where(arrivals>0)[0]\n",
    "for i in ik:\n",
    "    tt = arrivals[i]-np.min(arrivals[ik])\n",
    "    nmax=np.max(arrivals[ik])-np.min(arrivals[ik])\n",
    "    plt.plot(sta_lons[i],sta_lats[i],'o',color=cmap1(tt/nmax),markersize=20,markeredgecolor='k')\n",
    "    plt.text(sta_lons[i],sta_lats[i],stas[i]+\":\"+str(np.ceil(tt))+\" s\")\n",
    "plt.title(\"Travel time Relative to RCM\")\n",
    "plt.xlim([-122,-121.5]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, the location works but seems quite innacurate: why is the location not closer to the first stations that saw it?\n",
    "We will do a bootstrap grid search and find an enemble of solution and take the median location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ista =np.where(arrivals>-t_before+0.1)[0]\n",
    "# # Number of bootstrap samples\n",
    "# n_bootstrap = 100\n",
    "\n",
    "# # Initialize an array to hold the bootstrap results\n",
    "# bootstrap_results = []\n",
    "# llon_best=np.zeros(n_bootstrap)\n",
    "# llat_best=np.zeros(n_bootstrap)\n",
    "# for ii in range(n_bootstrap):\n",
    "#     # Generate a bootstrap sample from ista\n",
    "#     ista_sample = np.random.choice(ista, size=len(ista), replace=True)\n",
    "#     # ista_sample=ista\n",
    "#     # Perform the grid search with the bootstrap sample\n",
    "#     t_best, lon_best, lat_best = gridsearch_parallel(lat_start, lon_start, lat_end, lon_end,\\\n",
    "#                                                                 sta_lats[ista_sample], sta_lons[ista_sample],\\\n",
    "#                                                                     arrivals[ista_sample])\n",
    "\n",
    "#     # Store the results\n",
    "#     llon_best[ii] = lon_best\n",
    "#     llat_best[ii] = lat_best\n",
    "#     print(llat_best[ii],llon_best[ii])\n",
    "#     break\n",
    "# bootstrap_lon_best=np.mean(llon_best)\n",
    "# bootstrap_lat_best=np.mean(llat_best)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some experimentation, we find that the locations found by the grid search are highly dependent on the choice of stations used. Weighting with the SNR brings even more variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Existing imshow plot\n",
    "# fig, ax = plt.subplots(figsize=(16, 10), dpi=400)\n",
    "# im = plt.imshow(np.squeeze(rss_mat[0,:,:].T),extent=[lon_start,lon_end,lat_start,lat_end], cmap='hsv', interpolation='nearest',origin='lower')\n",
    "\n",
    "# # Add contour lines\n",
    "# num_contour_lines = 20  # Change this to the number of contour lines you want\n",
    "# contours = plt.contour(np.squeeze(rss_mat[0,:,:].T), num_contour_lines, extent=[lon_start,lon_end,lat_start,lat_end], colors='black')\n",
    "# plt.clabel(contours, inline=True, fontsize=8)\n",
    "# plt.plot(llon_best,llat_best,'o',color='k',markersize=6)\n",
    "# plt.plot(bootstrap_lon_best,bootstrap_lat_best,'o',color='k',markersize=10)\n",
    "# cmap1 = plt.get_cmap('hot_r')\n",
    "# ik=np.where(arrivals>0)[0]\n",
    "# for i in ik:\n",
    "#     tt = arrivals[i]-np.min(arrivals[ik])\n",
    "#     nmax=np.max(arrivals[ik])-np.min(arrivals[ik])\n",
    "#     plt.plot(sta_lons[i],sta_lats[i],'o',color=cmap1(tt/nmax),markersize=dff[dff['stas']==stas[i]]['snr'].values,markeredgecolor='k')\n",
    "#     plt.text(sta_lons[i],sta_lats[i],stas[i]+\":\"+str(np.ceil(tt))+\" s\")\n",
    "# plt.title(\"Travel time Relative to RCM, marker size shows SNR of waveform\")\n",
    "# plt.xlim([-122,-121.5]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay with the travel time to compare with the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the source location, calculate travel times\n",
    "proj = pyproj.Proj(proj='utm', zone=11, ellps='WGS84')\n",
    "\n",
    "if lon_start<0: \n",
    "    lon_start1 = lon_start+360\n",
    "    lon_end1 = lon_end + 360\n",
    "\n",
    "# Convert lat/long to Cartesian in meters\n",
    "x_step=100\n",
    "x1,y1=proj(lon_start,lat_start)\n",
    "x2,y2=proj(lon_end,lat_end)\n",
    "su_x,su_y=proj(lon_best,lat_best)\n",
    "# Generate the x and y coordinates for the grid\n",
    "x_coords = np.arange(x1, x2, x_step)\n",
    "y_coords = np.arange(y1, y2, x_step)\n",
    "vs=3000\n",
    "synthetic_tt = np.zeros((len(x_coords),len(y_coords)))    \n",
    "for i in range(len(x_coords)):\n",
    "    for j in range(len(y_coords)):\n",
    "        synthetic_tt[i,j] = np.sqrt( (x_coords[i] - su_x  )**2 + (y_coords[j] - su_y)**2  ) / vs \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing imshow plot\n",
    "fig, ax = plt.subplots(figsize=(16, 10), dpi=400)\n",
    "im = plt.imshow(np.squeeze(rss_mat[0,:,:].T),extent=[lon_start,lon_end,lat_start,lat_end], cmap='hsv', interpolation='nearest',origin='lower')\n",
    "\n",
    "\n",
    "# Add contour lines\n",
    "num_contour_lines = 20  # Change this to the number of contour lines you want\n",
    "\n",
    "contours = plt.contour(synthetic_tt.T, num_contour_lines, extent=[lon_start,lon_end,lat_start,lat_end], colors='black')\n",
    "# contours = plt.contour(np.squeeze(rss_mat[0,:,:].T), num_contour_lines, extent=[lon_start,lon_end,lat_start,lat_end], colors='black')\n",
    "# contours = plt.contour(synthetic_tt, num_contour_lines, extent=[lon_start,lon_end,lat_start,lat_end], colors='black')\n",
    "plt.clabel(contours, inline=True, fontsize=8)\n",
    "# plt.plot(bootstrap_lon_best,bootstrap_lat_best,'o',color='k',markersize=10)\n",
    "cmap1 = plt.get_cmap('hot_r')\n",
    "ik=np.where(arrivals>0)[0]\n",
    "for i in ik:\n",
    "    tt = arrivals[i]-np.min(arrivals[ik])\n",
    "    nmax=np.max(arrivals[ik])-np.min(arrivals[ik])\n",
    "    plt.plot(sta_lons[i],sta_lats[i],'o',color=cmap1(tt/nmax),markersize=dff[dff['stas']==stas[i]]['snr'].values,markeredgecolor='k')\n",
    "    plt.text(sta_lons[i],sta_lats[i],stas[i]+\":\"+str(np.ceil(tt))+\" s\")\n",
    "\n",
    "plt.plot(lon_best,lat_best,'o',color='k',markersize=10)\n",
    "plt.title(\"Travel time Relative to RCM, marker size shows SNR of waveform\")\n",
    "plt.xlim([-122,-121.5]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now consider weighing with the DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEM data \n",
    "import rasterio as rio\n",
    "dem = rio.open('../data/geospatial/Mt_Rainier/Mt_Rainier.tif') #washington volcanoes\n",
    "dem_array = dem.read(1).astype('float64')\n",
    "dem_array[dem_array == -32767] = np.nan #gets rid of edge effects\n",
    "crs = dem.crs\n",
    "#     else:\n",
    "#         dem = rio.open('Data/DEM_data/'+str(name)+'/_w001001.adf') #oregon volcanoes\n",
    "#         dem_array = dem.read(1).astype('float64')\n",
    "#         dem_array[dem_array == -3.4028234663852886e+38] = np.nan #gets rid of edge effects\n",
    "#         crs = dem.crs\n",
    "# #     volc = rd.rdarray(dem_array, no_data=-9999)\n",
    "#     slope = rd.TerrainAttribute(volc,attrib = 'slope_riserun')\n",
    "#     aspect = rd.TerrainAttribute(volc, attrib = 'aspect')\n",
    "#     dem_data_dict[name] = {'data':dem_array, 'elevation':volc, 'slope':slope, 'aspect':aspect}\n",
    "dem_data_dict={'data':dem_array, 'crs':crs, 'left':dem.bounds[0], 'right':dem.bounds[2], 'bottom':dem.bounds[1], 'top':dem.bounds[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.imshow(dem_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reproject the DEM onto our own grid (x_coord, y_coord)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import reproject, Resampling\n",
    "\n",
    "new_transform = rio.transform.from_origin(-180, 90, 0.1, 0.1)  # Change this to your desired grid\n",
    "new_crs = dem.crs  # Use the same CRS as the input data\n",
    "new_shape = (1800, 3600)  # Change this to your desired shape\n",
    "\n",
    "# Create an output array\n",
    "output_data = np.empty(new_shape, dtype=dem_array.dtype)\n",
    "\n",
    "# Reproject the data\n",
    "reproject(\n",
    "    input_data,\n",
    "    output_data,\n",
    "    src_transform=src.transform,\n",
    "    src_crs=src.crs,\n",
    "    dst_transform=new_transform,\n",
    "    dst_crs=new_crs,\n",
    "    resampling=Resampling.nearest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making plots of directivity and location\n",
    "crs = dem_data_dict[associated_volcano]['crs']\n",
    "data = dem_data_dict[associated_volcano]['data']\n",
    "info = volc_lat_lon[associated_volcano]\n",
    "p2 = Proj(crs,preserve_units=False)\n",
    "p1 = Proj(proj='latlong',preserve_units=False)\n",
    "# gives the lower left grid point in the grid search\n",
    "left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "# gives the left right, bottom, top of the grid\n",
    "grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "left, right = dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "bottom, top = dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "contour_x,contour_y = np.meshgrid(left_x+x_vect,bottom_y+y_vect)\n",
    "center_x, center_y = transform(p1,p2,info[1],info[0])\n",
    "loc_x,loc_y=transform(p1,p2,loc_lon,loc_lat)\n",
    "duration=avg_duration\n",
    "length_factor = duration/100\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,11), dpi = 200)\n",
    "a = ax.imshow(data,extent=[left, right, bottom, top],cmap='gist_earth')\n",
    "contours = ax.contour(contour_x,contour_y,np.log10(rss_mat[int(loc_idx[0]),:,:].T),cmap='plasma')\n",
    "ax.scatter(center_x, center_y, s=100,marker='*',c='r')\n",
    "plt.arrow(loc_x,loc_y,dy*length_factor,dx*length_factor, color='w', width=170, label='no weight')\n",
    "plt.arrow(loc_x,loc_y,dy_sharp*length_factor,dx_sharp*length_factor, color='k', width=170, label='sharpness')\n",
    "plt.arrow(loc_x,loc_y,dy_snr*length_factor,dx_snr*length_factor, color='m', width=170, label='snr')\n",
    "#plotting the stations on top of this as triangles\n",
    "for i, ii in enumerate(stas):\n",
    "    sta_x,sta_y = transform(p1,p2,lons[i],lats[i])\n",
    "    if left+info[3]<sta_x<right-info[4] and bottom+info[5]<sta_y<top-info[6]:\n",
    "        ax.plot(sta_x,sta_y, c='k', marker=\"^\")\n",
    "        ax.text(sta_x,sta_y,ii, c='k', fontsize = 15)\n",
    "\n",
    "#getting lat and lon tick marks on the axis\n",
    "tick_lons = lat_lon_dict[associated_volcano]['tick_lons']\n",
    "tick_lats = lat_lon_dict[associated_volcano]['tick_lats']\n",
    "ticks_x = []\n",
    "ticks_y = []\n",
    "for i in range(len(tick_lons)):\n",
    "    tick_x,tick_y=transform(p1,p2,tick_lons[i],tick_lats[i])\n",
    "    ticks_x.append(tick_x)\n",
    "    ticks_y.append(tick_y)\n",
    "    tick_lons[i]=str(tick_lons[i])\n",
    "    tick_lats[i]=str(tick_lats[i])\n",
    "divider = make_axes_locatable(ax)\n",
    "cax1 = divider.append_axes('right', size='4%', pad=0.1)\n",
    "cax2 = divider.append_axes('right', size='4%', pad=1.3)\n",
    "ax.set_title('Location and Directivity', fontsize = 20)\n",
    "ax.set_xlabel('longitudes(DD)', fontsize = 15)\n",
    "ax.set_ylabel('latitudes(DD)', fontsize = 15)\n",
    "ax.set_xticks(ticks_x)\n",
    "ax.set_xticklabels(tick_lons, fontsize = 15)\n",
    "ax.set_yticks(ticks_y)\n",
    "ax.set_yticklabels(tick_lats, fontsize = 15)\n",
    "ax.clabel(contours)\n",
    "cbar = plt.colorbar(a, cax=cax1)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "cbar.set_label('elevation(m)\\n', rotation=270, labelpad = 13, fontsize = 15)\n",
    "cbar2 = plt.colorbar(contours, cax=cax2)\n",
    "cbar2.ax.tick_params(labelsize=10)\n",
    "cbar2.set_label('RMS error on location\\n', rotation=270, labelpad = 13,fontsize = 15)\n",
    "ax.set_xlim(left+info[3],right-info[4])\n",
    "ax.set_ylim(bottom+info[5],top-info[6])\n",
    "ax.legend(fontsize = 12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('loc_direction'+ event_ID+associated_volcano+'.png',bbox_inches=\"tight\")\n",
    "\n",
    "# make a dataframe of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the avg slope value within one step of the grid search model\n",
    "associated_volcano = 'Mt_Rainier'\n",
    "step_gs = 100 # grid search model step size is 100m\n",
    "\n",
    "# plot DEM\n",
    "crs = r_dem_data_dict[associated_volcano]['crs']\n",
    "data = r_dem_data_dict[associated_volcano]['data']\n",
    "volc = rd.rdarray(data, no_data=-9999)\n",
    "slope = rd.TerrainAttribute(volc,attrib = 'slope_riserun')\n",
    "info = volc_lat_lon[associated_volcano]\n",
    "p2 = Proj(crs,preserve_units=False)\n",
    "p1 = Proj(proj='latlong',preserve_units=False)\n",
    "# gives the lower left grid point in the grid search\n",
    "left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "# gives the left right, bottom, top of the grid\n",
    "grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "left, right = r_dem_data_dict[associated_volcano]['left'],r_dem_data_dict[associated_volcano]['right']\n",
    "bottom, top = r_dem_data_dict[associated_volcano]['bottom'],r_dem_data_dict[associated_volcano]['top']\n",
    "contour_x,contour_y = np.meshgrid(left_x+x_vect,bottom_y+y_vect)\n",
    "center_x, center_y = transform(p1,p2,info[1],info[0])\n",
    "loc_x,loc_y=transform(p1,p2,loc_lon,loc_lat)\n",
    "\n",
    "# looking at where the grid is:\n",
    "x = np.linspace(left_x, left_x+25000, 10)\n",
    "y = np.linspace(bottom_y, bottom_y+25000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int((left_x-left)/10)\n",
    "b = a+2500\n",
    "c = (slope.shape[0] - int((bottom_y-bottom)/10))-2500\n",
    "d = slope.shape[0] - int((bottom_y-bottom)/10)\n",
    "\n",
    "x = np.arange(a,b,1)\n",
    "y = np.arange(c,d,1)\n",
    "\n",
    "x2 = np.arange(a,b,10) # every 100m\n",
    "y2 = np.arange(c,d,10) # every 100m\n",
    "\n",
    "slope_data = np.array(slope[c:d,a:b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_norm1 = slope_data/np.max(slope_data)\n",
    "\n",
    "slope_interp_mat = RectBivariateSpline(y,x,slope_norm1, s = 0)\n",
    "interp = slope_interp_mat(x2,y2)/np.max(slope_interp_mat(x2,y2))*0.9+.1\n",
    "\n",
    "rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "loc_lat_slope, loc_lon_slope, j = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 5})\n",
    "\n",
    "# weighted by SNR\n",
    "weight = np.array(SNR_weight)/np.max(SNR_weight)\n",
    "rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "loc_idx = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "loc_lat, loc_lon, j = location(x_vect[loc_idx[1]], y_vect[loc_idx[2]], lat_start, lon_start)\n",
    "\n",
    "x2 = np.linspace(a,b,250)\n",
    "y2 = np.linspace(c,d,250)\n",
    "\n",
    "# weighted by SNR and Slope\n",
    "rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "loc_lat_slope, loc_lon_slope, j = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n",
    "\n",
    "# unweighted\n",
    "no_weight = [1,1,1,1,1,1,1,1]\n",
    "rss_mat_nw = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,no_weight)\n",
    "loc_idx_nw = np.unravel_index([np.argmin(rss_mat_nw)], rss_mat_nw.shape)\n",
    "loc_lat_nw, loc_lon_nw, j = location(x_vect[loc_idx_nw[1]], y_vect[loc_idx_nw[2]], lat_start, lon_start)\n",
    "\n",
    "\n",
    "# plotting the results\n",
    "fig,ax = plt.subplots(3,1,figsize=(6,9), dpi = 180)\n",
    "\n",
    "ax[0].set_title('weighted by SNR: '+str(round(loc_lat,3))+','+str(round(loc_lon,3)))\n",
    "ax[0].scatter(x_vect[loc_idx[1]],y_vect[loc_idx[2]],s=100,marker='*',c='r')\n",
    "im0 = ax[0].imshow(np.log10(rss_mat[loc_idx[0],:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "#im0 = ax[0].imshow(rss_mat[loc_idx[0],:,:].T,origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "ax[0].set_ylabel('(m)')\n",
    "ax[0].set_ylabel('(m)')\n",
    "cbar0 = plt.colorbar(im0, ax = ax[0])\n",
    "cbar0.ax.tick_params()\n",
    "cbar0.set_label('RMS error on location', rotation=270)\n",
    "\n",
    "ax[1].set_title('weighted by SNR and Slope: '+str(round(loc_lat_slope,3))+','+str(round(loc_lon_slope,3)))\n",
    "ax[1].scatter(x_vect[loc_idx_slope[1]],y_vect[loc_idx_slope[2]],s=100,marker='*',c='r')\n",
    "im1 = ax[1].imshow(np.log10(rss_mat_slope[0,:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "#im1 = ax[1].imshow(rss_mat_slope[0,:,:].T,origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "ax[1].set_ylabel('(m)')\n",
    "ax[1].set_ylabel('(m)')\n",
    "cbar1 = plt.colorbar(im1, ax = ax[1])\n",
    "cbar1.ax.tick_params()\n",
    "cbar1.set_label('RMS error on location', rotation=270)\n",
    "\n",
    "ax[2].set_title('unweighted: '+str(round(loc_lat_nw,3))+','+ str(round(loc_lon_nw,3)))\n",
    "ax[2].scatter(x_vect[loc_idx_nw[1]],y_vect[loc_idx_nw[2]],s=100,marker='*',c='r')\n",
    "im2 = ax[2].imshow(np.log10(rss_mat_nw[0,:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "#im2 = ax[2].imshow(rss_mat_nw[0,:,:].T,origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "ax[2].set_ylabel('(m)')\n",
    "ax[2].set_ylabel('(m)')\n",
    "cbar2 = plt.colorbar(im2, ax = ax[2])\n",
    "cbar2.ax.tick_params()\n",
    "cbar2.set_label('RMS error on location', rotation=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#         # carry out the gridsearch weighted by SNR\n",
    "#         weight = np.array(SNR_weight)/np.max(SNR_weight)\n",
    "#         rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "#         loc_idx_snr = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "\n",
    "#         # gridsearch with no weight\n",
    "#         weight = [1 for i in range(len(SNR_weight))]\n",
    "#         rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "#         loc_idx = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "\n",
    "#         # gridsearch weighted with SNR and Slope\n",
    "#         # plot DEM\n",
    "#         # gives the lower left grid point in the grid search\n",
    "#         # gives the left right, bottom, top of the grid\n",
    "#         left, right = r_dem_data_dict[associated_volcano]['left'],r_dem_data_dict[associated_volcano]['right']\n",
    "#         bottom, top = r_dem_data_dict[associated_volcano]['bottom'],r_dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "#         crs = dem_data_dict[associated_volcano]['crs']\n",
    "#         data = dem_data_dict[associated_volcano]['data']\n",
    "#         volc = rd.rdarray(data, no_data=-9999)\n",
    "#         slope = rd.TerrainAttribute(volc,attrib = 'slope_riserun')\n",
    "#         info = volc_lat_lon[associated_volcano]\n",
    "#         p2 = Proj(crs,preserve_units=False)\n",
    "#         p1 = Proj(proj='latlong',preserve_units=False)\n",
    "#         # gives the lower left grid point in the grid search\n",
    "#         left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "#         # gives the left right, bottom, top of the grid\n",
    "#         grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "#         left, right = r_dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "#         bottom, top = r_dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "#         a = int((left_x-left)/10)\n",
    "#         b = a+2500\n",
    "#         c = (slope.shape[0] - int((bottom_y-bottom)/10))-2500\n",
    "#         d = slope.shape[0] - int((bottom_y-bottom)/10)\n",
    "\n",
    "#         x = np.arange(a,b,1)\n",
    "#         y = np.arange(c,d,1)\n",
    "\n",
    "#         x2 = np.arange(a,b,10) # every 100m\n",
    "#         y2 = np.arange(c,d,10) # every 100m\n",
    "\n",
    "#         slope_data = np.array(slope[c:d,a:b])\n",
    "\n",
    "\n",
    "#         slope_norm1 = slope_data/np.max(slope_data)\n",
    "\n",
    "#         slope_interp_mat = RectBivariateSpline(y,x,slope_norm1, s = 0)\n",
    "#         interp = slope_interp_mat(x2,y2)/np.max(slope_interp_mat(x2,y2))*0.9+.1\n",
    "\n",
    "#         rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "#         loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "#         loc_lat_slope, loc_lon_slope, test_d = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n",
    "\n",
    "#         # plot heatmap\n",
    "# #         fig,ax = plt.subplots(1,1,figsize=(8,8), dpi = 200)\n",
    "# #         ax.scatter(x_vect[loc_idx[1]],y_vect[loc_idx[2]],s=100,marker='*',c='r')\n",
    "# #         im = ax.imshow(np.log10(rss_mat[loc_idx[0],:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "# #         ax.set_ylabel('(m)')\n",
    "# #         ax.set_ylabel('(m)')\n",
    "# #         cbar = plt.colorbar(im)\n",
    "# #         cbar.ax.tick_params()\n",
    "# #         cbar.set_label('RMS error on location', rotation=270)\n",
    "# #         plt.savefig('heatmap'+ event_ID+associated_volcano+'.png')\n",
    "\n",
    "\n",
    "#         # find the latitude and longitude of the location index\n",
    "#         loc_lat, loc_lon, d = location(x_vect[loc_idx[1]], y_vect[loc_idx[2]], lat_start, lon_start)\n",
    "#         err_thr = np.min(np.log10(rss_mat))+.05\n",
    "#         thr_array = np.argwhere(np.log10(rss_mat)<err_thr)\n",
    "#         diameter = error_diameter(thr_array)\n",
    "\n",
    "#         break\n",
    "#         # calculating azimuth for each station with respect to the middle of the volcano\n",
    "#         for i in range(len(stas)):\n",
    "#             u,b,c = (gps2dist_azimuth(loc_lat, loc_lon, lats[i], lons[i], a=6378137.0, f=0.0033528106647474805))\n",
    "#             r.append(u)\n",
    "#             theta.append(b)\n",
    "\n",
    "#         bin1,bin2,bin3 = [],[],[]\n",
    "#         for i in theta:\n",
    "#             if 0<=i<=120:\n",
    "#                 bin1.append(i)\n",
    "#             if 121<=i<=240:\n",
    "#                 bin2.append(i)\n",
    "#             if 241<=i<=360:\n",
    "#                 bin3.append(i)\n",
    "\n",
    "#         if bin1 == [] or bin2 == [] or bin3 == []:\n",
    "#             continue\n",
    "\n",
    "#         #manipulating the data\n",
    "#         data = {'azimuth_deg':theta, 'freq':char_freq, 'station':stas, 'distance_m':r, \n",
    "#                 'weight':sharp_weight, 'SNR':SNR, 'colors':colors[0:len(stas)]}\n",
    "#         DF = pd.DataFrame(data, index = None)\n",
    "#         DF2 = DF.sort_values('azimuth_deg')\n",
    "\n",
    "#         #Taking out stations that are too close to the location when looking at azimuth \n",
    "#         drops = []\n",
    "#         for i in range(len(DF2)):\n",
    "#             value = DF2.loc[i,'distance_m']\n",
    "#             if value < az_thr:\n",
    "#                 drops.append(i)\n",
    "#         DF3 = DF2.drop(drops)\n",
    "#         y_data =  DF3[\"freq\"].values.tolist()\n",
    "#         Sta2 = DF3[\"station\"].values.tolist()\n",
    "#         dist2 = DF3[\"distance_m\"].values.tolist()\n",
    "#         spike_weight = DF3[\"weight\"].values.tolist()\n",
    "#         SNR2 = DF3['SNR'].values.tolist()\n",
    "#         colors2 = DF3['colors'].values.tolist()\n",
    "#         x_data =  np.asarray(DF3[\"azimuth_deg\"].values.tolist())\n",
    "#         x_points = np.linspace(0,360, 100)\n",
    "\n",
    "\n",
    "#         ################ DIRECTIVITY FIT ##################################\n",
    "#         #optimizing parameters to fit data to test_function\n",
    "#         params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(x_data), y_data, p0=None)\n",
    "#         perr = np.sqrt(np.diag(params_covariance))\n",
    "#         std_deviation = str(round(perr[0],9))+','+str(round(perr[1],9))+','+str(round(perr[2],9))\n",
    "#         d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "#         len_r = int(max(r))\n",
    "\n",
    "#         if params[0]<0:\n",
    "#             direction = params[1]+pi \n",
    "#         else:\n",
    "#             direction = params[1]\n",
    "\n",
    "#         fmax = max(d)\n",
    "#         fmin = min(d)\n",
    "#         v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "\n",
    "\n",
    "\n",
    "#         # weight the data\n",
    "#         # title = 'Sharpness'\n",
    "#         v_sharp,direction_sharp,d_sharp = weight_data(x_data,y_data,sharp_weight,test_func,v_s,stas)\n",
    "\n",
    "#         # title = 'SNR'\n",
    "#         v_snr,direction_snr,d_snr = weight_data(x_data,y_data,SNR_weight,test_func,v_s,stas)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         ############### PLOTS ###################\n",
    "#         #convert the direction from polar to cartesian coordinates\n",
    "#         dy = len_r*np.sin(direction)\n",
    "#         dx = len_r*np.cos(direction)     \n",
    "\n",
    "#         dy_sharp = len_r*np.sin(direction_sharp)\n",
    "#         dx_sharp = len_r*np.cos(direction_sharp)    \n",
    "\n",
    "\n",
    "#         dy_snr = len_r*np.sin(direction_snr)\n",
    "#         dx_snr = len_r*np.cos(direction_snr) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         fig,ax = plt.subplots(1,1,figsize=(11,8), dpi = 200)\n",
    "#         fig.suptitle('Fitted Cosine Curves')       \n",
    "#         ax.set_ylabel('characteristic frequency(Hz)')\n",
    "#         ax.set_xlabel(('azimuth(degrees)'))\n",
    "#         for i in range (0,len(Sta2)):\n",
    "#             ax.scatter(x_data[i], y_data[i], s = (SNR_weight[i]**2),label=Sta2[i], color = colors2[i])\n",
    "#         ax.plot(x_data,y_data, '--', label='rawdata')\n",
    "#         ax.plot(x_points, d, label = 'original')\n",
    "#         ax.plot(x_points, d_sharp, label = 'sharpness')\n",
    "#         ax.plot(x_points, d_snr, label = 'snr')\n",
    "#         ax.legend(loc='upper right', fontsize = 10)\n",
    "#         plt.grid(True)\n",
    "#         plt.savefig('curves_freq_data'+ event_ID+associated_volcano+'.png')\n",
    "\n",
    "#         #making plots of directivity and location\n",
    "#         crs = dem_data_dict[associated_volcano]['crs']\n",
    "#         data = dem_data_dict[associated_volcano]['data']\n",
    "#         info = volc_lat_lon[associated_volcano]\n",
    "#         p2 = Proj(crs,preserve_units=False)\n",
    "#         p1 = Proj(proj='latlong',preserve_units=False)\n",
    "#         # gives the lower left grid point in the grid search\n",
    "#         left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "#         # gives the left right, bottom, top of the grid\n",
    "#         grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "#         left, right = dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "#         bottom, top = dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "#         # convert loc data onto the DEM data\n",
    "#         contour_x,contour_y = np.meshgrid(left_x+x_vect,bottom_y+y_vect)\n",
    "#         center_x, center_y = transform(p1,p2,info[1],info[0])\n",
    "#         loc_x,loc_y=transform(p1,p2,loc_lon,loc_lat)\n",
    "#         duration=avg_duration\n",
    "#         length_factor = duration/100\n",
    "\n",
    "#         fig,ax = plt.subplots(1,1,figsize=(8,11), dpi = 200)\n",
    "#         a = ax.imshow(data,extent=[left, right, bottom, top],cmap='gist_earth')\n",
    "#         contours = ax.contour(contour_x,contour_y,np.log10(rss_mat[int(loc_idx[0]),:,:].T),cmap='plasma')\n",
    "#         ax.scatter(center_x, center_y, s=100,marker='*',c='r')\n",
    "#         plt.arrow(loc_x,loc_y,dy*length_factor,dx*length_factor, color='w', width=170, label='no weight')\n",
    "#         plt.arrow(loc_x,loc_y,dy_sharp*length_factor,dx_sharp*length_factor, color='k', width=170, label='sharpness')\n",
    "#         plt.arrow(loc_x,loc_y,dy_snr*length_factor,dx_snr*length_factor, color='m', width=170, label='snr')\n",
    "#         #plotting the stations on top of this as triangles\n",
    "#         for i, ii in enumerate(stas):\n",
    "#             sta_x,sta_y = transform(p1,p2,lons[i],lats[i])\n",
    "#             if left+info[3]<sta_x<right-info[4] and bottom+info[5]<sta_y<top-info[6]:\n",
    "#                 ax.plot(sta_x,sta_y, c='k', marker=\"^\")\n",
    "#                 ax.text(sta_x,sta_y,ii, c='k', fontsize = 15)\n",
    "\n",
    "#         #getting lat and lon tick marks on the axis\n",
    "#         tick_lons = lat_lon_dict[associated_volcano]['tick_lons']\n",
    "#         tick_lats = lat_lon_dict[associated_volcano]['tick_lats']\n",
    "#         ticks_x = []\n",
    "#         ticks_y = []\n",
    "#         for i in range(len(tick_lons)):\n",
    "#             tick_x,tick_y=transform(p1,p2,tick_lons[i],tick_lats[i])\n",
    "#             ticks_x.append(tick_x)\n",
    "#             ticks_y.append(tick_y)\n",
    "#             tick_lons[i]=str(tick_lons[i])\n",
    "#             tick_lats[i]=str(tick_lats[i])\n",
    "#         divider = make_axes_locatable(ax)\n",
    "#         cax1 = divider.append_axes('right', size='4%', pad=0.1)\n",
    "#         cax2 = divider.append_axes('right', size='4%', pad=1.3)\n",
    "#         ax.set_title('Location and Directivity', fontsize = 20)\n",
    "#         ax.set_xlabel('longitudes(DD)', fontsize = 15)\n",
    "#         ax.set_ylabel('latitudes(DD)', fontsize = 15)\n",
    "#         ax.set_xticks(ticks_x)\n",
    "#         ax.set_xticklabels(tick_lons, fontsize = 15)\n",
    "#         ax.set_yticks(ticks_y)\n",
    "#         ax.set_yticklabels(tick_lats, fontsize = 15)\n",
    "#         ax.clabel(contours)\n",
    "#         cbar = plt.colorbar(a, cax=cax1)\n",
    "#         cbar.ax.tick_params(labelsize=10)\n",
    "#         cbar.set_label('elevation(m)\\n', rotation=270, labelpad = 13, fontsize = 15)\n",
    "#         cbar2 = plt.colorbar(contours, cax=cax2)\n",
    "#         cbar2.ax.tick_params(labelsize=10)\n",
    "#         cbar2.set_label('RMS error on location\\n', rotation=270, labelpad = 13,fontsize = 15)\n",
    "#         ax.set_xlim(left+info[3],right-info[4])\n",
    "#         ax.set_ylim(bottom+info[5],top-info[6])\n",
    "#         ax.legend(fontsize = 12)\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('loc_direction'+ event_ID+associated_volcano+'.png',bbox_inches=\"tight\")\n",
    "\n",
    "#         # make a dataframe of the data\n",
    "#         evt_data = evt_data.append({'event_ID':event_ID, \n",
    "#                     'location_latitude': loc_lat,\n",
    "#                     'location_longitude': loc_lon,\n",
    "#                     'location_uncertainty(m)':diameter/10,\n",
    "#                     'origin_time': min(offsets)-int(loc_idx[0]),\n",
    "#                     'direction(degrees)':np.rad2deg(direction),\n",
    "#                     'direction_sharpness(degrees)':np.rad2deg(direction_sharp),\n",
    "#                     'direction_snr(degrees)':np.rad2deg(direction_snr),\n",
    "#                     'duration(sec)':avg_duration,\n",
    "#                     'params_std_deviation':std_deviation, \n",
    "#                     'velocity(m/s)':v, \n",
    "#                     'number_of_stations':len(stas)}, ignore_index = True)\n",
    "\n",
    "#         dict_temp = {}\n",
    "#         for i in range(len(stas)):\n",
    "#             dict_temp[stas[i]] = char_freq[i]\n",
    "#         print(dict_temp)    \n",
    "#         sta_freq = sta_freq.append(dict_temp,ignore_index = True)\n",
    "\n",
    "#         evt_data.to_csv('~/surface_events/Event_Data.csv', index=False)\n",
    "#         sta_freq.to_csv('~/surface_events/Station_frequency_data.csv', index=False)\n",
    "# #     except:\n",
    "# #         reject_evts = reject_evts.append({'event_ID':[event_ID]}, ignore_index = True)\n",
    "# #         reject_evts.to_csv('~/surface_events/Rejects5.csv', index=False)\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#         # create the grid of locations\n",
    "#         sta_x = []\n",
    "#         sta_y = []\n",
    "#         for i in range(len(sta_lats)):\n",
    "#             x_dist = distance.distance([lat_start,lon_start],[lat_start,sta_lons[i]]).m\n",
    "#             y_dist = distance.distance([lat_start,lon_start],[sta_lats[i],lon_start]).m\n",
    "#             sta_x.append(x_dist)\n",
    "#             sta_y.append(y_dist)\n",
    "#         x_vect = np.arange(0, side_length, step)\n",
    "#         y_vect = np.arange(0, side_length, step)\n",
    "#         t0 = np.arange(0,np.max(arrivals),t_step)\n",
    "\n",
    "#         # carry out the gridsearch weighted by SNR\n",
    "#         weight = np.array(SNR_weight)/np.max(SNR_weight)\n",
    "#         rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "#         loc_idx_snr = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "\n",
    "#         # gridsearch with no weight\n",
    "#         weight = [1 for i in range(len(SNR_weight))]\n",
    "#         rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,1000,arrivals,weight)\n",
    "#         loc_idx = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "\n",
    "#         # gridsearch weighted with SNR and Slope\n",
    "#         # plot DEM\n",
    "#         # gives the lower left grid point in the grid search\n",
    "#         # gives the left right, bottom, top of the grid\n",
    "#         left, right = r_dem_data_dict[associated_volcano]['left'],r_dem_data_dict[associated_volcano]['right']\n",
    "#         bottom, top = r_dem_data_dict[associated_volcano]['bottom'],r_dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "#         crs = dem_data_dict[associated_volcano]['crs']\n",
    "#         data = dem_data_dict[associated_volcano]['data']\n",
    "#         volc = rd.rdarray(data, no_data=-9999)\n",
    "#         slope = rd.TerrainAttribute(volc,attrib = 'slope_riserun')\n",
    "#         info = volc_lat_lon[associated_volcano]\n",
    "#         p2 = Proj(crs,preserve_units=False)\n",
    "#         p1 = Proj(proj='latlong',preserve_units=False)\n",
    "#         # gives the lower left grid point in the grid search\n",
    "#         left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "#         # gives the left right, bottom, top of the grid\n",
    "#         grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "#         left, right = r_dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "#         bottom, top = r_dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "#         a = int((left_x-left)/10)\n",
    "#         b = a+2500\n",
    "#         c = (slope.shape[0] - int((bottom_y-bottom)/10))-2500\n",
    "#         d = slope.shape[0] - int((bottom_y-bottom)/10)\n",
    "\n",
    "#         x = np.arange(a,b,1)\n",
    "#         y = np.arange(c,d,1)\n",
    "\n",
    "#         x2 = np.arange(a,b,10) # every 100m\n",
    "#         y2 = np.arange(c,d,10) # every 100m\n",
    "\n",
    "#         slope_data = np.array(slope[c:d,a:b])\n",
    "\n",
    "\n",
    "#         slope_norm1 = slope_data/np.max(slope_data)\n",
    "\n",
    "#         slope_interp_mat = RectBivariateSpline(y,x,slope_norm1, s = 0)\n",
    "#         interp = slope_interp_mat(x2,y2)/np.max(slope_interp_mat(x2,y2))*0.9+.1\n",
    "\n",
    "#         rss_mat_slope = np.multiply(rss_mat[loc_idx[0],:,:],interp)\n",
    "#         loc_idx_slope = np.unravel_index([np.argmin(rss_mat_slope)], rss_mat_slope.shape)\n",
    "#         loc_lat_slope, loc_lon_slope, test_d = location(x_vect[loc_idx_slope[1]], y_vect[loc_idx_slope[2]], lat_start, lon_start)\n",
    "\n",
    "#         # plot heatmap\n",
    "# #         fig,ax = plt.subplots(1,1,figsize=(8,8), dpi = 200)\n",
    "# #         ax.scatter(x_vect[loc_idx[1]],y_vect[loc_idx[2]],s=100,marker='*',c='r')\n",
    "# #         im = ax.imshow(np.log10(rss_mat[loc_idx[0],:,:].T),origin=\"lower\",extent=[0,side_length,0,side_length])\n",
    "# #         ax.set_ylabel('(m)')\n",
    "# #         ax.set_ylabel('(m)')\n",
    "# #         cbar = plt.colorbar(im)\n",
    "# #         cbar.ax.tick_params()\n",
    "# #         cbar.set_label('RMS error on location', rotation=270)\n",
    "# #         plt.savefig('heatmap'+ event_ID+associated_volcano+'.png')\n",
    "\n",
    "\n",
    "#         # find the latitude and longitude of the location index\n",
    "#         loc_lat, loc_lon, d = location(x_vect[loc_idx[1]], y_vect[loc_idx[2]], lat_start, lon_start)\n",
    "#         err_thr = np.min(np.log10(rss_mat))+.05\n",
    "#         thr_array = np.argwhere(np.log10(rss_mat)<err_thr)\n",
    "#         diameter = error_diameter(thr_array)\n",
    "\n",
    "#         break\n",
    "#         # calculating azimuth for each station with respect to the middle of the volcano\n",
    "#         for i in range(len(stas)):\n",
    "#             u,b,c = (gps2dist_azimuth(loc_lat, loc_lon, lats[i], lons[i], a=6378137.0, f=0.0033528106647474805))\n",
    "#             r.append(u)\n",
    "#             theta.append(b)\n",
    "\n",
    "#         bin1,bin2,bin3 = [],[],[]\n",
    "#         for i in theta:\n",
    "#             if 0<=i<=120:\n",
    "#                 bin1.append(i)\n",
    "#             if 121<=i<=240:\n",
    "#                 bin2.append(i)\n",
    "#             if 241<=i<=360:\n",
    "#                 bin3.append(i)\n",
    "\n",
    "#         if bin1 == [] or bin2 == [] or bin3 == []:\n",
    "#             continue\n",
    "\n",
    "#         #manipulating the data\n",
    "#         data = {'azimuth_deg':theta, 'freq':char_freq, 'station':stas, 'distance_m':r, \n",
    "#                 'weight':sharp_weight, 'SNR':SNR, 'colors':colors[0:len(stas)]}\n",
    "#         DF = pd.DataFrame(data, index = None)\n",
    "#         DF2 = DF.sort_values('azimuth_deg')\n",
    "\n",
    "#         #Taking out stations that are too close to the location when looking at azimuth \n",
    "#         drops = []\n",
    "#         for i in range(len(DF2)):\n",
    "#             value = DF2.loc[i,'distance_m']\n",
    "#             if value < az_thr:\n",
    "#                 drops.append(i)\n",
    "#         DF3 = DF2.drop(drops)\n",
    "#         y_data =  DF3[\"freq\"].values.tolist()\n",
    "#         Sta2 = DF3[\"station\"].values.tolist()\n",
    "#         dist2 = DF3[\"distance_m\"].values.tolist()\n",
    "#         spike_weight = DF3[\"weight\"].values.tolist()\n",
    "#         SNR2 = DF3['SNR'].values.tolist()\n",
    "#         colors2 = DF3['colors'].values.tolist()\n",
    "#         x_data =  np.asarray(DF3[\"azimuth_deg\"].values.tolist())\n",
    "#         x_points = np.linspace(0,360, 100)\n",
    "\n",
    "\n",
    "#         ################ DIRECTIVITY FIT ##################################\n",
    "#         #optimizing parameters to fit data to test_function\n",
    "#         params, params_covariance = optimize.curve_fit(test_func, np.deg2rad(x_data), y_data, p0=None)\n",
    "#         perr = np.sqrt(np.diag(params_covariance))\n",
    "#         std_deviation = str(round(perr[0],9))+','+str(round(perr[1],9))+','+str(round(perr[2],9))\n",
    "#         d = test_func(np.deg2rad(x_points), params[0], params[1], params[2])\n",
    "#         len_r = int(max(r))\n",
    "\n",
    "#         if params[0]<0:\n",
    "#             direction = params[1]+pi \n",
    "#         else:\n",
    "#             direction = params[1]\n",
    "\n",
    "#         fmax = max(d)\n",
    "#         fmin = min(d)\n",
    "#         v = v_s*((fmax-fmin)/(fmax+fmin))\n",
    "\n",
    "\n",
    "\n",
    "#         # weight the data\n",
    "#         # title = 'Sharpness'\n",
    "#         v_sharp,direction_sharp,d_sharp = weight_data(x_data,y_data,sharp_weight,test_func,v_s,stas)\n",
    "\n",
    "#         # title = 'SNR'\n",
    "#         v_snr,direction_snr,d_snr = weight_data(x_data,y_data,SNR_weight,test_func,v_s,stas)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         ############### PLOTS ###################\n",
    "#         #convert the direction from polar to cartesian coordinates\n",
    "#         dy = len_r*np.sin(direction)\n",
    "#         dx = len_r*np.cos(direction)     \n",
    "\n",
    "#         dy_sharp = len_r*np.sin(direction_sharp)\n",
    "#         dx_sharp = len_r*np.cos(direction_sharp)    \n",
    "\n",
    "\n",
    "#         dy_snr = len_r*np.sin(direction_snr)\n",
    "#         dx_snr = len_r*np.cos(direction_snr) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         fig,ax = plt.subplots(1,1,figsize=(11,8), dpi = 200)\n",
    "#         fig.suptitle('Fitted Cosine Curves')       \n",
    "#         ax.set_ylabel('characteristic frequency(Hz)')\n",
    "#         ax.set_xlabel(('azimuth(degrees)'))\n",
    "#         for i in range (0,len(Sta2)):\n",
    "#             ax.scatter(x_data[i], y_data[i], s = (SNR_weight[i]**2),label=Sta2[i], color = colors2[i])\n",
    "#         ax.plot(x_data,y_data, '--', label='rawdata')\n",
    "#         ax.plot(x_points, d, label = 'original')\n",
    "#         ax.plot(x_points, d_sharp, label = 'sharpness')\n",
    "#         ax.plot(x_points, d_snr, label = 'snr')\n",
    "#         ax.legend(loc='upper right', fontsize = 10)\n",
    "#         plt.grid(True)\n",
    "#         plt.savefig('curves_freq_data'+ event_ID+associated_volcano+'.png')\n",
    "\n",
    "#         #making plots of directivity and location\n",
    "#         crs = dem_data_dict[associated_volcano]['crs']\n",
    "#         data = dem_data_dict[associated_volcano]['data']\n",
    "#         info = volc_lat_lon[associated_volcano]\n",
    "#         p2 = Proj(crs,preserve_units=False)\n",
    "#         p1 = Proj(proj='latlong',preserve_units=False)\n",
    "#         # gives the lower left grid point in the grid search\n",
    "#         left_x,bottom_y = transform(p1,p2,volc_grid[associated_volcano][1],volc_grid[associated_volcano][0]) # p1,p2,lon,lat\n",
    "#         # gives the left right, bottom, top of the grid\n",
    "#         grid_bounds = [left_x, left_x+volc_grid[associated_volcano][2], bottom_y, bottom_y+volc_grid[associated_volcano][2]]\n",
    "#         left, right = dem_data_dict[associated_volcano]['left'],dem_data_dict[associated_volcano]['right']\n",
    "#         bottom, top = dem_data_dict[associated_volcano]['bottom'],dem_data_dict[associated_volcano]['top']\n",
    "\n",
    "#         # convert loc data onto the DEM data\n",
    "#         contour_x,contour_y = np.meshgrid(left_x+x_vect,bottom_y+y_vect)\n",
    "#         center_x, center_y = transform(p1,p2,info[1],info[0])\n",
    "#         loc_x,loc_y=transform(p1,p2,loc_lon,loc_lat)\n",
    "#         duration=avg_duration\n",
    "#         length_factor = duration/100\n",
    "\n",
    "#         fig,ax = plt.subplots(1,1,figsize=(8,11), dpi = 200)\n",
    "#         a = ax.imshow(data,extent=[left, right, bottom, top],cmap='gist_earth')\n",
    "#         contours = ax.contour(contour_x,contour_y,np.log10(rss_mat[int(loc_idx[0]),:,:].T),cmap='plasma')\n",
    "#         ax.scatter(center_x, center_y, s=100,marker='*',c='r')\n",
    "#         plt.arrow(loc_x,loc_y,dy*length_factor,dx*length_factor, color='w', width=170, label='no weight')\n",
    "#         plt.arrow(loc_x,loc_y,dy_sharp*length_factor,dx_sharp*length_factor, color='k', width=170, label='sharpness')\n",
    "#         plt.arrow(loc_x,loc_y,dy_snr*length_factor,dx_snr*length_factor, color='m', width=170, label='snr')\n",
    "#         #plotting the stations on top of this as triangles\n",
    "#         for i, ii in enumerate(stas):\n",
    "#             sta_x,sta_y = transform(p1,p2,lons[i],lats[i])\n",
    "#             if left+info[3]<sta_x<right-info[4] and bottom+info[5]<sta_y<top-info[6]:\n",
    "#                 ax.plot(sta_x,sta_y, c='k', marker=\"^\")\n",
    "#                 ax.text(sta_x,sta_y,ii, c='k', fontsize = 15)\n",
    "\n",
    "#         #getting lat and lon tick marks on the axis\n",
    "#         tick_lons = lat_lon_dict[associated_volcano]['tick_lons']\n",
    "#         tick_lats = lat_lon_dict[associated_volcano]['tick_lats']\n",
    "#         ticks_x = []\n",
    "#         ticks_y = []\n",
    "#         for i in range(len(tick_lons)):\n",
    "#             tick_x,tick_y=transform(p1,p2,tick_lons[i],tick_lats[i])\n",
    "#             ticks_x.append(tick_x)\n",
    "#             ticks_y.append(tick_y)\n",
    "#             tick_lons[i]=str(tick_lons[i])\n",
    "#             tick_lats[i]=str(tick_lats[i])\n",
    "#         divider = make_axes_locatable(ax)\n",
    "#         cax1 = divider.append_axes('right', size='4%', pad=0.1)\n",
    "#         cax2 = divider.append_axes('right', size='4%', pad=1.3)\n",
    "#         ax.set_title('Location and Directivity', fontsize = 20)\n",
    "#         ax.set_xlabel('longitudes(DD)', fontsize = 15)\n",
    "#         ax.set_ylabel('latitudes(DD)', fontsize = 15)\n",
    "#         ax.set_xticks(ticks_x)\n",
    "#         ax.set_xticklabels(tick_lons, fontsize = 15)\n",
    "#         ax.set_yticks(ticks_y)\n",
    "#         ax.set_yticklabels(tick_lats, fontsize = 15)\n",
    "#         ax.clabel(contours)\n",
    "#         cbar = plt.colorbar(a, cax=cax1)\n",
    "#         cbar.ax.tick_params(labelsize=10)\n",
    "#         cbar.set_label('elevation(m)\\n', rotation=270, labelpad = 13, fontsize = 15)\n",
    "#         cbar2 = plt.colorbar(contours, cax=cax2)\n",
    "#         cbar2.ax.tick_params(labelsize=10)\n",
    "#         cbar2.set_label('RMS error on location\\n', rotation=270, labelpad = 13,fontsize = 15)\n",
    "#         ax.set_xlim(left+info[3],right-info[4])\n",
    "#         ax.set_ylim(bottom+info[5],top-info[6])\n",
    "#         ax.legend(fontsize = 12)\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('loc_direction'+ event_ID+associated_volcano+'.png',bbox_inches=\"tight\")\n",
    "\n",
    "#         # make a dataframe of the data\n",
    "#         evt_data = evt_data.append({'event_ID':event_ID, \n",
    "#                     'location_latitude': loc_lat,\n",
    "#                     'location_longitude': loc_lon,\n",
    "#                     'location_uncertainty(m)':diameter/10,\n",
    "#                     'origin_time': min(offsets)-int(loc_idx[0]),\n",
    "#                     'direction(degrees)':np.rad2deg(direction),\n",
    "#                     'direction_sharpness(degrees)':np.rad2deg(direction_sharp),\n",
    "#                     'direction_snr(degrees)':np.rad2deg(direction_snr),\n",
    "#                     'duration(sec)':avg_duration,\n",
    "#                     'params_std_deviation':std_deviation, \n",
    "#                     'velocity(m/s)':v, \n",
    "#                     'number_of_stations':len(stas)}, ignore_index = True)\n",
    "\n",
    "#         dict_temp = {}\n",
    "#         for i in range(len(stas)):\n",
    "#             dict_temp[stas[i]] = char_freq[i]\n",
    "#         print(dict_temp)    \n",
    "#         sta_freq = sta_freq.append(dict_temp,ignore_index = True)\n",
    "\n",
    "#         evt_data.to_csv('~/surface_events/Event_Data.csv', index=False)\n",
    "#         sta_freq.to_csv('~/surface_events/Station_frequency_data.csv', index=False)\n",
    "# #     except:\n",
    "# #         reject_evts = reject_evts.append({'event_ID':[event_ID]}, ignore_index = True)\n",
    "# #         reject_evts.to_csv('~/surface_events/Rejects5.csv', index=False)\n",
    "#         continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo_exo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
