{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark ELEP for phase picking surface events\n",
    "\n",
    "We will test the ELEP workflow to phase picks the SU events picked by the PNSN.\n",
    "This notebooks focuses on the multiband workflow (a bit complicated!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/data/wsd01/pnwstore/')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import obspy\n",
    "from obspy.core import UTCDateTime\n",
    "from obspy.clients.fdsn.client import Client\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from geopy import distance\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "import torch\n",
    "import gc\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "\n",
    "import seisbench.models as sbm\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.ensemble_learners import ensemble_regressor_cnn\n",
    "from ELEP.elep import mbf, mbf_utils\n",
    "from ELEP.elep import trigger_func\n",
    "\n",
    "from ELEP.elep.mbf_utils import make_LogFq, make_LinFq, rec_filter_coeff, create_obspy_trace\n",
    "from ELEP.elep.mbf import MB_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define clients to download the station data\n",
    "# client = WaveformClient() # we ignore PNWdatastore for now\n",
    "client2 = Client('IRIS')\n",
    "\n",
    "t_before = 15 #number of seconds before pick time\n",
    "# t_after = 15 #number of seconds after pick time\n",
    "t_before_raw = 1200 #number of seconds before pick time before removing instrumental response\n",
    "# t_after_raw = 1200 #number of seconds after pick time before removing instrumental response\n",
    "fs = 40 #sampling rate that all waveforms are resampled to\n",
    "window = 150 #window length of the signal (this will help with phase picking with EqT next). \n",
    "# Use 150 seconds @ 40 Hz gives 6001 points. \n",
    "pr = 98 #percentile\n",
    "thr = 5 #SNR threshold\n",
    "station_distance_threshold = 25\n",
    "pi = np.pi\n",
    "v_s = 1000 #shear wave velocity at the surface\n",
    "\n",
    "# range of dates that we are looking at\n",
    "t_beginning = UTCDateTime(2001,1,1,0,0,0) \n",
    "t_end = UTCDateTime(2023,8,2,23,59)\n",
    "twin=6000\n",
    "\n",
    "smooth_length = 5 # constant for smoothing the waveform envelopes\n",
    "low_cut = 1 #low frequency threshold\n",
    "high_cut = 12 #high frequency threshold\n",
    "az_thr = 1000 #threshold of distance in meters from source location\n",
    "step = 100 #step every 100 m\n",
    "t_step = 1 #step every second\n",
    "ratio = 5.6915196 #used to define the grid \n",
    "colors = list(plt.cm.tab10(np.arange(10)))*3\n",
    "radius = 6371e3 # radius of the earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ML picker parameters\n",
    "paras_semblance = {'dt':0.025, 'semblance_order':4, 'window_flag':True, \n",
    "                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "p_thrd, s_thrd = 0.01, 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download models\n",
    "pretrain_list = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\",\"neic\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_pnw_model.to(device);\n",
    "pn_ethz_model.to(device);\n",
    "pn_scedc_model.to(device);\n",
    "pn_neic_model.to(device);\n",
    "pn_geofon_model.to(device);\n",
    "pn_stead_model.to(device);\n",
    "pn_instance_model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## volcano info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data includes all stations within 50km of each volcano and the lat, lon, elev of each station\n",
    "df = pd.read_csv('../data/station/Volcano_Metadata_50km.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Surface Event Data from PNSN\n",
    "\n",
    "Read files straight from PNSN data base. Extract station and network code, phase pick time (seen as start_time). this should be converted to pick_time0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv(\"../data/events/su_picks.txt\",sep=\"|\")\n",
    "f1.head()\n",
    "print(f1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the spaces in the file\n",
    "format='%Y/%m/%d %H:%M:%S'\n",
    "test=f1[\"date\"].values.tolist()\n",
    "start_time_temp = [  datetime.strptime(x.strip(),'%Y/%m/%d %H:%M:%S') for x in f1[\"date\"].values.tolist()]\n",
    "# # Ignore events prior to t_beginning\n",
    "ik=np.where(np.array(start_time_temp)>datetime(2001,1,1))[0][0]\n",
    "\n",
    "# select only net, sta, evid, startime for event past the start date.\n",
    "\n",
    "start_time = start_time_temp[ik:]\n",
    "net=[ x.strip() for x in f1[\"net\"].values.tolist()][ik:]\n",
    "sta=[ x.strip() for x in f1[\"sta\"].values.tolist()][ik:]\n",
    "evt_id=[ x for x in f1[\"orid\"].values.tolist()][ik:]\n",
    "all_stas=set(sta)\n",
    "\n",
    "\n",
    "f2=pd.DataFrame({\"date\":start_time,\"net\":net,\"sta\":sta,\"evt_id\":evt_id})\n",
    "f2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fqmin = low_cut\n",
    "fqmax = high_cut\n",
    "dt = 0.025; fs = 40\n",
    "nfqs = 10\n",
    "nt = 6000; nc = 3\n",
    "fq_list = make_LogFq(fqmin, fqmax, dt, nfqs)\n",
    "coeff_HP, coeff_LP = rec_filter_coeff(fq_list, dt)\n",
    "MBF_paras = {'f_min':fqmin, 'f_max':fqmax, 'nfqs':nfqs, 'frequencies':fq_list, 'CN_HP':coeff_HP, 'CN_LP':coeff_LP, \\\n",
    "    'dt':dt, 'fs':fs, 'nt':nt, 'nc':nc, 'npoles': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_error = np.zeros(len(evt_id))\n",
    "pick_error_mbf = np.zeros(len(evt_id))\n",
    "maxsnr = np.zeros(len(evt_id))\n",
    "whatvolcano = np.array(len(evt_id))\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('../plots/MLPicks_MBF_test.pdf')\n",
    "for n in range(len(evt_id)): \n",
    "    # if start_time[n]<datetime(2020,1,1):continue   \n",
    "    event_ID = str(evt_id[n])\n",
    "    otime = UTCDateTime(start_time[n])\n",
    "    networks=net[n]\n",
    "    stations=sta[n]\n",
    "    if sta[n]==\"LON\" or sta[n]==\"LO2\":continue\n",
    "    # print(net[n],sta[n])\n",
    "    try:\n",
    "        associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "    except: \n",
    "        pass\n",
    "    # if associated_volcano!=\"Mt_Rainier\":continue\n",
    "            \n",
    "#################### WAVEFORM DOWNLOAD #######################\n",
    "    #Download all waveforms for that event based on stations and times\n",
    "    bulk=[[net[n], sta[n], '*', '*H*', otime-t_before_raw, otime+t_before_raw]]\n",
    "    try:\n",
    "        st = client2.get_waveforms_bulk(bulk)\n",
    "        st = resample(st,fs)  #resampling the data to 40Hz for each trace\n",
    "        \n",
    "        evt_data = obspy.Stream()\n",
    "\n",
    "        # #Plotting all traces for one event with channel z, SNR>10, and bandpasses between 2-12Hz\n",
    "        SNR,SNR_weight, no_weight,stas,nets,max_amp_times,durations,data_env_dict,t_diff = [],[],[],[],[],[],[],{},{}\n",
    "        for i,ii in enumerate(st):\n",
    "            network = ii.stats.network\n",
    "            station = ii.stats.station\n",
    "            ii.detrend(type = 'demean')\n",
    "            ii.filter('bandpass',freqmin=low_cut,freqmax=high_cut,corners=2,zerophase=True)\n",
    "            cha = ii.stats.channel\n",
    "            starttime = ii.stats.starttime\n",
    "            signal_window = ii.copy()\n",
    "            noise_window = ii.copy()\n",
    "            # trim the data and noise window to exactly 6000 points\n",
    "            signal_window.trim(otime - t_before, otime - t_before + window) # trim the signal at the first pick time of the PNSN data, with loose 40s before\n",
    "            noise_window.trim(otime - window -t_before, otime - t_before) # noise window of the same length\n",
    "            if not len(signal_window.data) or not len(signal_window.data): continue\n",
    "            # print(len(signal_window),len(noise_window.data))\n",
    "            if not np.max(np.percentile(np.abs(signal_window.data),pr)):continue\n",
    "            if len(noise_window.data)==0:continue\n",
    "            snr = (20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                            / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "            max_amp_time = np.argmax(noise_window.data)/fs\n",
    "            # print(snr,max_amp_time)\n",
    "            # signal_window.plot()x\n",
    "            # if snr<thr: \n",
    "            #     st.remove(ii)\n",
    "            #     continue\n",
    "            # start the time axis 15 seconds before the pick time of the first reference station\n",
    "            t = signal_window.times()[:-1] #\n",
    "            t_diff[network+'.'+station] = starttime-otime \n",
    "            stas.append(ii.stats.station)\n",
    "            nets.append(ii.stats.network)\n",
    "            SNR.append(snr)\n",
    "            SNR_weight.append(int(snr))\n",
    "            # no_weight.append(1)\n",
    "            evt_data.append(signal_window)\n",
    "            \n",
    "        sta_available,ind = np.unique(np.array(stas),return_index=True)\n",
    "        sta_available=sta_available[np.argsort(ind)]\n",
    "        if len(sta_available)==0:continue\n",
    "\n",
    "        print(event_ID,otime)\n",
    "        print(associated_volcano)\n",
    "        bigS = np.zeros(shape=(len(sta_available),3,6000))\n",
    "        stas=[]\n",
    "        # print(sta_available)\n",
    "        # print(evt_data)\n",
    "        for i in range(len(sta_available)):\n",
    "            stream = evt_data.select(station=sta_available[i])\n",
    "            # print(i,stream)\n",
    "            if len(stream[0].data)<6000:continue\n",
    "            # print(\"original stream\")\n",
    "            # print(stream)\n",
    "            if len(stream)<3:\n",
    "                # copy stream to 2 components, zero the missing data.\n",
    "                tr3 = stream[0].copy() # assumed to be the vertical\n",
    "                tr2 = stream[0].copy();tr2.stats.channel=stream[0].stats.channel[0:2]+\"N\"\n",
    "                tr1 = stream[0].copy();tr1.stats.channel=stream[0].stats.channel[0:2]+\"E\"\n",
    "                tr1.data=np.zeros(len(stream[0].data))\n",
    "                tr2.data=np.zeros(len(stream[0].data))\n",
    "                stream=obspy.Stream(traces=[tr1,tr2,tr3])\n",
    "            # convert Stream into seisbench-friendly array    \n",
    "            # fill in big array and order data ZNE\n",
    "            bigS[i,0,:]=stream[2].data[:-1]\n",
    "            bigS[i,1,:]=stream[1].data[:-1]\n",
    "            bigS[i,2,:]=stream[0].data[:-1]\n",
    "            stas.append(sta_available[i])\n",
    "\n",
    "\n",
    "        \n",
    "        # print(\"put data in numpy array\")\n",
    "\n",
    "        nwin,twin=bigS.shape[1],bigS.shape[-1]\n",
    "        nsta = len(sta_available)\n",
    "        # print(\"There are %i stations available\"%nsta)\n",
    "\n",
    "        # allocating memory for the ensemble predictions\n",
    "        # 7 pre-trained models, nsta stations for batch, 6000 input points\n",
    "        batch_pred =np.zeros(shape=(7,nsta,6000)) \n",
    "        batch_pred_mbf =np.zeros(shape=(7,nsta,6000))\n",
    "\n",
    "\n",
    "        # evaluate\n",
    "        pn_pnw_model.eval()\n",
    "        pn_ethz_model.eval()\n",
    "        pn_scedc_model.eval()\n",
    "        pn_neic_model.eval()\n",
    "        pn_geofon_model.eval()\n",
    "        pn_stead_model.eval()\n",
    "        pn_instance_model.eval()\n",
    "\n",
    "        ######### Broadband workflow ################\n",
    "        crap2  = bigS.copy()\n",
    "        crap2 -= np.mean(crap2,axis=-1,keepdims=True) # demean data\n",
    "        # original use std norm\n",
    "        data_std = crap2 / np.std(crap2) + 1e-10\n",
    "        # could use max data\n",
    "        mmax= np.max(np.abs(crap2), axis=-1, keepdims=True)\n",
    "        data_max = np.divide(crap2 ,mmax,out=np.zeros_like(crap2),where=mmax!=0)\n",
    "        data_tt = torch.Tensor(data_max)\n",
    "        # batch predict picks.\n",
    "        _torch_pred_1 = pn_pnw_model(data_tt.to(device))\n",
    "        _torch_pred_2 = pn_ethz_model(data_tt.to(device))\n",
    "        _torch_pred_3 = pn_scedc_model(data_tt.to(device))\n",
    "        _torch_pred_4 = pn_neic_model(data_tt.to(device))\n",
    "        _torch_pred_5 = pn_geofon_model(data_tt.to(device))\n",
    "        _torch_pred_6 = pn_stead_model(data_tt.to(device))\n",
    "        _torch_pred_7 = pn_instance_model(data_tt.to(device))\n",
    "        # extract P pdf\n",
    "\n",
    "        # print(\"now predicting on BB\")\n",
    "        batch_pred[0,:, :] = _torch_pred_1[1].detach().cpu().numpy()[:, :]\n",
    "        batch_pred[1,:, :] = _torch_pred_2[1].detach().cpu().numpy()[:, :]\n",
    "        batch_pred[2,:, :] = _torch_pred_3[1].detach().cpu().numpy()[:, :]\n",
    "        batch_pred[3,:, :] = _torch_pred_4[1].detach().cpu().numpy()[:, :]\n",
    "        batch_pred[4,:, :] = _torch_pred_5[1].detach().cpu().numpy()[:, :]\n",
    "        batch_pred[5,:, :] = _torch_pred_6[1].detach().cpu().numpy()[:, :]\n",
    "        batch_pred[6,:, :] = _torch_pred_7[1].detach().cpu().numpy()[:, :]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        ############# Multi-band Workflow ########\n",
    "        windows_std = np.zeros(shape=(nsta, nfqs, 3, twin), dtype= np.float32)\n",
    "        windows_max = np.zeros(shape=( nsta, nfqs, 3, twin), dtype= np.float32)\n",
    "        _windows = bigS.copy();#np.zeros(shape=(nsta, 3, twin), dtype= np.float32)\n",
    "        _windows_mb = np.zeros(shape=(nsta, 3, nfqs, twin), dtype= np.float32)\n",
    "\n",
    "        # MB filter\n",
    "        for ista in range(nsta): # loop over stations, it should be one in this benchmark test\n",
    "            for icha in range(3): # loop over channel, there should be 3 channels total\n",
    "                _windows_mb[ista, icha, :, :] = MB_filter(_windows[ista, icha], MBF_paras)\n",
    "        _windows_mb = _windows_mb.swapaxes(1, 2)\n",
    "        # print(\"Shape of the multi-band data array: \",_windows_mb.shape)\n",
    "        # normalize the multi band data\n",
    "        for ista in range(nsta):\n",
    "            for ifreq in range(nfqs):\n",
    "                # original use std norm\n",
    "                windows_std[ista, ifreq,:, :] = _windows_mb[ista, ifreq, :]  \\\n",
    "                    / np.std(_windows_mb[ista, ifreq, :]) + 1e-10\n",
    "                # others use max norm\n",
    "                mmax=np.max(np.abs(_windows_mb[ista, ifreq,:, :]), axis=-1, keepdims=True)\n",
    "                windows_max[ista, ifreq,:, :] = np.divide(_windows_mb[ista, ifreq,:, :] \\\n",
    "                    ,mmax,out=np.zeros_like(_windows_mb[ista, ifreq, :]),where=mmax!=0)\n",
    "\n",
    "\n",
    "        # print(f\"Window data shape: {data_std.shape}\"))\n",
    "\n",
    "\n",
    "        # print(\"now predicting on MBF\")\n",
    "        batch_pred_mbf_freq =np.zeros(shape=(7,nfqs,nsta,twin))\n",
    "        for ifreq in range(nfqs):\n",
    "            # convert numpy array to torch tensor\n",
    "            data_tt_mbf = torch.Tensor(windows_max[:,ifreq,:,:])\n",
    "            # batch predict picks.\n",
    "            _torch_pred_1 = pn_pnw_model(data_tt_mbf.to(device))\n",
    "            _torch_pred_2 = pn_ethz_model(data_tt_mbf.to(device))\n",
    "            _torch_pred_3 = pn_scedc_model(data_tt_mbf.to(device))\n",
    "            _torch_pred_4 = pn_neic_model(data_tt_mbf.to(device))\n",
    "            _torch_pred_5 = pn_geofon_model(data_tt_mbf.to(device))\n",
    "            _torch_pred_6 = pn_stead_model(data_tt_mbf.to(device))\n",
    "            _torch_pred_7 = pn_instance_model(data_tt_mbf.to(device))\n",
    "            # # extract P pdf\n",
    "            batch_pred_mbf_freq[0,ifreq,:, :] = _torch_pred_1[1].detach().cpu().numpy()[:, :]\n",
    "            batch_pred_mbf_freq[1,ifreq,:, :] = _torch_pred_2[1].detach().cpu().numpy()[:, :]\n",
    "            batch_pred_mbf_freq[2,ifreq,:, :] = _torch_pred_3[1].detach().cpu().numpy()[:, :]\n",
    "            batch_pred_mbf_freq[3,ifreq,:, :] = _torch_pred_4[1].detach().cpu().numpy()[:, :]\n",
    "            batch_pred_mbf_freq[4,ifreq,:, :] = _torch_pred_5[1].detach().cpu().numpy()[:, :]\n",
    "            batch_pred_mbf_freq[5,ifreq,:, :] = _torch_pred_6[1].detach().cpu().numpy()[:, :]\n",
    "            batch_pred_mbf_freq[6,ifreq,:, :] = _torch_pred_7[1].detach().cpu().numpy()[:, :]\n",
    "\n",
    "\n",
    "            # batch_pred_mbf=np.zeros(shape=(nsta, nfqs, twin), dtype= np.float32)\n",
    "            # for ista in range(nsta):\n",
    "            #     plt.plot(t-t_before,windows_std[ista,ifreq,0,:].T,linewidth=0.7)\n",
    "            #     plt.plot(t-t_before,batch_pred_mbf_freq[6,:,ista, :].T*10,linewidth=0.7,color='0.8')\n",
    "            #     plt.plot(t-t_before,batch_pred[6,ista, :].T*10,linewidth=0.9,color='k')\n",
    "            #     plt.grid(True)\n",
    "            #     # print(np.amax(batch_pred[0, :, iseg, :]))\n",
    "            #     ifreq_max = np.argwhere(batch_pred_mbf_freq[0, :, ista, :] == \\\n",
    "            #                                 np.amax(batch_pred_mbf_freq[0, :, ista, :]))[0][0]\n",
    "            #     batch_pred_mbf[0, ista, :] = batch_pred_mbf_freq[0, ifreq_max, ista, :]\n",
    "            #     print(ifreq_max)\n",
    "            #     plt.plot(t-t_before,batch_pred_mbf[6,ista, :].T*10,linewidth=0.9,color='r')\n",
    "            \n",
    "                # ifre_max = np.argmax(batch_pred[0,icha, :, iseg, :])\n",
    "                # print(ifre_max)\n",
    "                # batch_pred[0,icha, :, :] = batch_pred[0,icha, ifre_max, :, :]\n",
    "                # plt.plot(batch_pred[0,icha, :, :])\n",
    "\n",
    "        # batch_pred_mbf=np.zeros(shape=(nsta, nfqs, twin), dtype= np.float32)\n",
    "        \n",
    "        fig = plt.figure()#figsize = (11,8), dpi=200)\n",
    "        fig.suptitle(str(otime)+\" \"+associated_volcano)\n",
    "        ax = plt.subplot(1,1,1)\n",
    "        for ista in range(nsta):\n",
    "            ax.plot(t-t_before,data_max[ista,0,:].T,linewidth=0.7)\n",
    "            ax.plot(t-t_before,batch_pred_mbf_freq[6,:,ista, :].T,linewidth=0.7,color='0.8')\n",
    "            ax.plot(t-t_before,batch_pred[6,ista, :].T,linewidth=0.9,color='k')\n",
    "            plt.grid(True)\n",
    "            # print(np.amax(batch_pred[0, :, iseg, :]))\n",
    "            ifreq_max = np.zeros(twin)\n",
    "            for it in range(twin):\n",
    "                # ifreq_max[it] = np.amax(batch_pred_mbf_freq[0, :, ista, it])#[0]\n",
    "                batch_pred_mbf[0, ista, it] =  np.max(batch_pred_mbf_freq[0, :, ista, it])\n",
    "                batch_pred_mbf[1, ista, it] =  np.max(batch_pred_mbf_freq[1, :, ista, it])\n",
    "                batch_pred_mbf[2, ista, it] =  np.max(batch_pred_mbf_freq[2, :, ista, it])\n",
    "                batch_pred_mbf[3, ista, it] =  np.max(batch_pred_mbf_freq[3, :, ista, it])\n",
    "                batch_pred_mbf[4, ista, it] =  np.max(batch_pred_mbf_freq[4, :, ista, it])\n",
    "                batch_pred_mbf[5, ista, it] =  np.max(batch_pred_mbf_freq[5, :, ista, it])\n",
    "                batch_pred_mbf[6, ista, it] =  np.max(batch_pred_mbf_freq[6, :, ista, it])\n",
    "            # print(ifreq_max)\n",
    "            # ifreq_max = np.argwhere(batch_pred_mbf_freq[0, :, ista, :] == \\\n",
    "                                        # np.amax(batch_pred_mbf_freq[0, :, ista, :]))[0][0]\n",
    "            # print(\"ifreq_max\",ifreq_max)\n",
    "            # batch_pred_mbf[6, ista, :] = batch_pred_mbf_freq[6, ifreq_max, ista, :]\n",
    "            # print(ifreq_max)\n",
    "            plt.plot(t-t_before,batch_pred_mbf[6,ista, :].T,linewidth=0.5,color='r')\n",
    "        \n",
    "            # ifre_max = np.argmax(batch_pred[0,icha, :, iseg, :])\n",
    "            # print(ifre_max)\n",
    "            # batch_pred[0,icha, :, :] = batch_pred[0,icha, ifre_max, :, :]\n",
    "            # plt.plot(batch_pred[0,icha, :, :])\n",
    "\n",
    "\n",
    "        # plt.show()\n",
    "        pdf.savefig(fig)\n",
    "        # ensemble semblance\n",
    "        if nwin==0:continue\n",
    "        smb_pred = np.zeros([ nsta, twin], dtype = np.float32)\n",
    "        smb_pred_mbf = np.zeros([ nsta, twin], dtype = np.float32)\n",
    "        smb_peak = np.zeros([ nsta], dtype = np.float32)\n",
    "        smb_peak_mbf = np.zeros([ nsta], dtype = np.float32)\n",
    "\n",
    "        # Pick the phase. Assume that the PNSN is correct within 5 seconds of record.\n",
    "\n",
    "        for ista in range(nsta): # should be 1 in this context\n",
    "            \n",
    "            # 0 for P-wave\n",
    "            smb_pred[ ista, :] = ensemble_semblance(batch_pred[:, ista, :], paras_semblance)\n",
    "            imax = np.argmax(smb_pred[ ista, t_before*40 - 5*40 : t_before*40 + 5*40 ]) # search for peak in the first 80 seconds\n",
    "            if smb_pred[ ista,imax]>0:\n",
    "                smb_peak[ista]=float((imax)/40)-5\n",
    "            # 0 for P-wave\n",
    "            smb_pred_mbf[ ista, :] = ensemble_semblance(batch_pred_mbf[:, ista, :], paras_semblance)\n",
    "            imax = np.argmax(smb_pred_mbf[ ista, t_before*40 - 5*40 : t_before*40 + 5*40]) # search for peak in the first 80 seconds\n",
    "            if smb_pred_mbf[ ista,imax]>0:\n",
    "                smb_peak_mbf[ista]=float((imax)/40)-5\n",
    "\n",
    "\n",
    "\n",
    "        print(smb_peak[ista],smb_peak_mbf[ista])\n",
    "        # plt.show()\n",
    "        del _torch_pred_1,_torch_pred_2,_torch_pred_3,_torch_pred_4,_torch_pred_5,_torch_pred_6,_torch_pred_7\n",
    "        gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        pick_error[n]=smb_peak[ista]\n",
    "        pick_error_mbf[n]=smb_peak_mbf[ista]\n",
    "        maxsnr[n] = max(SNR)\n",
    "        whatvolcano[n]=associated_volcano\n",
    "    except:\n",
    "        pass\n",
    "f2[\"pick_error\"]=pick_error\n",
    "f2[\"pick_error_mbf\"]=pick_error_mbf\n",
    "f2[\"snr\"]=maxsnr\n",
    "f2[\"associated_volcano\"]=whatvolcano\n",
    "f2.to_csv(\"../data/mbf_elep_picks_su.csv\")\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/mbf_elep_picks_su.csv\")\n",
    "df.head()\n",
    "ik=df.index[ ( df[\"pick_error\"]!=0 ) & ( np.abs(df[\"pick_error\"])<10 )].tolist()\n",
    "\n",
    "print(len(ik))\n",
    "plt.figure(figsize = (10, 5), dpi = 300)\n",
    "plt.hist(df[\"pick_error\"][ik], 100, edgecolor = 'k', zorder = 10)\n",
    "plt.grid(True)\n",
    "std_text=\"STD = %2.2f\"%(np.std(df[\"pick_error\"][ik]))\n",
    "mae_text=\"MAE = %2.2f\"%(np.mean(np.abs(df[\"pick_error\"][ik])))\n",
    "plt.text(-6,120,std_text,fontsize=16)\n",
    "plt.text(-6,100,mae_text,fontsize=16)\n",
    "plt.xlabel(\"Picking errors (s)\", fontsize = 20)\n",
    "plt.ylabel(\"Number of events\", fontsize = 20)\n",
    "plt.savefig(\"../plots/BB_ELEP_picking_errors_highSNR.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/mbf_elep_picks_su.csv\")\n",
    "df.head()\n",
    "ik=df.index[ ( df[\"pick_error_mbf\"]!=0 ) & ( np.abs(df[\"pick_error_mbf\"])<10 )].tolist()\n",
    "\n",
    "print(len(ik))\n",
    "plt.figure(figsize = (10, 5), dpi = 300)\n",
    "plt.hist(df[\"pick_error_mbf\"][ik], 100, edgecolor = 'k', zorder = 10)\n",
    "plt.grid(True)\n",
    "std_text=\"STD = %2.2f\"%(np.std(df[\"pick_error_mbf\"][ik]))\n",
    "mae_text=\"MAE = %2.2f\"%(np.mean(np.abs(df[\"pick_error_mbf\"][ik])))\n",
    "plt.text(-6,120,std_text,fontsize=16)\n",
    "plt.text(-6,100,mae_text,fontsize=16)\n",
    "plt.xlabel(\"Picking errors (s)\", fontsize = 20)\n",
    "plt.ylabel(\"Number of events\", fontsize = 20)\n",
    "plt.savefig(\"../plots/MBF_ELEP_picking_errors_highSNR.png\", bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo_exo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
